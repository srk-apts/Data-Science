{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science: \n",
    "\n",
    "## Homework 2  AC 209 : Linear and k-NN Regression\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2018**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader\n",
    "\n",
    "<hr style=\"height:2pt\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- To submit your assignment follow the instructions given in canvas.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- If you submit individually and you have worked with someone, please include the name of your [one] partner below. \n",
    "- As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach. And if a problem specifies a particular library you're required to use that library, and possibly others from the import list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names of people you have worked with goes here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2pt\">\n",
    "<hr style=\"height:2pt\">\n",
    "\n",
    "<div class='theme'>Linear Algebra, Accuracy, and Confidence Intervals </div>\n",
    "In this part of the homework, you will see how _uncertainty_ in the beta coefficients can directly impact our ability to make predictions with a linear regression model and how in general we can do inference on the predictors. You will explore a linear-algebra formula that tells us how accurately we've learned the beta parameters, going beyond simple SEs to describe the joint distribution of the betas. You'll see that the structure of the $X$ data can strongly impact how well we can learn the betas, and you'll determine desirable prroperties of the $X$ data.\n",
    "\n",
    "The data for this supplement are the same as in lab1, and are imported for you in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazda RX4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda RX4 Wag</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datsun 710</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hornet 4 Drive</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hornet Sportabout</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "   carb  \n",
       "0     4  \n",
       "1     4  \n",
       "2     1  \n",
       "3     1  \n",
       "4     2  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv(\"data/cleaned_mtcars.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['mpg']].values\n",
    "X = df[['cyl','disp','hp','wt','qsec']]\n",
    "\n",
    "\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 5 [4 pts] </b> </div>\n",
    "\n",
    "**5.1** Fit a simple linear regression model predicting `mpg` via `disp`. Use the `FittedOLS.get_prediction().summary_frame()` method to access the confidence intervals for our prediction at various values of `disp` and make a well-labeled plot showing\n",
    " 1. The observed values of `disp` and `mpg`.\n",
    " 2. The regression line.\n",
    " 3. The upper and lower bounds of the 95% confidence interval for the _mean/predicted_ (not the observed) `mpg` at any given displacement.\n",
    " \n",
    "**5.2** Why do we have a confidence interval for our predicted value? Why isn't the prediction just a single number?\n",
    "\n",
    "**5.3** Someone asks what `mpg` you would predict for a `disp` value of 400. What do you tell them? paying attention to the confidence interval (5.1.3) above?\n",
    "\n",
    "**5.4** Why does the 95% confidence interval for the predicted `mpg` appear to curve as we move away from the data's center? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1 Fit a linear regression model predicting `mpg` via `disp`. Use the `FittedOLS.get_prediction().summary_frame()` method to access the confidence intervals for our prediction at various levels of `disp` and make a well-labled plot showing**\n",
    " 1. **The observed values of weight and mpg**\n",
    " 2. **The regression line**\n",
    " 3. **The upper and lower bounds of the 95% confidence interval for the_mean/predicted_ (not the observed) `mpg`at any given displacement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAElCAYAAADp4+XfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119068b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here \n",
    "x_var = 'disp'\n",
    "\n",
    "# fit a simple linear regression predicting mpg via weight\n",
    "simple_model = sm.OLS(y, X[['const',x_var]]).fit()\n",
    "simple_model.summary()\n",
    "\n",
    "\n",
    "x_vals = np.linspace(X[x_var].min(),X[x_var].max(),500)\n",
    "line_y_vals = simple_model.predict(sm.add_constant(x_vals))\n",
    "\n",
    "prediction_int = simple_model.get_prediction(sm.add_constant(x_vals)).summary_frame()\n",
    "\n",
    "plt.scatter(X[x_var],y)\n",
    "plt.plot(x_vals,line_y_vals,c='r', label=\"Regression Line\")\n",
    "plt.plot(x_vals,prediction_int['mean_ci_upper'],c='orange',label=\"95% Confidence Interval (mean)\")\n",
    "plt.plot(x_vals,prediction_int['mean_ci_lower'],c='orange',label=\"\")\n",
    "#plt.plot(x_vals,prediction_int['obs_ci_upper'],c='g',label=\"95% Prediciton Interval (future obs)\")\n",
    "#plt.plot(x_vals,prediction_int['obs_ci_lower'],c='g', label=\"\")\n",
    "plt.xlabel(\"Engine Displacement\")\n",
    "plt.ylabel(\"Observed Miles Per Gallon\")\n",
    "plt.title(\"Effect of Engine Displacement on Gas Mileage\\n(Observed Data and Predictive model)\")\n",
    "plt.legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2 Why do we have a confidience interval for our predicted value? Why isn't the prediction just a single number?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "The regression line predicts mean `mpg` at each value of `disp` (for instance we think the average `mpg` of all cars with `disp`=250 will be 20 miles per gallon). However, we don't perfectly know what the average `mpg` is at each `disp` value, and if we re-collected the data and re-ran our model our prediction might be higher or lower. The bounds above give a reasonable estimate of where the true average `mpg` might be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3 Someone asks what `mpg` you would predict for a `disp` value of 400. What do you tell them, paying attention to the confidence interval (5.1.3) above?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval data for disp=400:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.113807</td>\n",
       "      <td>0.983136</td>\n",
       "      <td>11.105976</td>\n",
       "      <td>15.121638</td>\n",
       "      <td>6.176537</td>\n",
       "      <td>20.051077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0  13.113807  0.983136      11.105976      15.121638      6.176537   \n",
       "\n",
       "   obs_ci_upper  \n",
       "0     20.051077  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "print(\"Confidence interval data for disp=400:\")\n",
    "simple_model.get_prediction([1,400]).summary_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "We should tell them:\n",
    "1. My best single estimate is that the car will get 13.11 miles per gallon.\n",
    "2. However, I'm not completely certain in that value. Based on the data, the optimal prediciton could reasonably be anywhere between 11.1 and 15.12.\n",
    "3. The range of _actual_ `mpg` ratings we see could reasonably be as low as 6.17 or as high as 20.05. The range quoted above is only describing what I think the _average_ `mpg` of cars with a `disp` of 400 might be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.4 Why does the 95% confidence interval for the predicted `mpg` appear to curve as we move away from the data's center?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "All regression lines (with an intercept) must pass through the average value of the data-- if the predictor is at its mean, guess the mean of the response. However, suppose we move 10 units away from the mean, and our uncertainty in the slope is +/-.2 mpg/disp. The lower bound at 10 units would be -2 units and the upper bound would be +2 units. If we moved 20 units instead, the same error in the slope gives bounds at +/- 4 units. The farther out we move, the wider our bounds have to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Question 6 [8 pts] </b></div>\n",
    "Hopefully, in the question above you recognized that uncertainty in the beta coefficients could impact the certainty of our predictions. In this question and the next, we're going to explore properties of the data that can make us more or less certain of the values of the betas.\n",
    "\n",
    "**6.1** Fit a multiple linear regression to the full X matrix (on the car data). That is, predict `mpg` using `cyl`,`disp`,`hp`,`wt`, and `qsec`.\n",
    "\n",
    "**6.2** The formula for the covariance of the vector of betas, assuming the linear regression model holds, is:\n",
    "$${\\rm Cov}(\\beta) = \\sigma^2\\left(X^TX\\right)^{-1}.$$\n",
    "Compute and display this matrix for the car data. \n",
    "\n",
    "**6.3** Verify that the SE reported by statsmodels matches the square root of the variance listed for that variable in your calculated covariance matrix.\n",
    "\n",
    "**6.4** Interpret the matrix formula above. At a minimum, discuss what affects our ability to estimate the betas accurately. When would you expect two betas to have large/small covariances? [This is intended as an open-ended question. You will be graded only on the specified minimum].\n",
    "\n",
    "**Hint**: we don't know $\\sigma^2$, but we can estimate them.<BR>\n",
    "**Hint**: remember that numpy's normal distribution expects a standard deviation and not a variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.1 Fit a multiple linear regression to the full X matrix (on the car data). That is, predict `mpg` using `cyl`,`disp`,`hp`,`wt`, and `qsec`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   29.51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 18 Sep 2018</td> <th>  Prob (F-statistic):</th> <td>6.18e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:41:02</td>     <th>  Log-Likelihood:    </th> <td> -72.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   156.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    26</td>      <th>  BIC:               </th> <td>   164.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   35.8736</td> <td>    9.918</td> <td>    3.617</td> <td> 0.001</td> <td>   15.487</td> <td>   56.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cyl</th>   <td>   -1.1561</td> <td>    0.715</td> <td>   -1.616</td> <td> 0.118</td> <td>   -2.626</td> <td>    0.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>disp</th>  <td>    0.0119</td> <td>    0.012</td> <td>    1.004</td> <td> 0.325</td> <td>   -0.013</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hp</th>    <td>   -0.0158</td> <td>    0.015</td> <td>   -1.037</td> <td> 0.309</td> <td>   -0.047</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wt</th>    <td>   -4.2253</td> <td>    1.252</td> <td>   -3.374</td> <td> 0.002</td> <td>   -6.800</td> <td>   -1.651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qsec</th>  <td>    0.2538</td> <td>    0.487</td> <td>    0.521</td> <td> 0.607</td> <td>   -0.748</td> <td>    1.256</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.925</td> <th>  Durbin-Watson:     </th> <td>   1.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.085</td> <th>  Jarque-Bera (JB):  </th> <td>   3.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.782</td> <th>  Prob(JB):          </th> <td>   0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.453</td> <th>  Cond. No.          </th> <td>6.73e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.73e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.850\n",
       "Model:                            OLS   Adj. R-squared:                  0.821\n",
       "Method:                 Least Squares   F-statistic:                     29.51\n",
       "Date:                Tue, 18 Sep 2018   Prob (F-statistic):           6.18e-10\n",
       "Time:                        14:41:02   Log-Likelihood:                -72.003\n",
       "No. Observations:                  32   AIC:                             156.0\n",
       "Df Residuals:                      26   BIC:                             164.8\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         35.8736      9.918      3.617      0.001      15.487      56.261\n",
       "cyl           -1.1561      0.715     -1.616      0.118      -2.626       0.314\n",
       "disp           0.0119      0.012      1.004      0.325      -0.013       0.036\n",
       "hp            -0.0158      0.015     -1.037      0.309      -0.047       0.016\n",
       "wt            -4.2253      1.252     -3.374      0.002      -6.800      -1.651\n",
       "qsec           0.2538      0.487      0.521      0.607      -0.748       1.256\n",
       "==============================================================================\n",
       "Omnibus:                        4.925   Durbin-Watson:                   1.682\n",
       "Prob(Omnibus):                  0.085   Jarque-Bera (JB):                3.534\n",
       "Skew:                           0.782   Prob(JB):                        0.171\n",
       "Kurtosis:                       3.453   Cond. No.                     6.73e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.73e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "fitted_model = sm.OLS(y, X).fit()\n",
    "fitted_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.2 The formula for the covariance of the vector of betas, assuming the linear regression model holds, is:\n",
    "$${\\rm Cov}(\\beta) = \\sigma^2\\left(X^TX\\right)^{-1}.$$\n",
    "Compute and display this matrix for the car data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>98.368517</td>\n",
       "      <td>-3.780794</td>\n",
       "      <td>0.018899</td>\n",
       "      <td>-0.083821</td>\n",
       "      <td>4.959981</td>\n",
       "      <td>-4.638669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyl</th>\n",
       "      <td>-3.780794</td>\n",
       "      <td>0.511577</td>\n",
       "      <td>-0.004108</td>\n",
       "      <td>-0.001251</td>\n",
       "      <td>-0.169858</td>\n",
       "      <td>0.128479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disp</th>\n",
       "      <td>0.018899</td>\n",
       "      <td>-0.004108</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.008850</td>\n",
       "      <td>0.000328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hp</th>\n",
       "      <td>-0.083821</td>\n",
       "      <td>-0.001251</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>0.004399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wt</th>\n",
       "      <td>4.959981</td>\n",
       "      <td>-0.169858</td>\n",
       "      <td>-0.008850</td>\n",
       "      <td>-0.004826</td>\n",
       "      <td>1.568470</td>\n",
       "      <td>-0.347664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qsec</th>\n",
       "      <td>-4.638669</td>\n",
       "      <td>0.128479</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>-0.347664</td>\n",
       "      <td>0.237618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           const       cyl      disp        hp        wt      qsec\n",
       "const  98.368517 -3.780794  0.018899 -0.083821  4.959981 -4.638669\n",
       "cyl    -3.780794  0.511577 -0.004108 -0.001251 -0.169858  0.128479\n",
       "disp    0.018899 -0.004108  0.000142 -0.000024 -0.008850  0.000328\n",
       "hp     -0.083821 -0.001251 -0.000024  0.000233 -0.004826  0.004399\n",
       "wt      4.959981 -0.169858 -0.008850 -0.004826  1.568470 -0.347664\n",
       "qsec   -4.638669  0.128479  0.000328  0.004399 -0.347664  0.237618"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "def get_beta_cov_mat(X,y):\n",
    "    fitted_model = sm.OLS(y,X).fit()\n",
    "    \n",
    "    sse = np.sum((y.reshape(1,-1)-fitted_model.predict(X).values)**2)\n",
    "    sigma_est = sse/(X.shape[0]-X.shape[1])\n",
    "\n",
    "    var_cov = sigma_est*np.linalg.inv(np.dot(X.T,X))\n",
    "    return pd.DataFrame(var_cov, columns=X.columns.values, index=X.columns.values)\n",
    "\n",
    "beta_cov_mat = get_beta_cov_mat(X,y)\n",
    "beta_cov_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.3 Verify that the SE reported by statsmodels matches the square root of the variance listed for that variable in your calculated covariance matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEs from matrix: [9.91809038 0.71524643 0.01190742 0.01526723 1.25238578 0.48746086]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "print(\"SEs from matrix:\",np.sqrt(np.diag(beta_cov_mat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "Horray, they match the SEs in the summary table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.4 Interpret the matrix formula above. At a minimum, discuss what affects our ability to accurately estimate the betas. When would you expect two betas to have large/small covariances? [This is intended as an open-ended question. You will only be graded on the specified minimum].**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "The formula has a constant multiplier of $\\sigma^2$, the irreducible noise in the data-generating process, so whenever the noise goes up, all our estimates get less accurate. \n",
    "\n",
    "Beyond that, the formula uses the inverse of the $X^TX$, so our knowledge of the betas will be tied to the correlation structure / similarity of the features. We might (wrongly) expect that a large similarity between two features would create a small covariance in their betas, since this formula uses the inverse of the $X^TX$ similarity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 7 [12 pts]: What affects our knowledge of the betas? </b></div> \n",
    "\n",
    "\n",
    "**7.1** Create a separate dataset `edit1` with a new column `noise` that is totally independent of the other columns (random values from an exponential distribution). Using the formula for the covariance of the betas, what effects do you see on our ability to estimate the betas?\n",
    "\n",
    "**7.2** Create a separate dataset `edit2` with a new column `ratio` that is the ratio of a car's horsepower to its weight. Using the formula for the covariance of the betas, what change do you see in our certainty about weight's effect on mpg?\n",
    "\n",
    "**7.3** Create a separate dataset `edit3` with a new column `combo` that is horsepower+displacement+weight+ Normal(0,.01) noise. Using the formula for the covariance of the betas, how well can we estimate the betas for this dataset, and which ones are correlated?\n",
    "\n",
    "**7.4** If you could choose the different features in your data (either because you're running a lab experiment manipulating the X values, or by deciding which columns to measure/keep), how would you like your features to relate? Specifically, how can you get as good an estimate of the betas as possible?\n",
    "\n",
    "**Hint**: Should introducing pure noise give us meaningfully more accurate beta values? <br>\n",
    "**Hint**: What happens if $X^TX$ is diagonal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Answers\n",
    "\n",
    "**7.1  Create a separate dataset `edit1` with a new column `noise` that is totally independent of the other columns (random values from an exponential distribution) ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes in accuracy:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>17.932429</td>\n",
       "      <td>-0.552929</td>\n",
       "      <td>-0.003721</td>\n",
       "      <td>0.013561</td>\n",
       "      <td>-0.400964</td>\n",
       "      <td>-0.644033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyl</th>\n",
       "      <td>-0.552929</td>\n",
       "      <td>0.018022</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>0.012273</td>\n",
       "      <td>0.019750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disp</th>\n",
       "      <td>-0.003721</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hp</th>\n",
       "      <td>0.013561</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>-0.000481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wt</th>\n",
       "      <td>-0.400964</td>\n",
       "      <td>0.012273</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qsec</th>\n",
       "      <td>-0.644033</td>\n",
       "      <td>0.019750</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>-0.000481</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.023212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           const       cyl      disp        hp        wt      qsec\n",
       "const  17.932429 -0.552929 -0.003721  0.013561 -0.400964 -0.644033\n",
       "cyl    -0.552929  0.018022  0.000105 -0.000427  0.012273  0.019750\n",
       "disp   -0.003721  0.000105  0.000001 -0.000003  0.000065  0.000136\n",
       "hp      0.013561 -0.000427 -0.000003  0.000011 -0.000335 -0.000481\n",
       "wt     -0.400964  0.012273  0.000065 -0.000335  0.013795  0.013889\n",
       "qsec   -0.644033  0.019750  0.000136 -0.000481  0.013889  0.023212"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "edit1 = X.copy()\n",
    "edit1['noise'] = np.random.exponential(10,size=X.shape[0])\n",
    "\n",
    "print(\"Changes in accuracy:\")\n",
    "pd.DataFrame(get_beta_cov_mat(edit1,y).values[:-1,:-1] - get_beta_cov_mat(X,y).values, columns=X.columns.values, index=X.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.2 Create a separate dataset `edit2` with a new column `ratio` that is the ratio of a car's horsepower to its weight ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes in accuracy:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>69.777665</td>\n",
       "      <td>-1.382871</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>0.306407</td>\n",
       "      <td>-13.255780</td>\n",
       "      <td>-1.061523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyl</th>\n",
       "      <td>-1.382871</td>\n",
       "      <td>0.042240</td>\n",
       "      <td>-0.000418</td>\n",
       "      <td>-0.005864</td>\n",
       "      <td>0.246347</td>\n",
       "      <td>0.021476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disp</th>\n",
       "      <td>0.014894</td>\n",
       "      <td>-0.000418</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>-0.003211</td>\n",
       "      <td>-0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hp</th>\n",
       "      <td>0.306407</td>\n",
       "      <td>-0.005864</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>-0.063054</td>\n",
       "      <td>-0.004004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wt</th>\n",
       "      <td>-13.255780</td>\n",
       "      <td>0.246347</td>\n",
       "      <td>-0.003211</td>\n",
       "      <td>-0.063054</td>\n",
       "      <td>2.787984</td>\n",
       "      <td>0.168079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qsec</th>\n",
       "      <td>-1.061523</td>\n",
       "      <td>0.021476</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>-0.004004</td>\n",
       "      <td>0.168079</td>\n",
       "      <td>0.020750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           const       cyl      disp        hp         wt      qsec\n",
       "const  69.777665 -1.382871  0.014894  0.306407 -13.255780 -1.061523\n",
       "cyl    -1.382871  0.042240 -0.000418 -0.005864   0.246347  0.021476\n",
       "disp    0.014894 -0.000418  0.000008  0.000066  -0.003211 -0.000179\n",
       "hp      0.306407 -0.005864  0.000066  0.001457  -0.063054 -0.004004\n",
       "wt    -13.255780  0.246347 -0.003211 -0.063054   2.787984  0.168079\n",
       "qsec   -1.061523  0.021476 -0.000179 -0.004004   0.168079  0.020750"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "edit2 = X.copy()\n",
    "edit2['ratio'] = edit2['hp']/edit2['wt']\n",
    "\n",
    "print(\"Changes in accuracy:\")\n",
    "pd.DataFrame(get_beta_cov_mat(edit2,y).values[:-1,:-1] - get_beta_cov_mat(X,y).values, columns=X.columns.values, index=X.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.3 Create a separate dataset `edit3` with a new column `combo` that is horsepower+displacement+weight+ Normal(0,.01) noise... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes in accuracy:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-11.061934</td>\n",
       "      <td>0.361917</td>\n",
       "      <td>-21.007017</td>\n",
       "      <td>-20.996628</td>\n",
       "      <td>-21.686745</td>\n",
       "      <td>0.536395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyl</th>\n",
       "      <td>0.361917</td>\n",
       "      <td>-0.039400</td>\n",
       "      <td>5.559511</td>\n",
       "      <td>5.559567</td>\n",
       "      <td>5.607744</td>\n",
       "      <td>-0.015230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disp</th>\n",
       "      <td>-21.007017</td>\n",
       "      <td>5.559511</td>\n",
       "      <td>1578.040949</td>\n",
       "      <td>1578.150271</td>\n",
       "      <td>1586.308986</td>\n",
       "      <td>-0.118299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hp</th>\n",
       "      <td>-20.996628</td>\n",
       "      <td>5.559567</td>\n",
       "      <td>1578.150271</td>\n",
       "      <td>1578.259550</td>\n",
       "      <td>1586.418397</td>\n",
       "      <td>-0.118777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wt</th>\n",
       "      <td>-21.686745</td>\n",
       "      <td>5.607744</td>\n",
       "      <td>1586.308986</td>\n",
       "      <td>1586.418397</td>\n",
       "      <td>1594.437436</td>\n",
       "      <td>-0.078797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qsec</th>\n",
       "      <td>0.536395</td>\n",
       "      <td>-0.015230</td>\n",
       "      <td>-0.118299</td>\n",
       "      <td>-0.118777</td>\n",
       "      <td>-0.078797</td>\n",
       "      <td>-0.027388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           const       cyl         disp           hp           wt      qsec\n",
       "const -11.061934  0.361917   -21.007017   -20.996628   -21.686745  0.536395\n",
       "cyl     0.361917 -0.039400     5.559511     5.559567     5.607744 -0.015230\n",
       "disp  -21.007017  5.559511  1578.040949  1578.150271  1586.308986 -0.118299\n",
       "hp    -20.996628  5.559567  1578.150271  1578.259550  1586.418397 -0.118777\n",
       "wt    -21.686745  5.607744  1586.308986  1586.418397  1594.437436 -0.078797\n",
       "qsec    0.536395 -0.015230    -0.118299    -0.118777    -0.078797 -0.027388"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "edit3 = X.copy()\n",
    "edit3['combo'] = edit3['hp']+edit3['wt']+edit3['disp'] +np.random.normal(0,.01,size=X.shape[0])\n",
    "\n",
    "print(\"Changes in accuracy:\")\n",
    "pd.DataFrame(get_beta_cov_mat(edit3,y).values[:-1,:-1] - get_beta_cov_mat(X,y).values, columns=X.columns.values, index=X.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.4 If you could choose the different features in your data (either because you're running a lab experiment manipulating the X values, ... **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "There's nothing we can do about the $\\sigma^2$ term, but we'd like it to be small. (We'd also like a pony).\n",
    "\n",
    "The rest of the game is making the terms in the inverse matrix as small as possible. First, let's make the covariances/correlations of the features zero (so that all off-diagonal entries of $(X^TX)$ are zero). That makes the $X^TX$ matrix diagonal, which makes the inverse easy to calculate: we just invert each entry on the diagonal. Therefore we want to make the diagonal entries as large as possible, which means making each feature as 'long' as possible. That is, we'd prefer each feature to cover a wide range of values.\n",
    "\n",
    "Intuitively, we'd like to collect data about low displacements, high displacements, and everything in between, and we'd like for all other features to not be confounded with displacement. We'd like for each new feature included in the model to be measuring something completely different than what the existing features capture (otherwise we won't know which feature to assign the effect to).\n",
    "\n",
    "Finally, we'd like for the included features to actually predict the response. We could include a bunch of uncorrelated noise terms and get very accurate measures of the beta values, but the actual betas would be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
