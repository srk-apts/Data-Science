{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS-109A Introduction to Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 10:  Neural Networks using `keras` \n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2018**<br/>\n",
    "**Instructors:** Pavlos Protopapas and Kevin Rader<br/>\n",
    "**Lab Instructor:** Eleni Kaxiras<br/>\n",
    "**Authors:** David Sondak, Eleni Kaxiras, and Pavlos Protopapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! python -m pip install --upgrade pip --user\n",
    "# ! pip install tensorflow\n",
    "# ! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN THIS CELL TO GET THE RIGHT FORMATTING \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get\\\n",
    "    (\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomy of an Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous lab we created our own neural network by writing some simple python functions.  We focused on a regression problem where we tried to learn a function. We practiced using the logistic activation function in a network with multiple nodes, but a single or two hidden layers.  Some of the key observations were:\n",
    "* Increasing the number of nodes allows us to represent more complicated functions  \n",
    "* The weights and biases have a very big impact on the solution\n",
    "* Finding the \"correct\" weights and biases is really hard to do manually\n",
    "* There must be a better method for determining the weights and biases automatically\n",
    "\n",
    "We also didn't assess the effects of different activation functions or different network depths. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 3 parts of an ANN\n",
    "\n",
    "- **Part 1: the input layer** (dimentions are determined from our dataset)\n",
    "- **Part 2: the internal architecture or hidden layers** (the number of layers, the activation functions, the learnable parameters and other hyperparameters)\n",
    "- **Part 3: the output layer** (what we want from the network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word about .npy files\n",
    "\n",
    "Numpy arrays are faster than plain python lists, as we know. Numpy also offers a file format called .npy, which, when it comes to reading the same data multiple times from disk storage, is a lot faster than reading from a csv file. You can save any list or array into this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('123', np.array([[1, 2, 3], [4, 5, 6]]))\n",
    "hello = np.load('123.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Keras` Basics ![](figs/keras.png)\n",
    "https://keras.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning computations can be quite demanding. TensorFlow is a framework for representing complicated ML algorithms and executing them in any platform, from a phone to a distributed system using GPUs. Developed by Google Brain, TensorFlow is used very broadly today. \n",
    "\n",
    "**[`keras`](https://keras.io/)**, is a high-level API used for fast prototyping, advanced research, and production. We will use `tf.keras` which is TensorFlow's implementation of the `keras` API.\n",
    "\n",
    "### Models are assemblies of layers\n",
    "\n",
    "The core data structure of Keras is a **model**, a way to organize layers. A model is understood as a sequence or a graph of standalone, fully-configurable modules that can be plugged together with as few restrictions as possible. In particular, neural layers, cost functions, optimizers, initialization schemes, activation functions, regularization schemes are all standalone modules that you can combine to create new models.\n",
    "\n",
    "The simplest type of model is the **Sequential** model, a linear stack of layers. For more complex architectures, one can use the Keras **Functional** API, which allows to build arbitrary graphs of layers.\n",
    "\n",
    "https://keras.io/models/model/\n",
    "\n",
    "Everything you need to know about the Sequential model is here: https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Installation\n",
    "\n",
    "If you haven't already, install `Keras` using the instructions found at [https://keras.io/#installation](https://keras.io/#installation)\n",
    "\n",
    "Choose the TensorFlow installation instructions (found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/) )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Approximating a Gaussian using keras\n",
    "Let's try to redo the problem from last week.  Recall that we had a function\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f\\left(x\\right) = e^{-x^{2}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "and we wanted to use a neural network to approximate that function.  This week, we will use `keras` to do the true optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary `keras` modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 5076864472248868278)]\n"
     ]
    }
   ],
   "source": [
    "# Checking if our machine has GPUs. Mine does not..\n",
    "with tf.Session() as sess:\n",
    "    devices = sess.list_devices()\n",
    "    print(devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, we need to create some **data**.  We will generate data points from an underlying function (here the Guassian).  Then we will use the `sklearn` `train_test_split` method to split the dataset into training and testing portions.  Remember that we train a machine learning algorithm on the training set and then assess the algorithm's performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_samples = 1050 # set the number of samples to take for each dataset\n",
    "test_size = 0.3 # set the proportion of data to hold out for testing\n",
    "\n",
    "# define the function and add noise\n",
    "\n",
    "def f_gauss(x):\n",
    "    return np.exp(-x * x) + np.random.normal(loc=0, scale=.1, size = x.shape[0])\n",
    "\n",
    "X = np.random.permutation(np.linspace(-10, 10, n_samples)) # choose some points from the function\n",
    "Y = f_gauss(X)\n",
    "\n",
    "# create training and testing data from this set of points\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x16ff48df60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a keras network\n",
    "\n",
    "Now we will create a neural network model with keras. We're going to use a single layer and just 2 neurons in that layer. We will start with the sigmoid activation function. We also choose a linear output layer since we are doing regression. The loss function is selected to be the **mean squared error (MSE)**. In addition to these choices we must also specify our initial weights as well as the optimization method that will be used to minimize the loss function. The keras interface has many choises as to those hyperparameters.\n",
    "\n",
    "**Part 1:** First we start by defining the number of nodes in a layer and the input dimensions. If we have more than one layer we might need to define a value for the number of nodes (H) for each layer.\n",
    "\n",
    "`H = \n",
    "input_dim =`\n",
    "\n",
    "Then we instantiate the model\n",
    "\n",
    "`model = models.Sequential() `\n",
    "\n",
    "**Part 2:** Then we add the hidden layers. Adding layers and stacking them is done using `.add()`\n",
    "\n",
    "`model.add(layers.Dense(H, input_dim=input_dim,  \n",
    "                activation='sigmoid')) `\n",
    "\n",
    "**An alternative way** \n",
    "\n",
    "`model = Sequential([\n",
    "    Dense(200, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(4, activation='linear')\n",
    "])`\n",
    "\n",
    "**Part 3:** We end with the final layer (output)\n",
    "\n",
    "`model.add(layers.Dense(1, \n",
    "                activation='linear')) `\n",
    "                \n",
    "Our model is not ready yet. We need to configure its learning process with .compile():\n",
    "\n",
    "`model.compile(loss='mean_squared_error', optimizer='sgd')`\n",
    "\n",
    "If you need to, you can further configure your optimizer. A core principle of Keras is to make things reasonably simple, while allowing the user to be fully in control when they need to (the ultimate control being the easy extensibility of the source code)\n",
    "\n",
    "`model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01))`\n",
    "              \n",
    "Our model is now ready to use. We haven't trained it yet, but we'll do that now using the fit method. Notice that we also need to specify the batch size for the stochastic gradient decent algorithm as well as the number of epochs to run.\n",
    "\n",
    "`model.fit(X_train, Y_train, batch_size=100, epochs=100)#, verbose=1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 1:</b> </div>\n",
    "\n",
    "Build a NN with one hidden layer with **2 neurons**. Use the `tanh` activation function. Train the model using the X_train dataset from above (train the model in this case means run `.compile` and `.fit`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "H = 2\n",
    "input_dim = 1\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(H, input_dim=input_dim, \n",
    "                      activation='tanh'))\n",
    "model.add(layers.Dense(1, kernel_initializer='normal', \n",
    "                activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=100, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "735/735 [==============================] - 0s 423us/step - loss: 0.0695\n",
      "Epoch 2/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0681\n",
      "Epoch 3/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0668\n",
      "Epoch 4/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0658\n",
      "Epoch 5/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0650\n",
      "Epoch 6/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0643\n",
      "Epoch 7/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0636\n",
      "Epoch 8/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0632\n",
      "Epoch 9/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0628\n",
      "Epoch 10/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0624\n",
      "Epoch 11/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0620\n",
      "Epoch 12/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0618\n",
      "Epoch 13/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0615\n",
      "Epoch 14/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0613\n",
      "Epoch 15/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0610\n",
      "Epoch 16/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0608\n",
      "Epoch 17/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0605\n",
      "Epoch 18/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0603\n",
      "Epoch 19/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0600\n",
      "Epoch 20/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0597\n",
      "Epoch 21/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0593\n",
      "Epoch 22/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0589\n",
      "Epoch 23/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0585\n",
      "Epoch 24/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0581\n",
      "Epoch 25/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0576\n",
      "Epoch 26/100\n",
      "735/735 [==============================] - 0s 49us/step - loss: 0.0571\n",
      "Epoch 27/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0565\n",
      "Epoch 28/100\n",
      "735/735 [==============================] - 0s 44us/step - loss: 0.0560\n",
      "Epoch 29/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0553\n",
      "Epoch 30/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0547\n",
      "Epoch 31/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0540\n",
      "Epoch 32/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0533\n",
      "Epoch 33/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0525\n",
      "Epoch 34/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0517\n",
      "Epoch 35/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0508\n",
      "Epoch 36/100\n",
      "735/735 [==============================] - 0s 44us/step - loss: 0.0500\n",
      "Epoch 37/100\n",
      "735/735 [==============================] - 0s 49us/step - loss: 0.0491\n",
      "Epoch 38/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0481\n",
      "Epoch 39/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0471\n",
      "Epoch 40/100\n",
      "735/735 [==============================] - 0s 44us/step - loss: 0.0462\n",
      "Epoch 41/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0452\n",
      "Epoch 42/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0442\n",
      "Epoch 43/100\n",
      "735/735 [==============================] - 0s 44us/step - loss: 0.0432\n",
      "Epoch 44/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0422\n",
      "Epoch 45/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0412\n",
      "Epoch 46/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0402\n",
      "Epoch 47/100\n",
      "735/735 [==============================] - 0s 38us/step - loss: 0.0391\n",
      "Epoch 48/100\n",
      "735/735 [==============================] - 0s 33us/step - loss: 0.0381\n",
      "Epoch 49/100\n",
      "735/735 [==============================] - 0s 27us/step - loss: 0.0371\n",
      "Epoch 50/100\n",
      "735/735 [==============================] - 0s 27us/step - loss: 0.0361\n",
      "Epoch 51/100\n",
      "735/735 [==============================] - 0s 27us/step - loss: 0.0352\n",
      "Epoch 52/100\n",
      "735/735 [==============================] - 0s 27us/step - loss: 0.0343\n",
      "Epoch 53/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0333\n",
      "Epoch 54/100\n",
      "735/735 [==============================] - 0s 5us/step - loss: 0.0325\n",
      "Epoch 55/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0316\n",
      "Epoch 56/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0308\n",
      "Epoch 57/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0300\n",
      "Epoch 58/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0292\n",
      "Epoch 59/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0284\n",
      "Epoch 60/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0277\n",
      "Epoch 61/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0269\n",
      "Epoch 62/100\n",
      "735/735 [==============================] - 0s 5us/step - loss: 0.0262\n",
      "Epoch 63/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0255\n",
      "Epoch 64/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0249\n",
      "Epoch 65/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0242\n",
      "Epoch 66/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0236\n",
      "Epoch 67/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0230\n",
      "Epoch 68/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0225\n",
      "Epoch 69/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0220\n",
      "Epoch 70/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0214\n",
      "Epoch 71/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0209\n",
      "Epoch 72/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0204\n",
      "Epoch 73/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0200\n",
      "Epoch 74/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0195\n",
      "Epoch 75/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0190\n",
      "Epoch 76/100\n",
      "735/735 [==============================] - 0s 22us/step - loss: 0.0186\n",
      "Epoch 77/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0182\n",
      "Epoch 78/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0178\n",
      "Epoch 79/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0175\n",
      "Epoch 80/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0171\n",
      "Epoch 81/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0168\n",
      "Epoch 82/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0164\n",
      "Epoch 83/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0161\n",
      "Epoch 84/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0158\n",
      "Epoch 85/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0155\n",
      "Epoch 86/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0152\n",
      "Epoch 87/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0150\n",
      "Epoch 88/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0147\n",
      "Epoch 89/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0145\n",
      "Epoch 90/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0142\n",
      "Epoch 91/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0141\n",
      "Epoch 92/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0138\n",
      "Epoch 93/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0136\n",
      "Epoch 94/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0135\n",
      "Epoch 95/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0133\n",
      "Epoch 96/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0131\n",
      "Epoch 97/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0129\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735/735 [==============================] - 0s 16us/step - loss: 0.0128\n",
      "Epoch 99/100\n",
      "735/735 [==============================] - 0s 11us/step - loss: 0.0126\n",
      "Epoch 100/100\n",
      "735/735 [==============================] - 0s 16us/step - loss: 0.0125\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/NN_1_layer_2_nodes.py\n",
    "H = 2 # number of nodes in the layer\n",
    "input_dim = 1 # input dimension: just x\n",
    "\n",
    "model = models.Sequential() # create sequential multi-layer perceptron\n",
    "\n",
    "# our first hidden layer\n",
    "model.add(layers.Dense(H, input_dim=input_dim, \n",
    "                activation='tanh')) \n",
    "# layer 1\n",
    "model.add(layers.Dense(1, kernel_initializer='normal', \n",
    "                activation='linear')) \n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# fit the model\n",
    "model_history = model.fit(X_train, Y_train, batch_size=100, epochs=100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  We've trained a model.  Now it's time to explore the results.  Notice the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants for our plots\n",
    "FIG_SIZE = (10,5)\n",
    "FONT_SIZE = 10\n",
    "LABEL_SIZE = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our model to predict in the range we want\n",
    "X_range = np.linspace(-10, 10, 1000)\n",
    "y_pred = model.predict(X_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnsAAAFWCAYAAAAR7lviAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3Xd4VGXa+PHvTQgQEAhSFIJUBaQnRBSRjkTEEkFXWWXFhuvaSxRfXSmrK7u4lnXdV33Xgi4/URAjiIhUERQ1ECKC9KIERERCS5CU5/fHmZnMmUxLMpOcJPfnunIl5znPOeeZmvs8VYwxKKWUUkqp6qlWZRdAKaWUUkpFjwZ7SimllFLVmAZ7SimllFLVmAZ7SimllFLVmAZ7SimllFLVmAZ7SimllFLVmAZ7SgUgIpNFxIjIIj/75ojICq/twa68v4jIaT557xKRiM5xJCLtXNe7zCvtYREZ7CevEZG7ynCNs0XkFRHJEpFC78cb4rjxrmueFjp31SIiLUVkuus5OS4iP4rIDBFp5YCyRfx9FuA6VfL1Lcfn4E0RyYhGmZSqKBrsKRXaCBE5L8y8TYE7olkYl/1AP2CVV9rDwOAIXqMbcCmw1fWjoA9wFfAOcDmQBpwPfFHVgp9yWID13sut7IIopcJTu7ILoJTD/QrsBR4DUsPIvwJ4UEReNMacjFahjDG/AWuidX6X+caYD8GqyQSaRfl6USEisUCRMaYwAqdbBXQxxhR4nX8dsAUYA8yIwDUczRhzEDhY2eWoqUQkzhiTV9nlUFWL1uwpFZwB/gpcISI9wsj/d6AJcGu4FxCReiLym4j83ivtaVez0xVeaS+KyGrX37ZmXBHZjVWrOMmVbnyadGNE5K8iclBEfhaRl0SkbrByGWOKwn0MYTzGaSKywdX0uVdEZorImV77p4vIThERn+NuEpFTItLMtV1LRCaKyHbXc7ZVRG70OWaFq5l9gojsAE4CrUSktYi853r8eSKyQ0T+UprHYYzJ8Q70XGlbsWq5WoR4Dtzl+r2r/EdFZKGItPbJ18zVNHxIRHJdxyX75KkrIv8SkRwR+VVEngNi/VzzdFdT/AEROSkiX4jI+T55bhGRja7n5BcR+UxEugV5HLZmXK/34u9c1zrieo2niEjI/zEicqWIZLjK95OI/N0VoLv3dxGRWa4m81xXWe/zPbeINHVdf7/rXFtE5D6fy5X6c+CnvC1F5HXX+zXP9R58UkTqeOX5RkTe8HPsDLFuDtzb4bw+RkQeEJHnReQgsKE05VUKNNhTKhyzsZoxHwsj74/AW8DD3v+wgnHVAH4DDPBKHogVpPimfR7gNFcBR4DXsJrY+gHrvPY/CLQCbgCmA7cD94ZTvghpgRU0jwLuAzoAy0QkxrX/P0B7YJDPceOxahh/cW2/CDwOvOo61wfA6+LVd9GlP1Zz+iNYza1HsF6Xs4AJwEjgKaBU/+j9EZGeQH1gUxjZzwfuwno9JgBJrsfiLR1IAR4CrsX6nl4uImd75ZmGdUPxF+B6oK3rnN7lqgssAS7Gam5OxaqRW+IOtEVkIPAy8F+s5+Rm4AugcRiPxdffgePA1a7zPeH6OyAR+R0wF/gauAKYgvW8PO2VLQGr5vRPWN0K/s+V7xGv88Rh1aqnYj0nlwL/wHrPe4vE56AZVo3/A8AlrvPchPXedPsPcI14Ne27/h4DvOHaDvn6eEkDWgLjgHtKWV6lwBijP/qjP35+gMnAL66/xwOFQCfX9hxghVfewVi1gN2BjkABcItr313WRy3otZ4GvnP9XQ/4DfgXsMaVFu+6/ijXdjvX9S7zOscvwGQ/5zbASp+0dPe5w3wubI83RN7xrmueFmB/DNY/cAMM9EpfBczw2u4AFLkfI3C2a/tGn/O9BXzjtb0CyAPO9Ml3HLg8wu+RWsByrJuB2BB5V2AFnU280u5zPQ9xru1LXNuDvPI0wAoCXnFtN3U9vkd8yrHZ+30G3AKcAs7xSqsN7ACmu7YfAtaW8jHbXl+v9+JbPvnWA7OCnEeAPcAbPuk3ux5f0wDH1Ab+B9jplX67673RO8j1yvQ5AN4EMoLsrw38HuvmrI4rrRFwArjJ53H95n5c4bw+XuXOjOT7Vn9q3o/W7CkVnv8CPwCPhspojNkBzAImetVchfI50FVETgcuwPpH8b9AkojUBy5y5Vtd2oK7fOqzvQlo7S9jNIjISFcT1RGsQHiva1cnr2yvAWO8akPGAweAT1zbw7D+oX8gIrXdP8BSoLfPc73WGPOTTzHWA0+7miHbROihPY1VizrOGJMfRv5vjDGHvbbdtYEJrt99gYPGmM/cGYwxJ4CPKH4P9MC6IfjQK0+R97bLcGAtsMvruQL4DHA3C68HEkXkOREZ6N0UWQalfY91AtoA7/m8nsuwHl938HRzmCIi27GCpXysWtn2Xo9pKFZAtD7CZSxBLPeJyCYRyXOVZyZWLXEbAGPMUawbpPFeh44H5hljDrm2w3l93BaUpoxK+dJgT6kwGKuf1t+BG0SkbRiH/BWrhu/aMC+xGusO/iKspttVxpiNWDVBF7jSvjPG5JS27C6+x53C+ocadWKNZJ6HFeCNwwqOLnDt9i7De1jB3O9ERIA/YNUWufvINcOqFTyC9Q/W/fMmVo1IS69zHfBTlGuBDOA5YI+IrBeRYeV4XH/Cal670RjzVZiH+XsdoPh5aIn/sh8ATnf97W7i+9knj+92M6znOd/n5yas5myMMUtc2wOxah5/EZF/i0iD8B6OTWnfY+4BPx/7lG+XK/0s1++/YdVAvorVPHse8KRrn/v8TbFGqEe6jP7ch9VE/AFwJVaAfqdPecC6eRkgIh1FpCPWZ/h1r/0hXx8v/t4TSoVNR+MqFb7XsfqLPRIqozFmk4h8gNXc9EoY+Y+IyLdY/xB6A+65/Va50oL113O6q7CaIa81xlhtcX4CZmPMCRGZhVUDsgerH9qbXll+xaoV7I8VFPryDnZKzDdnjMkGxrs69vfFaqafJyJtvGpbwiIiY7D6aD1sjHm3NMeGsB//Az3OwHr8AO4ayxZeae5tb79iBbf+pgL6zf2HMWYGMENEmgOjsYLho8DE0ha+lNxlnwBk+tnvDvquAV40xvzdvUNERvnkPYTVzF8RrgFmG2M8fXhFpKtvJmPMShHZBtyI1fy8D3vNYlivj/t05S20qtk02FMqTMaY30TkGaymu7VYd+HBPIk1SOKqMC/xOTAE6ELxYJCVWP9c+gDPhzi+wmrrSikOyHcHei7XB8j7GtaUMpOx+lJ977VvGVbNXmNjzOKyFsbV5LlGRKZgDUZoixUshEWsUc4zgX8ZY54pazkC+AqYIiIDjTErXderT/FgFLBGY57EqlXa7MpTy7XtbSkwAvjBGONb61eCsaZUeUVERgMlgpco2AJkA+2MMf8XJF8cXsGPq7n+Op88S7EGRPQ0xnwb8ZIGKY9LoPfz61gDS8Cqpfae/qdUr49S5aHBnlKl8wpWbd2FWH1rAjLGZIrIQqxRjuFYCdyNNZDAPZL2c+BZ19+r/B3kZTMwSkQ+cZ1jizHmWJjXLsEVZFzq2kwAGomIe3Tlx8aYcCfVXQzcJyLPA/Oxnrsb/GU0xnwlIhuxmrNv99m3RUReBmaJyN+xakXqYU3+3MkYE3C6GxFpjFVb+hbWYIq6WCMzfwK+d+UZjDXYYogxZkWA85yL1al/M/CuiFzgtfugq79mmRljFok1vc67IjIRKwh9CCvAmO7Kc0hEXsUKCguAjcBtgO+kzm8BfwRWuG5SdmI1d/YFfjLGPOcKeE/H1YQLJGKNiI52rR7GmCIReRB4W0QaAQuxblg6YI1Mvdr1HlsM3Onqs/crVpOp7yjqt1zpn4rIZKxAsj3W+yLSj2UxcI+IfIU1mOJ6AtcqzsC66auNvZbaXeagr0+Ey61qMA32lCoFY0yuWHOaPRXmIU8SfrDnbqb90qufWiZwDGtUcHaI49OAl7A6c9fHqiVcEea1/WmBNe2MN/d2e2B3OCcxxnwsIo9gBbK3AV8ClxF4VY50rH/4s/zsu9N13G3AVKzmxk1YNYLBnMSqEbsXqz9ULlYN4ghTPEFtfdfvYLUs52NNS9KLkoNlZmDvkF9WV2H1CXseK5j9GhhqjNnuledhrHn1nsBq0v4v1k3BP9wZjDEnRWQI1vM0Basp+GfX+ea5sn0D3I9VU9YQq/l8MvBCBB5HSMaYd0XkKNYN1M1YI853Yg1IcfdnvBtrepiXsEbpzsCq5XzV6zwnRWQo1pQ0U7FGw+4G/h2FYk8FmlPcb3Au1nQo830zGmN+cgWFGGO2+OwL5/VRKiLE3rKilFKVS0S+xqqVHFfB152CNRXMkIq8rqq+XKPrs4G7jDGhbkiUihqt2VNKOYJYq0QMxRpteWeI7NFwIcVN5kqVmYg0xOr3eC9Wzfw7lVsiVdNpsKeUcopvsKbGeNQY801FX9wYc3FFX1NVW32w+n/uAf5Qiv6tSkWFNuMqpZRSSlVjOqmyUkoppVQ1psGeUkoppVQ1pn32vDRr1sy0a9eusouhlFJKKRXS2rVrfzHGNA+VT4M9L+3atSMjI6Oyi6GUUkopFZKI7AknnzbjKqWUUkpVYxrsKaWUUkpVYxrsKaWUUkpVY9pnTymlFPn5+ezdu5eTJ09WdlGUUj7q1atH69atiY2NLdPxGuwppZRi7969NGzYkHbt2iEilV0cpZSLMYZDhw6xd+9e2rdvX6ZzaDOuUkopTp48SdOmTTXQU8phRISmTZuWq9Zdgz2llFIAGugp5VDl/WxqsKeUUsoRRIRx48Z5tgsKCmjevDmXXXYZAG+++SZ33XVXiePatWtHjx496NWrFyNGjOCnn34q9bWfeOIJlixZAsDzzz9Pbm6uZ99pp51W6vNFSrt27fjll19KpM+bN49p06b5PSZQecePH8+cOXPKXabdu3fTvXv3cp+nIvl7HnNzcxk1ahRdunShW7duTJw4MSrXnjx5Ms8880xUzh0uDfaUUko5QoMGDfjuu+/Iy8sDYPHixSQkJIR17PLly8nKyiI5OZm//vWvpb721KlTGT58OFAy2HOiK664ImrBSWUrLCyssGs99NBDbN68mczMTFavXs3ChQsr7NoVSYM9pZSqAOmZ2fSftoz2ExfQf9oy0jOzK7tIjjRy5EgWLFgAwDvvvMPYsWNLdfzAgQPZvn27Le3rr79m9OjRAHz44YfExcVx6tQpTp48SYcOHYDiWq9//vOf7Nu3jyFDhjBkyBDPOR577DF69erFBRdcwIEDB0pc99dffyU1NZWePXtywQUX8O233wJWrc7NN9/M4MGD6dChA//85z89x/z3v/+lb9++9O7dm9tvvz1gkPPiiy+SlJREjx492Lx5M2Cv5dy1axf9+vXjvPPO489//rPnOGMMd911F127dmXUqFH8/PPPnn1r165l0KBB9OnTh5SUFPbv3w/A4MGDeeSRR+jbty+dOnXi888/D/p87969mwEDBpCUlERSUhJffPEFAOPGjePDDz/05Lv++uuZN28ehYWFpKWlcd5559GzZ09eeeUVAFasWMGQIUP4/e9/T48ePUpc54477iA5OZlu3boxadIkT3q7du2YNGlSiefn0KFDjBgxgsTERG6//XaMMSXOWb9+fc9rXKdOHZKSkti7d2+JfMFew2effZbu3bvTvXt3nn/+eU/6U089RefOnRk+fDhbtmzxpO/YsYNLLrmEPn36MGDAAE95Z8+eTffu3enVqxcDBw4M+pyXiTFGf1w/ffr0MUopFWkfrNtrujy+0LR95CPPT5fHF5oP1u2t7KJ5bNq0yfoDovsTRIMGDUxWVpYZM2aMycvLM7169TLLly83o0aNMsYY88Ybb5g777yzxHFt27Y1Bw8eNMYYc+edd5qHH37Ytj8/P9+0a9fOGGPMgw8+aJKTk82qVavMihUrzHXXXWeMMebGG280s2fPLnE+6ynBzJs3zxhjTFpamvnLX/5Sogx33XWXmTx5sjHGmKVLl5pevXoZY4yZNGmS6devnzl58qQ5ePCgOf30082pU6fMpk2bzGWXXWZOnTpljDHmjjvuMDNmzPD72P75z38aY4x56aWXzC233FLiubj88ss9x/7rX/8yDRo0MMYY8/7775vhw4ebgoICk52dbRo3bmxmz55tTp06Zfr162d+/vlnY4wxs2bNMjfddJMxxphBgwaZBx54wBhjzIIFC8ywYcNKlGnXrl2mW7duxhhjTpw4YfLy8owxxmzdutW4/4+uWLHCXHnllcYYY3Jycky7du1Mfn6+eeWVVzzP38mTJ02fPn3Mzp07zfLly039+vXNzp07S1zPGGMOHTpkjDGmoKDADBo0yGRlZQV9fu6++24zZcoUY4wxH330kQFsr6mvw4cPm/bt25sdO3aU2BfoNczIyDDdu3c3x48fN8eOHTNdu3Y169at86SfOHHCHDlyxHTs2NFMnz7dGGPM0KFDzdatW40xxqxZs8YMGTLEGGNM9+7dzd69ez1l8cfzGfUCZJgw4hudekUppaJs+qIt5OXba23y8guZvmgLqYnhNVPWFD179mT37t288847XHrppWEfN2TIEGJiYujZsydPPvmkbV/t2rU5++yz+f777/n666954IEHWLlyJYWFhQwYMCDkuevUqePpN9inTx8WL15cIs+qVat4//33ARg6dCiHDh3iyJEjAIwaNYq6detSt25dWrRowYEDB1i6dClr167lvPPOAyAvL48WLVr4vb67VrJPnz7MnTu3xP7Vq1d7rj1u3DgeeeQRAFauXMnYsWOJiYmhVatWDB06FIAtW7bw3XffcfHFFwNWs2nLli39Xm/37t1Bn5v8/Hzuuusu1q9fT0xMDFu3bgVg0KBB3Hnnnfz888/MnTuXMWPGULt2bT799FO+/fZbT9/BI0eOsG3bNurUqUPfvn0DTi3y3nvv8eqrr1JQUMD+/fvZtGkTPXv2DPj8rFy50vP3qFGjaNKkScDHUFBQwNixY7nnnns8Nb2+/L2Gq1at4qqrrqJBgwaecnz++ecUFRVx1VVXUb9+fcBqcgc4fvw4X3zxBddcc43nvL/99hsA/fv3Z/z48fzud7/zPJ5I0mBPKaWibF9OXqnSa7orrriChx56iBUrVnDo0KGwjlm+fDnNmjULuH/AgAEsXLiQ2NhYhg8fzvjx4yksLAyr43xsbKxnNGRMTAwFBQUl8hg/zYTuY+rWretJcx9vjOHGG2/k6aefDnl99/GBru19rXDSjTF069aNL7/8sszXc3vuuec444wzyMrKoqioiHr16nn2jRs3jpkzZzJr1ixef/11z7VffPFFUlJSbOdZsWKFJ2jytWvXLp555hm++eYbmjRpwvjx423TkAQqb7gjWCdMmMA555zDfffdFzBPoNcwEH/XLioqIj4+nvXr15fY9/LLL/PVV1+xYMECevfuzfr162natGlY5Q+H9tlTSqkoaxUfV6r0mu7mm2/miSee8Nt3q6wGDhzI888/T79+/WjevDmHDh1i8+bNdOvWrUTehg0bcuzYsVKff+bMmYAVuDRr1oxGjRoFzD9s2DDmzJnj6Uf366+/smfPnlJd061///7MmjULwFMGd5lmzZpFYWEh+/fvZ/ny5QB07tyZgwcPeoK9/Px8Nm7cWKZrHzlyhJYtW1KrVi3efvttW7/D8ePHe/qxuZ/nlJQU/vd//5f8/HwAtm7dyokTJ4Je4+jRozRo0IDGjRtz4MCBsAZReL8eCxcu5PDhw37zPf744xw5csTW3y5cAwcOJD09ndzcXE6cOMEHH3zAgAEDGDhwIB988AF5eXkcO3aM+fPnA9CoUSPat2/P7NmzASvwzcrKAqy+fOeffz5Tp06lWbNm/Pjjj6UuTzBas6eUUlGWltKZR+dusDXlxsXGkJbSuRJLFUCQ2oqK0rp1a+69916/+958803S09M922vWrAnrnOeffz4HDhzwdH7v2bMnLVq08FsDM2HCBEaOHEnLli09AVIokydP5qabbqJnz57Ur1+fGTNmBM3ftWtXnnzySUaMGEFRURGxsbG89NJLtG3bNqzreXvhhRf4/e9/zwsvvMCYMWM86VdddRXLli2jR48edOrUiUGDBgFWs/ScOXO45557OHLkCAUFBdx3331+A99Q/vSnPzFmzBhmz57NkCFDbLVzZ5xxBueeey6pqametFtvvZXdu3eTlJSEMYbmzZvbXk9/evXqRWJiIt26daNDhw70798/ZLkmTZrE2LFjSUpKYtCgQbRp06ZEnr179/LUU0/RpUsXkpKSALjrrru49dZbw3rsSUlJjB8/nr59+3oeW2JiIgDXXnstvXv3pm3btrauAjNnzuSOO+7gySefJD8/n+uuu45evXqRlpbGtm3bMMYwbNgwevXqFVYZwiXBqiFrmuTkZJORkVHZxVBKVUPpmdlMX7SFfTl5tIqPIy2ls6P6633//fece+65lV0MVY3k5ubSo0cP1q1bR+PGjSu7OFWev8+oiKw1xiSHOlZr9pRSKkqcHuApFS1Llizh5ptv5oEHHtBAzwE02FNKqShIz8y2Nd1m5+Tx6NwNABrwqWpv+PDh/PDDD5VdDOWiAzSUUioKgk23opRSFUmDPaWUigKdbkUp5RQa7CmlVBTE14/1m67TrSilKpoGe0opFWHpmdkcyc33u29Il+YVXBqlVE3n2GBPRM4WkVdEJEtECkVkRZjHNRaRN0TksIgcEZGZIhK5aaiVUiqI9MxsHnwvi6IA+5dvPlih5akqDh06RO/evenduzdnnnkmCQkJnu1Tp06FdY6bbrrJtui8Py+99JJt4uFIWbJkiW0+OX/WrVvHJ598EvFrKxWKk0fjdgMuBdYAdUpx3LtAZ+BWoAj4G5AOhF4AUSmlysE9ArcwyPylgfrs1fRpWpo2bepZRmry5MmcdtppPPTQQ7Y87kXda9XyX0/xxhtvhLzOnXfeWf7CltG6dev47rvvuOSSSyqtDKpmcmzNHjDfGHOWMeYaIKx1XESkH5AC3GiMed8Y8wFwA3CRiAyPYlmVUsrvCFxf/vrsuYPE7Jw8DMXTtKRnZkeppOWXnplN/2nLaD9xAf2nLYtaWbdv30737t354x//SFJSEvv372fChAkkJyfTrVs3pk6d6sl70UUXsX79egoKCoiPj2fixIn06tWLfv36eZYle/zxxz1LY1100UVMnDiRvn370rlzZ7744gsATpw4wZgxY+jVqxdjx44lOTnZ73qmCxYsoHPnzlx00UV8+OGHnvQ1a9bQr18/EhMT6d+/P9u2bSMvL4+pU6cyc+ZMevfuzZw5c/zmUyoaHBvsGWMCtYIEMxI4YIxZ6XWer4Fdrn1KKRU14Yy0PfFbQYnAqKpN01LRwemmTZu45ZZbyMzMJCEhgWnTppGRkUFWVhaLFy9m06ZNJY45cuQIgwYNIisri379+vH666/7Pbcxhq+//prp06d7AscXX3yRM888k6ysLCZOnEhmZmaJ43Jzc7n99tv5+OOP+fzzz9m3b59n37nnnsuqVavIzMzkz3/+M48//jhxcXE88cQTXH/99axfv56rr77abz6losHJzbhl0QXY7Cf9e9c+pZSKKO/m11oiQZtwAXLy8ktMrlzVpmkJFpxGo+m5Y8eOnHfeeZ7td955h9dee42CggL27dvHpk2b6Nq1q+2YuLg4Ro607vH79OnD559/7vfco0eP9uTZvXs3AKtWreKRRx4BrHVZ/a0Zu2nTJjp16kTHjh0BuP7663nrrbcAyMnJ4Q9/+AM7duwI+rjCzadUeTm2Zq+MmgA5ftIPu/YppVTE+NZwhQr03Hxr7QJNx+LUaVoqOjht0KCB5+9t27bxwgsvsGzZMr799lsuueQSTp48WeKYOnWKu3rHxMRQUFDg99x169YtkSfcNeNFxG/6Y489RkpKCt999x3p6el+y1eafEqVV3UL9gD8fUolQDoiMkFEMkQk4+BBHSWnlApfOH30AsnOyfP0ecs9VUBsLXvgEBcbQ1pK50gUM+IqMzg9evQoDRs2pFGjRuzfv59FixZF/BoXXXQR7733HgAbNmzw20zctWtXtm7dyq5duzDG8M4773j2HTlyhIQEq4bzzTff9KQ3bNiQY8eOhcynVKRVt2DvMBDvJz0e/zV+GGNeNcYkG2OSmzfX+a+UUuHLLmdNlrtG8HBuPgjEx8UiQEJ8HE+P7uHY0bhpKZ2Ji42xpVVUcJqUlETXrl3p3r07t912G/3794/4Ne6++26ys7Pp2bMn//jHP+jevTuNGze25alfvz4vv/wyI0eOZMCAAXTo0MGz75FHHiEtLa1E2YYOHUpWVhaJiYnMmTMnYD6lIk3Cra6uTCIyB2hmjBkcIt9U4DZjTEuf9B1AujHmwWDHJycnm4yMjPIWVylVQ3R89OOwm27DkRAfx+qJQyN2vtL4/vvvOffcc8POX52niikoKKCgoIB69eqxbds2RowYwbZt26hdu7p1c1dVib/PqIisNcYkhzq2ur1zFwJ/FpGLjDGrAEQkGejg2qeUUhETyUAPnDsgw5/UxIRqE9z5On78OMOGDaOgoABjDK+88ooGeqpKc+y7V0TqY02qDJAANBKRq13bHxtjckVkO/CZMeYWAGPMlyKyCHhLRB6ieFLlVcaYJRX8EJRS1VxCfFzQptzYGCG/MPyA0KkDMmqa+Ph41q5dW9nFUCpinNxnrwUw2/VzAdDVa7uFK09tIMbnuOuAz4DXgbeAtcBVFVBepVQN46/vmnuYRUJ8HA3qhH8/7eQBGUqpqs2xNXvGmN0Uf28GytPOT1oOcJPrRymlosbdjBmo71r7iQvCOk+T+rFMurxbpTeLGmMCTieilKo85R1f4dhgTymlqoJgfddaBWjmjRGhyBhHDWyoV68ehw4domnTphrwKeUgxhgOHTpEvXr1ynwODfaUUqqcAo1MTUvpzKNzN9jm4ouLjXHktCqtW7dm79696HyjSjlPvXr1aN26dZmP12BPKaXKwB3gZefk2WZtd68TC6GbeZ0kNjaW9u3bV3YxlFJRUCXm2asoOs+eUioc7mXSgq2e0aR+LJlPjKjAUimlapqaOs+Tcy5dAAAgAElEQVSeUkpFlL8m2nCWSTucm0+7iQvKPfiiOk9erJSqGBrsKaVUAL41eO4m2tKsh3s4N5+0OVkApQ7SAl2/LOdSStVcTp5nTymlKpW/Gry8/EJiSjlaNb/QMH3RlohdvyznUkrVXBrsKaVUAIGWLys0psRkymU9V1mOqUrLqimlKp8Ge0opFUCg5csS4uN4enQPEkqxvFlZlkILdIwuq6aUKg0N9pRSKgB/y6G5lzVLTUxg9cSh7J42iuev7U392MBfp7ExUqal0IJdXymlwqXBnlJKBZCamMCYPgmePnoxIozp43/FDBNgdccm9WOZfnWvMg2oSE1M8NQgCsU1ijo4QylVGjoaVymlAkjPzOb9tdkUuuYjLTSG99dmk9z2dFvAFWgqloT4OFZPHFquMgRbjk0ppcKhNXtKKRVAuKNhAw2YyM7Jo/+0ZbSfuID+05aRnpkdtbIqpVQgGuwppVQA4Y6GDTRgQrACPkPxHHka8CmlKpoGe0opFUC4o2H9DaTwXi/XTefIU0pVBg32lFIqgEBBnLt51l1L528gRaBVx3WOPKVURdMBGkopFYB7YMT0RVvIzsmz1db5Ll3mO5Ci/7RlZPsJ7HxrBXXtW6VUtGnNnlJKBeGeT89fbV2wZtlw5shzr32r/fqUUtGkwZ5SSoUh2Ihbf8FZOHPk6dq3SqmKoM24SikVhlbxcX6bZQHue3c9U+ZvZNLl3WzBXKg58nTtW6VURdCaPaWUCoO/Zllvh3PzS90Eq2vfKqUqgtbsKaVUGNw1dPe9uz5gHncTbLDaPO8BGXF+1tPVtW+VUpGmNXtKKVUK/lfALRasCdZ3QEZufpGfXIb7312vK24opSLGscGeiHQVkaUikisi+0RkqogEbkMpPi5ZRD4VkUMi8quILBGR8yuizEqp6is9M5sH38sKOH+eW7Am2EBr6HrLyy/SkblKqYhyZLAnIk2AJVhTWl0JTAUeBKaEOO4s13G1gT8A41x/fyoibaNZZqVU9eWukSs0wUO9UE2wpR14oSNzlVKR4NQ+e38E4oDRxpijwGIRaQRMFpG/u9L8GQU0dB2XAyAiXwC/AJcC/xv9oiulqptwauQSwpgQOdiI3kB0ZK5SqrwcWbMHjAQW+QR1s7ACwEFBjosFCoDjXmnHXWmhutoopZRfwQKuuNgYnr+2N6snDg258kWoEb3+6MhcpVR5OTXY6wJs9k4wxvwA5Lr2BfK+K88/RKSFiLQAngMOA7OjVFalVDUXLOCq52dEbSC+Ey03qR9LfFys5+/YWvZ7UgGGdGletkIrpZSLU5txmwA5ftIPu/b5ZYzZJyJDgI+Ae1zJ+4EUY8zBiJdSKVUjpKV05tG5G/w25brn1wPCWtM22ETLj6dvYOaaHzyDQAzw/tpsktueruvlKqXKzKk1e4DfQW8SIN3aKdISmAOsxWoKHun6e4GItAlwzAQRyRCRjIMHNR5USpXkXSPnT6QGUizffLBU6+8qpVQ4nBrsHQbi/aQ3xn+Nn1saVm3l1caYT4wxnwBjgELgIX8HGGNeNcYkG2OSmzfX5hKllH+piQmsnjg0YOffSAyk0OXTlFLR4NRgbzM+ffNc06o0wKcvn48uwEZjTL47wRhzCtgIdIxCOZVSNUw0lzjT5dOUUtHg1GBvIZAiIg290q4F8oDPghy3B+guInXcCSJSF+gO7I5COZVSNYy/EbWRWuIsmudWStVcTh2g8TLWAIu5IvI3oAMwGXjWezoWEdkOfGaMucWV9B/gVuADEfk3Vh+/O4GWwKsVV3ylVHXlHijhXt+2VRjz6wXjvVZuq/g4xvRJYPnmgxE5t1JKgUODPWPMYREZBvwLmI/VT+85rIDPW20gxuu4tSJyCTAJeNuVvAG42BiTFe1yK6VqhmAjakvDvTKHe5Rvdk4e76/N5unRPTTAU0pFjCODPQBjzCZgaIg87fykLQWWRqlYSikVMf5W5vAefRup2kOlVM3m2GBPKaWqu0CjbLNz8krU+JVmLj+llPLm1AEaSilV7QUbZRusxk8ppUpDgz2llIqGI0dg+XKYNw8yMqCw5OobpV0rV+fbU0qVhTbjKqVUJP3wA/z5z/DOO5CfX5zeogU89BDccw/UrQvYR/ZmhxHI6Xx7Sqmy0Jo9pZSKlHnzoGdPeOste6AH8PPP8PDD0L8//PijJznUyhxuOt+eUqqsNNhTSqlImDULRo+2mm+DWbsWBgywagC9BKu1S4iP0+lYlFJlpsGeUkqFKT0zm/7TltF+4gL6T1tGema2tWPNGrjxxpL98tq3h5QUaNjQnr5nD1xyCRw75kkKtHrG89f2ZvXEoRroKaXKTIM9pZQKg3sC5OycPAzF06EsXLIexoyBU6eKM9eqBc8+C9u3wyefwK5dcMUV9hN+/z3cdptnMzUxgadH9yAhPg5Ba/OUUpEjxpjKLoNjJCcnm4yMjMouhlLKgfpPW+Z3EMVrHz/DsA0r7In//S9cf709raAAxo6FOXPs6XPnwlVXRbawSqkaQUTWGmOSQ+XTmj2llAqDv2lPBu/4pmSg9/DDJQM9gNq1YcYM6NXLnn7XXbZ+fgGbipVSqow02FNKqTD4DqCoU5DPXxa/bM/Upw889VTgk9SvD2+/bQV+bvv2wZNPAoGbijXgU0qVhwZ7SikVBt8BFNdlfcJZRw4UZ6hVC1591R7I+dOjh1X75+1f/4Ls7JBr5SqlVFlosKeUUi7BmlC9B1DE5Z/knq9m2w++4w5ISgrvQo8/DgleAy9OnoS//CXgChm6coZSqjw02FNKKcJrQnVPgPx9wh6aHfu1+OC4OCuAC1dcHDzxhD3ttddI5Kjf7LpyhlKqPDTYU0opCNiEet+76+21fPn58Pzz9oPvuQfOPLN0F7zpJujYsXi7oIC/7fvM71x7unKGUqo8NNhTSimCN5XaavnmzLEtd0ZcnLXmbWnFxsIjj9iSzkn/f0y/uK3OtaeUiqgQPYmVUqpmaBUf53cePbe8/EKmf7KZ1LnP2nfceCM0a1a2i44bZzX//vyztX3sGJdlLOSyiQ+U7XxKKeWH1uwppRT+lyvz1fz7LPCdeP3++8t+0Xr14M477WmvvAI62b1SKoI02FNKKYpH28bHxQbMM37LMnvCqFHQqVP5LnzHHVaTrtvWrbBqVfnOqZRSXjTYU0opl9TEBBrU9d+7pcGpPEZ9t8KeOGFC+S/avDmkptrT/vOfEtl0ZQ2lVFlpsKeUUl4CDdS4dPMqYnNPFCe0bAmXXhqZi956q3179mzIyfFs6soaSqny0GBPKaW8xNf334w7btMSe8L48aFXywjX8OHQtm3xdl4ezJzp2dSVNZRS5aHBnlJKuaRnZnP8ZEGJ9HNy9tFzz0Z74s03R+7CtWqVPN/bb3v+1JU1lFLlocGeUkq5TF+0hfyikiNhU7f6DJgYOBDOPjuyFx8/3r791VewaxcQeAUNXVlDKRUOxwZ7ItJVRJaKSK6I7BORqSISfF6E4mNHi8g3IpInIodE5BMRaRDtMiulqja/NWXGMOLb5fa066+P/MXbtIGLLrKnzZoF+J8WRlfWUEqFy5HBnog0AZYABrgSmAo8CEwJ49hbgf8HLARGArcC29AJpJVSIfirKev8yx7OOeS1Ykbt2jB6dHQKcN119u133gGKp4XRlTWUUmXh1ADoj0AcMNoYcxRYLCKNgMki8ndXWgki0gx4DrjbGPN/Xrs+iHqJlVJVXlpKZx6du8E2GOKy7z+3Zxo+vOwrZoRyzTVw771Q6Lr+hg2MuOXfnDinC2kpnVk9cWh0rquUqtYcWbOHVSO3yCeom4UVAA4KctzvXL9nRKtgSqnqy12D1sQ9ItcYLv9+pS3P2n4p0StAixYwbJgt6fLvV+pUK0qpcnFqsNcF2OydYIz5Ach17QvkfGALcIuI7BWRfBH5SkQujF5RlVLVSWpiAvXrWI0ePX7aTruc/Z59v8XU5r6TbQMdGhk+Tbkjt6wGdKoVpVTZOTXYawLk+Ek/7NoXyJlAZ+Bx4BHgcuAE8ImInOHvABGZICIZIpJx8ODB8pVaKVUtuAdqXLbZ3oT7WYdkfiyqE92Lp6aSX6t4MMbZv+6lo6vPoE61opQqC6cGe2ANzvAlAdLdagGnAbcYY2YaYz4BUoFC4C6/FzHmVWNMsjEmuXnz5uUts1KqGmgVHwfGcMnWL2zpH3UZEP2LN2nC+g69bEkXb/sKsL78dKk0pVRpOTXYOwzE+0lvjP8aP7dfXb9XuBNc/f7WAl0jVTilVPWVnplN7qkCOv2yh7Y5P3nSf4upzdKO5xEf53+FjUiqc/UY2/aIbV96/tb+e0qp0nLqaNzN+PTNE5GzgAb49OXz8T3Wza/4pAtQFMkCKqWqh/TMbKYv2sK+nDwax8Vy4lQB+YWG37tq09y+aNuLE3Xr00SsY6I57UmvO/8A0x7zbCft20KLY4f4uWFToLj/nk69opQKh1Nr9hYCKSLS0CvtWiAP+CzIcR9hBXZD3Aki0hjoA2RFoZxKqSosPTObR+duIDsnDwPk5OWTX2j1FBmxbY0t7+JzLgDgcG5+9GvWWreG886zJV283R58av89pVS4nBrsvQz8BswVkeEiMgGYDDzrPR2LiGwXkdfc28aYDOBD4DURuVFERgHzgHzgpYp8AEop55u+aIttTj23M479Qq+fttnSFp99vufvChkZe9VVtk3f4FOXSlNKhcuRwZ4x5jAwDIgB5mOtnPEcMMkna21XHm83AOnAs8AcrEBvqOucSinlEah27OLtX9u2M1t25uBpp4d1bMSkpto2++35loa/nQCs5ovsnDwdrKGUCotT++xhjNkEBJ0u3hjTzk/aceAO149SSgXUKj6ObD9B24itX9q2F59zfok8Ua9ZO/dc6NwZtlg1iHWKChi4cx0Lzh3gmZLAPVgD0P57SqmAHFmzp5RSFSEtpTNxsfbGgSb5efT7cYMt7bOu/W3bcbExpKV0jnr5uOIK2+aQnRklsuhky0qpUDTYU0rVWO7l0RLi4xAgIT6OV848RGxhQXGmc87httsuteV5enSPiqlJu/RS2+agnWsRU3JiAR2soZQKxrHNuEopVRFSExPsgdstM+0ZLruM1KTWpCa1rtiCAfTvDw0bwrFjADTPzaH7TzvY0PIcWzYdrKGUCkZr9pRSys0YWLjQnuZTu1ahYmNhxAhbkm9TrkDFNCkrpaosDfaUUsotKwv27y/ebtAABlTAEmnBjBpl2xy64xvP3wJcf0EbHZyhlApKm3GVUjWeexWNKxfO4GHvHcOGQd26lVUsyyWX2DZ7/rSNZidyqJvQkrSUzhroKaVC0mBPKVWjuVfRyMsvZLDvaNeRIyunUN5atoSkJFi3DoBaxpDRtwjGBZ2ZSimlPLQZVylVo7lX0Wh08jhJ2T5Lb1dysJeemU3/act4sa59QMbiZ96g/cQFOqmyUiosGuwppWo097QlA3ZlUttrWpOtTdtA27aVVSzbur3LOybb9p239RtqFRV6JlXWgE8pFYwGe0qpGs09bcngnWtt6RldL6iM4nh4r9u7vmUnfo1r5NkXf/I4vfdZEynrpMpKqVA02FNK1WhpKZ2pX1sYtMse7LW5fkwllcjiPVFyUa0YPmufZNvvPSpXJ1VWSgWjwZ5SqkZLTUzgzibHaHHisCftt3r1ueim1EosVcmJkn2bcr3n29NJlZVSwWiwp5Sq0dIzs8n/6GNb2udte5G+8WAllcjiu27vyvZJFErxV3bXn3fR4tihilunVylVZWmwp5Sq0aYv2kL/bfYpV5a261Pp/eDc6/bGiACQE9eILJ9l0lIPbKi4dXqVUlWWBntKqRrtxP6fSdpnn3JlRYc+ZOfkVfoo19TEBP7xu16eGr4VHexNuf8juzXQU0qFpMGeUqpGu+LgRmK8plzZ3Kwt+xs1B3DEtCbuGr6E+DhW+gzSYPFiKCionIIppaoMDfaUUjXarcftzbUrOvTx/O2UaU1SExNYPXEo6W/eB82aFe84coQ/3fmvSg9IlVLOpsGeUqrmKiqizVef2ZJW+Ix6ddS0JrVq8eN5A2xJ3b79whE1kEop59JgTylVo7iXIGs/cQE33/sq/PyzZ9+xOnFkJHS15XfatCavN+xi2x68cy15+YXc9+562/Jp3o9Tl1VTqmarXdkFUEqpiuJegsy9MkXXrNW2/V92SKIgpvhr0YnTmnx4Rnf+jFALA0C3n3fS/PivHDztdM/yaRl7fuX9tdmex+lOB3RAh1I1kNbsKaVqDO8lyACG7LBPudL8mitJiI9DgIT4OEdOaxLX6ky+9ZmCxXupt7z8Qt756kfb43SnO6H/oVKq4mnNnlKqxvDufxefd5Te+7fa9idOGMvq1q0rulilkpbSmZULkm1lH7RzLbN7XuzZLjTG77GO6n+olKowWrOnlKoxvPvfDdyVaZtyhZ49weGBHljNsF93Od+WNmB3JjFFxTV57omYfTmt/6FSqmKEDPZE5IaKKIif63YVkaUikisi+0RkqojEhD7Sc3wtEVkrIkZELotmWZVSVYP3EmSDd9qbcLn00kooUdl82aQdv8Y18mw3/u0Eia6JoQWrZs833HNi/0OlVMUIp2ZvnIi8UJpAq7xEpAmwBDDAlcBU4EFgSilOcyvgrM42SqlK5Z6guHWjugzy6ucGwMiRlVOoMjjz9NNY2T7Rlubut+duwDXgCfic2v9QKVUxwgn2LgHygGUi0iLK5XH7IxAHjDbGLDbGvIwV6D0gIo2CH+oJFp8CHotuMZVSVU1qYgKrhjeiad7R4sTGjaFfv8orVCmlpXTmi3P62tIG+wavWAFfQnwcqycO1UBPqRosZLBnLBOBF4CVIjJBRPqKSP0olmsksMgY4/VtzCysAHBQGMf/BVgNLI1C2ZRSVdzm12bZtrP7DoDY2EoqTemlJiYw+J4bKPLqm9f9wA6aHz9cIq8OylBKhTVAw9Xn7VbgFJAEPAP8KCLbo1SuLoBtZXJjzA9ArmtfQCLSE7gJeChKZVNKVWHpmdn89tHHtrSX6p5T5SYdvnRoT2ol21f7GLSrZO2eDspQSoUzQGMncAfwnDGmpzHmj8aYgcaYpsDgKJWrCZDjJ/2wa18wLwIvGWOiFYgqpaqw/3v/K3rss0+5srhtYtWcg86nn+Gw3ets2zooQykF4dXsXWqMGWWMWey7wxizNwpl8pzeT5oESLd2ilwHdAaeDPcirmbpDBHJOHjwYOlLqZSqUjplfeFZfQJgwxkdOXja6VWzudM32PsxizYN6zh6UmilVMULOamyMWZzqDxRcBiI95PeGP81fohILDAd+BtQS0TiAfdgjgYi0tAYc8z3OGPMq8CrAMnJyQEDSaVU9TDyx0zb9ooOVlNolWzuPO88aNoUDh0CoM6xI6wcXB/6XxziQKVUTeLUSZU349M3T0TOAhrg05fPSwOgNfAsVrB4GMhy7ZsFZAY4TilVUxQWctEOe7+25a5gLyf3VJXrt0dMDIwYYU9buLByyqKUciynBnsLgRQRaeiVdi3WFDCfBTjmODDE52esa9//ANdHp6hKqcqWnplN/2nLaD9xAf2nLQsctH39NfWPH/Fs5tQ7jfWtOgFw4lQhj87dUPUCPt/5ATXYU0r5cGqw9zLwGzBXRIaLyARgMvCs93QsIrJdRF4DMMYUGGNWeP8Aa1xZNxhjvqrYh6CUqgjpmdk8OncD2Tl5GCA7Jy9w0PaxfRTuyvZJFNUqni8+L7+w6g3USEmxb69bBz/9VDllUUo5kiODPWPMYWAYEAPMx5pQ+Tlgkk/W2q48SqkaavqiLeTlF9rSAgZtPsGeuwnXW5UbqNGiBfhMwbL21Vnh1XQqpWqEkAM0KosxZhMwNESediH274YSS0QqpaqRQMFZifS9e61aL5cihJXtk0ocVyUHaowcCRnFa/0eePcDsi8/Byiu6QR0ZK5SNZQja/aUUipcgYKzEunz59s2N7TuwqEG9kH/VWleOu9+ihMONrftu3DnOmKKims7q2TztFIqYjTYU0pVaWkpnYmLtffm8Bu0ffihbbPXnX/g+Wt7kxAfV+XmpfPtp7ikYVsO1ysezxZ/8ji9fCaOrnLN00qpiHFsM65yjvTMbKYv2sK+nDxaxceRltK5SvxDVDWD+70Y9D169CgsW2Y/8MorST03oUq+l337KRbViuHz9olc8f1KT9rgnRmsa32uZ7tKNk8rpSJCgz0VlLsGwf2PRfv/KCdKTQwRtC1aBPn5xdtnnw1dgi6z7Wj+aulWdOhjD/Z2reXZgeMAiK0lVaZ5WikVeRrsqaCCjXTUYE85lW9t9KzPZ3GWd4YrrgCpumO3WsXHke0T8PkONun503bOPPoLPzVqpsPUlKrhtM+eCirskY5KOYRvf7YDh47RcNmn9kxXXlkpZYsUf/0Uf2nQhHWt7LV3F2+3phrNLzQ6QEOpGkyDvWos7FUFggh7pKNSDuFbG52cvYn4k8c92zlxDfkwrm1lFC1iUhMTeHp0D+LjYm3pn57Tz7Y9Yusaz996g6ZUzaXBXjVVqlUFggh7pKNSDuEb1Fy8zb54ztKO5/H3pTsqskhRkZqYwPpJI2wjitf3GWzLc8GPG2jkCnT1Bk2pmkv77FVTkeprF9ZIR6UcxNafzRgu3rbGtn/x2edXq1ou38EpRz94ika7tgEQW1TI0B3fsKj38LBu0HTkvVLVkwZ71VQk+9qFHOmolIOkpXT2jCDvfmAHbY4c8Oz7LSaWle2TqnUtV6Ox18Bf/+rZvnL31wyeen/Iz7COvFeq+tJgr5ryN1rPna5UdeZdGz1qxSrbvpXtk8irE8foLs39HVpledfIDT2WwGte+4bsXAtdTg95Dh15r1T1pX32qinta6dqstTEBFY/MoQ7Dq6zpS/ochEGeH9tdpkGLDmRb//cpae14aeGTYsz5ObCkiUhz6Mj75WqvjTYq6bco/Wq4lJQSkVEZibs3OnZ/C2mNkvP7gtYNVaT522srJJFVIkaOREWnXOBPdMHH4Q8j468V6r60mbcakz72qkabfZs2+bK9kkcq9vAs52Tl096ZnaV/oykZ2b77a6x6Jx+3LhuQXHCvHnWCiKxsSXyunn3dXTT1oDo0gExqqJozZ5SqvoxpkSw93Hni0pkq8oTDbubb/35+qzu5NQ7rTjh0CFYujTo+bQ1oGJFanospcKhNXtKqYhyRG3F+vWwo3guvd9iarPknPNLZKvK/dH8DahwK4ipzcJOFzL2W6+VQ2bNgksuCXpObQ2oOBU5IMYRn0lVqbRmTykVMY6prZg1y7b5ebtEWxOuW1XujxYqUJ1/7kB7wgcfwMmTUSyRKo2KGhDjmM+kqlQa7CmlIiZYbUWFKSyEmTNtSR/5Bj5U/f5ooQLVNW16cLBBfHHC0aOwcGGUS6XCVVEDYhzxmVSVToM9pVTEOGL6juXLIbu41uJEbD0W+awZC1T5/mj+plcSr7+LasXwUZcB9oN8ajxV5amo6bEc8ZkshUis6a5K0mBPKYepyl92jpi+4+23bZufdOpHXp16trQYEe5/d32Ve369eQ+oAOsxGZ8887v41GjOnw/Hj1dMAVVQFTUgxhGfyTBpk3P0aLCnlINU9S+7Sp/M+8QJeP99W9KCXheXyFZojOf5ve/d9fSe8mmVeY69pSYmeJ7zQuMb6sH6hM7kNG9ZnJCXBx9+WIElVMGkJiaweuJQdk0bxeqJQ6NS01zpn8lS0Cbn6NFgT6kIiUSNXFX/sqv06Ts++MAK+NxateKK+6/3lCdGxO9hOXn5VSqo9hZsVG6R1CrZX3HGjAoolXKKSv9MlkJVa3KuSnTqFaUiIFKLyFeHL7tKnb7DpwmXG24gNbkNqclteDx9A/9d80PAQ6vqOrCh3htvnz2AG1a+W5ywZAns2QNt20a5ZMopovmZjOS0LmVd012nlgnNsTV7ItJVRJaKSK6I7BORqSISE+KY80TkDRHZ7jpui4hMEpF6wY5TqrwiVSNXlfrXOM6ePZjFi21J/2x1Pv2nLaPdxAVBAz23qhRUu4V6b2xp3o5Nrb2a7IzR2j0VEZHudlKWJueK6PpSlftRuzky2BORJsASwABXAlOBB4EpIQ69FugI/A24FHgJeACYGewgVbGqwwfHV6Rq5KpS/xqn2fKXZxGvfmsbzujIs/vr+q0pCKQqBtVpKZ2JjfHfPO02s+swe8Ibb0BRURRLpWqCSHc7KUuTc7S7vlT1ftRuTm3G/SMQB4w2xhwFFotII2CyiPzdlebP34wxB722V4jISeAVEWlrjNkT5XKrECLV3Ok0ZW1+8OV+DrRJopTy82n63n9tSf+v98hSnaKqBtWpiQlMnreRnLz8gHnmnzuQPy/7D/UKTlkJu3fDihUwdGiFlFFVT9HodlLaJudwylCeZt6KXOkkmhxZsweMBBb5BHWzsALAQYEO8gn03DJdv1tErniqrKr6AIRAIlkjVxEj9Kqd+fNpduxXz+bxOnHM8zORsj9O77QejiNBAj2Ao/VOY2GnC21p6Xf/pdrUrKvK4YRuJ6HKUN6auerQjxqcG+x1ATZ7JxhjfgByXftK40KgCKja0UQ1UV0+OL6q0oi3aunll22b6V0Hc6Ju/ZCH3XBBm2oRVIfzz/W9nvYpaC7Z+gUn9h+okk1SkVAdu5NUNCd0OwlVhvJWMDghoI0EpzbjNgFy/KQfdu0Li4icCTwGvB2k6VdVoEg1dzqRLiIfeemZ2UyZv5HDuVbNVXxcLJOv6GZ/nr//HnwGZoRqwo0RYez5Z/Fkao+Il7kypKV0tnWP8Gdtu5780PgM2hw5AEC9glNcl/UpL19wdambpMraLOaUUZPVtTtJRXNCt5NQZShvBYO/z1ZV7PLh1GAPKDEZPFgtLv7SS2YUqQO8BxwH7g+SbwIwAaBNmzalL6UDOOULNBzV5YOjoi89M5u0OVnkFxZa20MAACAASURBVBZ/5HPy8kmbnQV4/VN+/nnbcRvPOpdNZ3Qo8WUhwPUXtKk2AZ43f//whnRpzvLNBz3buacKmJk4kkdXvOk57obMBfxf36vIzskjPTM77ICtLIGSkwKs6tIPywmccJMbrAzlrWBwQkAbCWL8zLpe2UTkZ+AlY8wUn/TjwBRjzPQQxwvwDnAx0N8YszlYfrfk5GSTkZFRxlJXDt8vULCCJyc3IVal4FSVTiRf2/7TlgUcSZsQH8fqiUPh4EFo0wZOnize+e678Lvf6fvMR/uJC2icd5Q1/x5fPFADuP2q/2FRpwvD/t4I9Lp4XpMIHxcN7ScuCFibsGvaqAoti4quqvg/sjREZK0xJjlUPqfW7G3Gp2+eiJwFNMCnL18Az2FN2XJxuIFeVVUV71CdcCfoRJEKTioryIl0zU2wZhbPvpdftgd6bdrA6NGea+r7rFir+DiysfozXvftp570G9d+xKJOF5KXX8jkeRtDvnfK2izmpP66gWp7aomEXcOpIiPa31fh1sxV95tDpw7QWAikiEhDr7RrgTzgs2AHisijwN3ADcaYVdErojM46QtUlV2k5nKqzDmhIj3SOlgzS6v4OGud15desu+4916o7dR72Mrl7sg+o89ltvQLf/iW7j9tB6xm8lDvnbJ2WHdSR3d/nfrBWjO5pg5YiaRwB79U1PdVqBkOqstcesE4Ndh7GfgNmCsiw1396iYDz3oPtHCtlPGa1/bvgb8CbwHZInKB10/zin0IZVeaUWJO+gJVZRepQKkyp7aJ9I1HoMmCY2uJ1cfz1VfhwIHiHQ0bwi232PLqiMti7hHjRzt1Y81Z3W37/vTle36Pycsv5MH3smzPX6jRj4GecyeM3HRzPxf+1kquDlNBVabSBE5OmYrLKeWIJkcGe8aYw8AwIAaYj7VyxnPAJJ+stV153Ea4fo8HvvT5qRIdMUp7h+GkL1BVdpEKlCqzpjfSNx6piQlMv7oXTerHetLi42KZfk0vUs9tCn/7m/2AO+6Axo09mzXhbr203DUcRQ8/Yku/ZOuXdDz0o99jCo2xPX9AwGmGgj3nTpueKDUxgaIAfda1ZaTsShM4OaVlyinliCbHtncYYzYBQXvtGmPa+WyPxwr0qqzS9sGrLiOFoqWq9MOI1JQ0lTm1TTRGWgfsd/fii7B/f/F2/frw0EO2LFWxP2uk+Hvfg9f3ROOWzO7QhVY7rS7NtTDckzGXe1PuDXpe9/MXaF7CUM+50/pRRuPzUpbvnHCOccJ3WThlKE3g5JSpuAKVI97rRrOqc2ywV1OV5Q7DaV+g0VLaLzsnTfUQSqQCpUicp6z/VCrsxiM3F6ZNs6f96U/Q3N5ToybcrfvzePoGZq75wTPaNDsnj7Q5WWAgv8hKzT5ykum9r+K5nU97jrv8u+X8+8Lr2NLwjKDnD2vgTCmOqUyRvkEpy3dOOMc44bssUBky9vxqm+Invn6sZ15Mb/4COKdMxZWW0rnENE8Ax08WVJsBOxrsOYxT7nSirSICt6pUsxOpQKm85wn3Cz3QOSvkxuPZZ2HfvuLtuLgStXpQcz5L3tIzs22BnpvvPzGADztewP1NE2hzyGrWrlVQwH92zee6gXezLyePWiIU+mnmDDVwpiJHuZa3tivSNyhl+c4J5xgnfJcFKoPvjUVsLSE2RmzvuUABXDRuEMvyngi0vnR+kXHk/4uy0GDPYfzd6cTWEnJPFdB+4gJHN0WGq6ICt6pWyxCpQCnQecL5Egz3C73Sakh/+qlkrd7dd8MZJWujnFJrUJGmL9oS3qzzQFGtGJ65cCz/nP+MJ+2shems/usk6N074PxkwZ6/QCt5uEe5QuTeM5Gq7YrE58792Qo0L2R5a0Od8F0W6FolbiyKDPFxsTSoWzusgCuSN4jleU8EWl/aqf8vSsuRAzRqMt9OzPFxsSBwODe/2nQyL8vIp7J82elI5WLhDlYI9wu90kaqTZoEJ054Nn+Na0TP35L8jrR12oCAilDaf0wfdx0EPXvaE//nf4CyPX8VOcrVKSMovT9bgYScRihEuhO+y0pzrSN5+Z6pTtJSOjN90ZYKGRFfnveEE57jaNKaPQfyvtPpP21ZiarlymiKjGTn4ED/kLJz8ug/bZnfa5SlSa4q1+xEujN2uDWjgZ5nfyr8jjcjA/Of/+AdRrzQfyxH653GUVe/tMnzNnIkL9/2nFXn4M5XaV4/gAKEmzpdxRvfflucuHCh9TNyZJmev9TEBO5/d73ffZF8z5T2BjDYZ6o8nzd/ny1vZakN9T3GCd9l/soQaP1S9/eyv5q2+95dz5T5G5l0ebeIfzbLUwPqhOc4mjTYcxB/XzjBAqOKLFekOgenZ2YH7AskFD8u32uU5YNYVUcqR6MzdrhfgmkpnUmbneXpyB9M47hYek/51HMz0qR+bFS+wAEoKIDbbkOKijxJO5u0YmbvkZ7t/ELjKUt2Th73v7ue+95dT4KfdWKrwvugLAI1owazvEMyX7Xuxvl7NxYn3nMPfPcd1K1bpnJURH/J0lzD32cqbXYWU+Zv5HBuvi1ocb93Mvb8GtY6ysECiYQw3mvhfE85YRUIf2UY0qU576/NDvi9HCgQPpybH5WuIOV531XV/xfhcuTauJWlMtfGDdQ/pl5sLb8jmwR47tretjditD7o5VnT0rtM8fVjOX6ywG8gEegO0X2dElNHVPEPYrDXKhpriJbmnIlTP/X7nvMWW8sK2H1fytgYYfrVvSL/ujzzDKSl2ZJuvGYKn3XoU6bTVae1MX2F6j/mT7eftjN/xv3U8v4UPvkkPPZYmcsQ7fVI0zOzS9yYxNYSax5G15x/7s9YoBvMYPx9x/rjfcPjraLX/K2sNWC9n+fGcbGIQE5ufli1zJF+jsr7HJT3f2hlTI9T1dfGrXECNbPVrV3LbyBkgMnzNkZ1aH6ofxqhPsi+ZQoWQAT7GnY/lqdH9yjVF4MT5qUKVK5gr1U0OmOXpmY0J8jrJFh3ybmnCvy+nvmFkRu95n796u3YyoIZj1PPa9+H5w4qc6AHzh2VHQnupld///gC2Xjm2cxMHMm4zI+LE598Eq6+GjqXvhkrVC1JxD6bvl0DXdu+j/3/t3fu4VVU5/7/vjvZSXbCJUFAIYJ4qxwtCmoVtT0qVdR6oyqij/bo6a+19rTHyrH0YGsVW3u0pWqvnqq1ra3WoqIpikqteKWCBQNHqVAvCBhQbglCspPsJOv3x8wkk9nrNrOv2Xk/z5MHMpnLWjNr3nnXu95LWEUPcGSSaYw0NDahtbMrbXtvlZccEryHu1o7kEz19NsnH+NcNd6aWpLaSTyQfVeQTKxzJrlsGrPFkB5HByt7RYJq0O9OppQvS0sy1ZvOINuh+TYfCnL3CxNBqzuXTiiE7Usxv3imZ5WLJbAwQlA3I/eOU/lkAdkR4N7z60624/FF81GV6uj92+6qIfj+Z7+U8TVKJcpOhfdsr9U8Kz8//swX8Ll1r2CfpFuRsr0duOIK4JVXItUbDvr7eWXUgkpA1Hdz/pL1aSllvMkGgFBL2SpMY0TWBqBPuczVhFMm31Tka5zL5JqAXrbnIvghqp+uKbjDlJJKZj0upkklK3tFgukDr3qZvYGULWtQmCUg08w3zLVNQgFw7oEq/UxQqLZ1dkVWfnNtEdT5YXq1R3PhKGwrBHV+X56QG56IS5eugOwIcE/wfvul3+OIbe/1+9s7138flRVjgZYkylwBW6dxEVBRKlF2OryJoOx9Dr5vuxND8YNp/w93LL6zb+OKFcD8+cD112fUjqByooruDvOe5SMdiWmMqK7VI4A5j6wBqC/HYTYnnGEm0sE+5Eq+6SL5ayXywlam5WuFRjeebFJSqazHxTKpZGWvSDB94FWzc28ghXVWlr08YZZ9gteXnTNsZKCA48OhOyZYo1O1fGBqr4p8WAR198Vbrr71gkkFW4L2ruM5rwdJproRS8+sAcDx2cvG8tWWliTOfutlXPX3x/ttf3LiZ3DOd7+BZZLUHv6JimniUEpRdiZUsuXCY+rxwPJN/fZ97IhpOPOfr2L628v7Nt54I3DKKcAJJ0Rug41yIns3dR961Xs0PBHHnvYu6ce3jAg9QmB4Io7Wzi6pVc5Dlt/U64upWgQA6cQjygqFrP9hFAj/OM9ldKzqeXh+eVHLyOVrhUb3DbVNSaU6bzHAARo+ChmgAegFm8pp3v8i2Tim6vYL69TtXV/3MQlGasXLCF3dQvqS6PqiuvayudOUwQcyahNxrL5puvLv2Q6OUNUo1fWvjAi3X5yDIIeQhLmvAFBTUYYffD47zuBXXnM3/vd/v4FEV9/y7QfDRuFL196LZ24+33h88L4PlmhcFTc0vIGHVmxGtxAoI8Klx4/DLTMmSeXKyNZmLLnva33LuQBQXw+8/jowenSk60+Yu9i4T/AdM8k02d/jMepnTfMTlIe6MSJTBuNl1K/knOl6KgjAhtvONu4XLHvn74OtrK6Ox1BXU9nbx9aOLqVFPtNgjlwEiNjI42xZ/rL9bfQfn0tZwwEaAxD/Mps3gGcvWI2xtQmcfeQYbYi7rU+Wzi8hrLnZu77qnM+v245bL5jUz0JUU1GOc44K1xeVGPXaG6bdEoOQ9Jy222WoLEz+QJNbL5iktNbmotpAFMKOh9rqiuy0d9Mm3PXwzf0Uvc5YOeZ8fi6unmGUaQAGT71oGxoam7BwVVOvpatbCCxc1YRjDxgB2Vx/R00d5p51De597Ja+jU1NwKxZwJIlQEWF9Bq6YIwwlladK0ky1Y3rHl7TKxcvPKYez6/bjiZ3SV+3jH/hMf3HhG6MyPKbyhQ6r1qEypIow8bSoyp758lqmxRJ8ZhzP/zprHSEsTrqnnc2VyRM8lhm+fOnXApzfVP7bVe9POtxsU0qWdkrQmQDeOGqpl7BpsvFZBpYupcnzLKr/0UyJVBt90WItSRT0r6cOnFUP+V2zhmH9c7cVLM7T2iGabcu0lR3LltTvK1v0rK507SzxWJw7A27DJ8V35SPPgJOOw3VH23tt/n2Gd/AwTNOTxsjxSJIixndBE9VIurZQ6fiV8ddgKtfe6xv4wsvYPOMS3D+cVdhV7tzvtpEPG3yFlxqM5Vw88sSG6u+p1Q1tSTx4PJNOPHgEdjV2mn8ED+0YjMeXL7JauyEGcu7kyncOWuylZXR1n1Ad8+2tCQxY0q90s0CcO6pKmJeh02/TUur+cybpwoKkbUriH9S4fn+qhRE22CnYk7pxOXSihCdpcwrQbNs7rRIA0pXEmbOGYchES/THp+Il+Ensyb3u77unDZ9mXPGYVi4qgmqUl6ydvmFpuzvKgOeSWkzXcvEvEVrrX2TTPe70I69qvuaiMvFRsa+KR9+CJx+OvD22/23/+d/4l9umK0dI4wa0wRPxfyTr8DrBx3Vb9u4px/HVU/fC88k2JJM4YHlm7RRjLpx/H5AloUJPACcD/uyd3dZHdMthPXYCTOWx9YmMGNKemm5+TOPwvyLjopUrs+mDKRq4koAls2dZpzYyogR9d4XL3o6WOYsbEky1XlsMMljk4xUtStY4s4/gbj+sTdwQ8MbaW2eMaUe9ZpxQUi3HhcTbNkrQnTC2cYXCVCbolWRlm1urijd8qL39+Bg1gWX2JRNUgmPaxes7l2y0AUsyMzvpszugHpmZ7KgqmhobFL6w/jxhLV3zuseXiNdAooRKaOPo6DyHwxzX1U+hxkHPLz3nqPovdc/8hYzZwJ33on581/MamqhwYTOOqKLvK6orMCH9/4e+MqFwDvv9G6/+rXHICiGH558hdYvwhQ8Jvtw5muC4y0HA3Krj+y+yHz2gu4nsnNFnZSrIqhPnTgKJ9221JjORGeZVy2rey4kKzfuUlprw7i6ZBpgYVpatVl9kLVLN6kIRtn626x7XwSA59dtN/apUHCAho9CB2h4qJYtaxNxdHT1aGexKoHkd2qet2itVCmxcUatq45DCKTVH1X5cJic/E3Rt8H2h8HkR6R6ab3rAX1CJpgZXqZ82QQ02AbN2BwXBltndtvrhFUctbz4oqPUbQ8IyjPPxJ9vvgs/WrpB+9GycXYfzNgEOmiXs959FzjxRGDbtn7n/e0x5+L7076EnpjcOu0PuJrz6Jq0YAdZpRXdO1QWoQqGCU/pkS3fRRnjmQQLmKoNEYATDx6B1zftVsqK4HNVTdy96iCqiabqXnsKum0QWy6qAfmxkZ2yax04d7FVJK3sPLr76u2XTxcT2wANVvZ85EPZCwqDCfsksPy95n5RcsceMCJU6TQbVFGzQbw2BK1iKkzKQZR0LjKyXVbHpJjVVcfRnlIr1jKF0PQm6fxCbEo75aJcmowo14kUidfTA/z0p04ZtO7AfT77bDzx7Z/gW0+/E1qQM+lkHLG4ahX2fPpkDG1v7bf52UOOxzfO/SbaKvpb6YJKhyyY4PKp49Nqz+rG0cqNu9JSxaiIxwhDqspDyUvZO627V7JVFtlqgu3kSWZJrKko751YnzpxVG9EtQyZXFGVcqurjqO6ojx0hKmnJNpmftApm1EnabL7rrovqpJ3YTMNBNtsOj6fvnus7EUg18qereJz+dTxOPaAEWmz7UwgQJsTyk88Rph13LjeKDcTpg9uQ2OTcgZpS7YtOFFmdkFMCqEOnTBQtS3qPTDNRMNeR6Y4qJzFlWNjwwbgi18EXngh/W+XXw785jc46faXi0agMsDzDz6NyV+ehbrknn7b1408ANecNwf/HDUBQJ8F6v2dSe3kJfgh1lkYAftoSMB5N28694hQ4947LvhO21rjVUujtYk4airLtdZAlXy0TUelemdlx8UIaTWtg+gsezY580ztzSSVlW2aLwJwmWRC4Z1n9oLVob4BwXQvUSyKucBW2eMAjTxi63z80IrNmDGlvtc5NRtLF8MTdooe4CwBP7lmK5bNnaYMdPCj8tXwHFznL1mfcR9UyaGjOv5mI9Flc1sqssVS59CsC3gJiyeUwqC71xPmLsbsBav7BUrMeXSNcmz5UyScdNtSTLzuMfzqzC+h64hPyhW9m24C7r8fiMe1/lthnN2Z7HDqZWeh8bcLsX3IiH7bJ+7YiCfun40rVy4CiR4IAH97d1fvGFG9+14FHkDuMO/5w3kRvWHetea2FK5/7A1lMJHuOJvgA10UaJCWZEoZWNRbFtBQfcHUf5VsCAaO1CbiRkWPAEw9qE4bGDFjSr02WFDXXoJzH8LKbNV5/Wm+vH7WVccxPBHHg8s3Sa8zY0o9Lps6Xlpa+aSDRxiD9Pz3VUWhA+yCcIBGHrF9+N6LH1bAqUjEy4z55YJ4pn8bB9jhiXi/36MUxNYhc/7PxPG3obGpNyClkATHg64ChCybv42ioxtDtqkhTOlkdAllx9Ym0NDYhBsfeR1nrH4O177yR9TvkTgxDxuG5fPuxHUdE7Dl209rqxOoZsz5Kqs0mJk263TgpDXAuecCq/usZpXdKcx77h6c99aLuOm0q/HGmEOtzqdTZvwBOCbZKbNEJVPdqKuOo6tbhCqjp2un6vcwJFPdmLdorVWiXk+J013PFBzlDxyR5Q8MIgC8vml35EA1U3szqYmsCw7x+mn7bbhlxqTeFTRZNSmTLPGuZ0oNViywspdHbPOWlbmame6FIfd8XjSuzqn51gsmaQvX67Dx82vt7OoNTQeiFcRW4S3HhEkOrRMc2fIhBOT1HsPgFwZBvyb/fap1s/l7io9X4mjeorWYd56+xJFuDM2f6aTViJKI25bvfGofbPjO9/CXlx/Ffnt3yXeaPh1Lrr0F1/5tJ5KpvgSw8RghXkZWecryWVZpoGEKVAqtIO+/P/DKK8DVVwMPPNDvT0dvWY8///6/8Ngnp+GXJ1yMDSMM5yKnDaYIT53srK9Vl7NqaXNy4AUDrZrbUmnyKBEvQ2V5TPpOBz/cYXNQprUrmTLKDv9YV13Pk+/ZUML8+NNjRcH2/vitpjbj0CYPaphvgy6C2sZPc84Zh+Wslnm24WXcPGKTxw4ALj1+HAD1zKC+NtFrPr9lxiTtcmuPEJgxpT70LKOmwmnnjCn1uPCYeu1ybqpb9Fvm0NUR9MzetpbG6opy6UsXtdJFtqyltYk45p13hHV+vyBBYTBv0Vqp9cHz95FZz1qSqcj5wurd3GDB5RgAaUvjYa0YNR1tOGvdK/jd47fgc2cei689fY9U0WupGgLcfTfwzDP43po9ac8l1SNQU1FulacsbO6vwYJ/eTS4jKj7m5GaGuAPf8DKH/wceyqr+/0pBoGL3nwOf/31V/GzRT/CsR+shbRUB5zNOr86b/zqPpy6fIFeDjxvjK++aToab5yO9287G3fOmpw2tmTvtOzDHSa3Z1T8Y12Vby5sWcUw34FMlFnbb513neA4vHbBaky++S9pY/HUiaPS7nPw+WSjCpKMGxreSHNh8SaUwRyLxehiUrSWPSI6HMDPAZwAoAXArwHcLITQfqmJaDiAnwCYAUeZfRLANUKInbltsRlZziB/NK7H8+u2O5aeEDMG04xHVV7HK2gf1DM6u3p6rXXPr9tutMj5XyRTQWwP/yzJVBLNT0Njk9Lp20sKqnrRwr7wKodtv0XN/zxNaWZUFUNUs3yTBcBkzZQ99xggXRJWlR6qiseQ9FVBCVKNLvzLh+9h8qa1OOW9VTh+85uo6FEvk3fGynH/Medg4VlX4pmrnDq3queyO5lS1jKOOn4GEyYlONPchcd+++tYctSngNnX4oy3l/f7W5nowXlvvYTz3noJ7+2zPx6bfAb+fMgJ2Fy7X9p5ZM8v6COmShlVWx1Ha0f6eAuzvOnR0Njkjve++1Il8fuzze0pS4Vli79tpnxzQVQWW5uVGg9yz2NaKZFdR9ZeXV1eWXtakinMeaQvF6JX9s9/J4OJjHXfBpWia2PdNpWvi1rkIJ8UZTQuEdUBWAvgHwB+COBgALcDuFMIcYPh2GcAHAbgmwB63OM/EkJ8xnTdQuXZ06UbAOzTAJjOETbBpqec2USulhH1zjKjpOFQ+T0E6wwC5qg83bXChtz7I6NthKxt4e4wS8mmaGxd9Kwsx1kQm/yKXp3NYe178YkdG/GJHZtw6I5NOHrnBnxy69so6+iQHuenLV6JBUdOx32fmoGdI8f28wlSCWjAsTL/4PPpOeFs3AIGe2oWXWQ3IL9/UaK+T7ptKQ5qXIYbn7sXh+7crN133cgD8NdDj8eKcZ/E62MnotVnGdTVFVWlJ5EpUyr3D+88Kj8tU+5N0/lk+TiB/jLcpoxZJuPWNq+iX0mVKTKmdugiklXppUz1fGXUJuJYfdN0pWyNEXDHxZMBqL8Nqudn+63SfTcKnevTNhq3WC17VwNIALhACPExgGeJaBiAeUT0I3dbGkR0AoAzAJwshHjJ3dYEYAURnSaE+Gue2h8K3ezbdsagmvkBZuXIZBWx8b/wMq/r2qLrh2rGGSxjU1keMypJOuuEylrqhO5/kGbB8grGBwVemJlz0MIQZim5ziJdjrbk1ZL1WkUPADo7OnHvwhWo+mgbjknuQV1yD+qSH2NkWwvGfLwDYz/ehrF7dqB+z3YMT+61areff+4zHgsnTcOCI6ejJTHMyeUYSJWgU2ZbO7tx3SNr0rL6mz4Zxeg3k29MFv9sOZbPOeMwzG5J4owv/gJnr3sFX3v1YUzcsVG678QdGzFxx0Z8/dWH0UUx/GPfg/DGfodg3agJWD9qAq646hycffIRaceFsRap3D90vp2mqgoymRI8X0syhUS8LC23W9gk6m0BP+gwmHzWZBZNVf5CndyPVJc2wlq393xVVvoeAcx5dA2GVJZL76nOr9HWv0+3QhAMUCxWitWy9xKALUKIS3zbxgPYCOA8IcQTiuO+B+AqIcR+ge3vAXhcCHGd7ro5tey9+irwcUBHde/9Fb95rXcTBZ7H7754nNzfxXLbnEfWYFdrutWFfLt6eZco8PmMARDC8Ztq7+pGtzsjC+7nXNv5Z5+aCvyPa030t+e1DTvx59VbsKu1EyOq4zh/8lgcd+A+/dr+2oZdWLRmC5pbO0EECMkMUHbt4D1z9gN+dumUQBud/Va+vwtP/t9WNLd1oq66AudM2g/HThiBmxetxa62zt7j/dRVx3HOJ/fDMRNGYNX7u/Dwyg/Q2d3T254yIlTFY2jr7Ea1G/3c2uFEA541aQyOGV+L1zc24+k3t/ZT3mRt925meYww85hxeGbth9jd2oHynm6U9XSjvKcH5T1dKO/pRhUJTP/ECFBXN1a+uw3Jtg7UxgnH1A/FgbWVWLj8PVSmOlGdakeiqwOJVDsSqQ5UpzpQlepAdaodNal2SRsyY0PdGCw9+Dg8fsSpeHPfg/s5aXrBRWF9gmzzTXrn52hcs8U/dCJsyfk95cu/3E+iB/+6oRGXvvkspr+9HLGucNHvHXX7oPLgA4EJE5yf8eOBUaOA0aOdf0eNAkaOxIE3LAllnYySTFd3zqgVIoLVMtpT3WkTzah5JKPk6VT1Q5WUWHcdP/77kMm9f/+2szM63u9C45cLuj6877tXumvXVcfReOP0gmUDGNBJlYloG4C7hBDzAttbAcwTQsxXHPcwgNFCiFMC2xcDgBBCa2vNqbJ3zDHA66/n5twMU2jGjnVKan3607hkUy2Wx0cqd/UEby4kz2BftpWh+wjd0PBGWvWBesXyY7AOt9RHza1c0dKWQq1bWrF8x3Z8YcPfcNmHr2OfxtdAPWr/z7C0VSSwpyKB1ngVWisSvT9tFQkc+YkxOGBMHVBRAVRWAhUVuOPF99FZFkeqrBydZeXoLIujO1aGHiJ0UwyCYughQg/F3N+d//cQYcSQKvz40qOBWKz3Z9avX0MPAOGbzAgQCMCjXz2xfySa5v9fvn8ltu/t6PdOCCKMGlKJ+678lPV5AGDW3a9iT0ffMxHuLqOHVuH+Lx4nvY9L123Dj5esk76TquOu+M1r2LZHP1EkAE99418BQTEUigAAIABJREFUAJ/76UuR3vlhVeX4ysmH4O4X38HH7eFTZgXdPSrLy3DNZw/FtImjjX0YPbQKV5w4AQAwf8k65fm/ecZE/Oy5t9HR1Xffe69zxqeA2trQ7bZloCt7KQBzhBA/CWz/AMDvhRDfVhz3LIBWIcSMwPYHABwkhDhRd11W9hhGT2esHO+NqMfbI8f3/qwZcyjaRo8FxQgtbSlUV5ShtVNfZs4mx1hYuKJGOHTLibIcjEF0vr4qd4YfT9sfZzetBl56Cdue+itGN23IQk8YpohZsAC4+OKcnX6g++wBat9hk3Ya6jgiugrAVQAwfvz4MO1jmJJhd2UNmhPD0JIYiubEUDQnhqE5MQxbho7ElmGjsHXYKDQNG4UdNbUQJMnY5JtxqxS9oO9M2FJWMnQO4YwenY+ajRO9ztdX5Qv1Pyu24ey5l6PhiFNx/b4XILF7FyZvWY+J29/HYds34rDt7+PgXR8g3pN5eiSGYfooVmWvGYDM7jkcThoW3XGjJNtrVccJIe4BcA/gWPbCNTMEU6cCIyVLW7KEc5bb1m/b6yyHCefPY2sTOGy/YQCAZe/sQHtX33KJ1DNMcs7yshjKYzG0p7rT9quKx/Cvh47C1t3tWLv1414fPo/9R9TgiLHD0tr9wvrtUkfeREUZPrHvUPzzoz1o7+xGZUU5DttvaG8uvqaWJNZ9tBfJoPIQaHciXobPHr4vAOCJNVu0/XOu3bc9UVGG6Yfv23vOzc1teGvLHrSluvrt5z9nzNUwenrPJ0Fybdn5qivK8Lkjx1odj3gciMfxm+Wb0RUrQ3esDCn3X9nv3rZkvBLJeCXa4lVoL6/E43NOd/KkVVfj9LtX4r02ge6YXU6sTPByPmYTlT8RYyZXaWnGapIcBytmJKuHY+khx2HpIX3LhGU93dh3707U796G/XdvQ/3H27Dfnp0Y0bYbY1J7MaWyE9i+HWLXLoXPK8MwQYpV2VsHYKJ/AxGNA1Dj/k13nCzFykQADVlrXRR++UvjLmEcPG9oeEMaQXW5W/j5cgvnWRWXTx2f5osD9CUSVi3BqfylWjTFq/9DkpeqpqIcu5N9qQtMBav9jse3hXTiDTotjwOwqrEJ/7VgNXSeRXXVcVRXlPemW2jt7DJGvcqufeesyWhAuMjl+zJ0VMaRR/b+/rXzj7aysNVbpozQ4UV5eulgdHjPRecY7SWGZqKRaRUIIH3JxIuAVskIm/Jf3bEybBk2GluGjcbfx6Vfb8NtZ6OhsQnfeXQ1Ym2tqOlIoiaVRE1nEjWd7e6/bajsSqGipwsVXSnEe1Ko6ulGRXcKZV0pxLu7UNHt/Bvv6QIJgZjoQRzA+LoqbNm5F6KnBzEhQKIHFRCYOLoG+w6pwCvrt4HQg7KeHve4vjtw0MhqbNzZhh4h+imi8Rhh/zqn75t2tvbGrnkBXkTAPtUV+Lg9hVR3D8rdyV5Xj0BlGWHfYVWoq44DQqClza216zu//1r+IDYbZfhfxvRN0HcnU9i2pwNd3dnxqywvi+HQ0UOUf/dfr7wshtFDK9OiW9/etjdSe4gIw6vjaGlLKZN622LTj6272/s/EyKMGV6F4cOHZ3TtbFGsyt7TAOYQ0VAhxB532ywASQAvGo77LhF9WgjxCgAQ0bEADnL/VrSELff00Ap5LquHVmzGLTMmGcsL6RJcPrB8E2oTccSo/5KcV7FBtfTjL3rvCXsvgrKuOg6CQJsbcVZZHsPi/9uaXjWhW/S2y7sHww1lyfypIuaccVhaXrl4GWFIZblUUZGlmZi3aK1W0QOcPFqNN/Yl+7VJ8OuHAFw21XEbCFvmS5YXy+8YPzwRx56OrjTLazxGaalIdMlq/W1dNndaRqXm/GlQvvP4G0bFWMCJgDt14igs+PvmtP1lfWHCESbBrgxvwqaqn6pLQaQr/6WLuPbe1/lL1qO1G0BlDfZU1kRqv/+a/tx+V2v8SetrE2g9US47/SsSMnTl2LzjVe+Z311BJ7vDIstrOByZRc56xGOE+TOPwqGaxM820eBrZfkVY4QeIE3GBamrjmNvh91E3Bt7sgnMrRdM6tcPmWEGSJ+0TyyiyWixlkv7FYAOAI8R0WmuX908AHf4c+wR0TtEdJ/3uxDiVQBLAPyeiC4gohkAHgTwSrHm2PMIU+6pobFJKRC97aryOj+ZNRnL5k7DvPPS81j5aUmm0CbxvUqmuntr9wbxit57pW/87WluS/Uqet75baxEyVQ3iKAsvRPMpfbIyk3pL7YADh8z1Fhmx982E0El0V+SqV6iQAKOMPHK6dw5azJumTEpdJkvVRb5WceNQ+ON03tLQt0+8yjHEuBSm4hj/kx5aSVZiShZX2dMqe8tC2QiXkaoTcTTygc1NDYpffqCNLUksXBVE2Z9aly/vgDAkKpinacOHMI8Tw/vHaqvTWgVPf+5ZSWkVPLp0uPHWb3r2VyC7hGit1zgjCn12nM3tSTR2tnlBLBI2qY7Npnq1soWT2aa8tdlS9EDHPksK5UX5f7ayhsPW9knG0tDqsqNih7gfHdsV1x6hFCW0ZPlSZSVTfOXniy2VYeilJhCiGYi+iyAXwB4Ao6/3Z1wFD4/5QCCkuESd9/fwFcuLZftzQaql6upJYmTblualuVdhaeH6RIbe7MSE6pXRDX78ZZvslF71o+/mLnfWhh0yr+h4Q0seze9BmuqR+Bv7+7SltkJgylZryoSUSY0VLNn1XhQfQieX7e93zZVIW8Z3n4yC1+wr955dZU5dMESYWvVegXZbzr3iH73tLkthdkLVmPlxl24ZcakUOdk+vCPE9sqNqrSekGLtH+seKUB5y9Z329syOSTV7FG965nYwnaIzhxM5071S36uXH4255plPmEuYsjH5sp/mTCYe9vlJRHYWrYBuXZgTm4T/5JbRQl9bqH1/SWvyzGYLGiVPYAQAjxDwDa0SOEmCDZ1gLg392fosHkj6d7uWyzvANAorzPWKuq/ZjJ0o2HgDwScnYWIiyDxIh6X6KfaBzyVUvbXnuDvwcVJA9d1QqVIhN8vjqrh7e/Tmn3rKQ3P7G2ty21muVsv4CMktwz+GE2HRulSkqwnbaoojsFgAeXb8KxB4woOsE6ELGdpAD2lQdMSqFqbJmep6ytplQNsnQysombzfJ20I3D9ti66jj2tndFqpUbBpu0FTK89zPsEn+Uih+m6i46WVRrUVkoLFtakpgwd7FT4ef4ccpJpOo7Haz2BKhdcQpB0Sp7pYTNLNj0cnmC1PSxbEv14KTblio/wGEtbzqh4Sl6/hld2BlhbSKOmsry3kzyMkEoe4mAdEXDprqCH9W9vOncI6R+f/Mvki9LyJ7vwlVN2pxvuueQiJfh1Imj0tpg47cY1vczSFiLYFhhphsfKiVbF90pAGVpPCYcYRR4W6uMrVKYi7ba+lUF2+E/t2qs6hSSWy+YpLSS33Su4z6TjbRDQfxWUFnCaxv81i0A/SabOprbUqEVHF1pSZ0cA4C9kuTKZTHC0EonuA8UPibD271biN7gR5nCZ1PJJxtjPNsUZVLlQpGrpMq2JXX8gQ0ybMpMyZZX/VYmU1Sr6ljbItBhLIeqpU1PeMYUL5VMAU3Ey9DR1Y0wE2ZTkW9bq1WUkkm6Mj2XTx1vvOcyB+IZU+pDtSWsBTBqOaBgaaigQu8Fqxx7wAilZcn0XhSyEHmpkIsxrxvnqhJW+cZUYSQYDGVbbk533mwEQMhQXd9GLAblcdRVINnqh+peqLbrxhcgt67VJuJYfZNTtkynTHvy1bum6v6UEeHdWz+Xtt12qT1fcqkUkiqXDLazYM9Sohro3sugegFlSlAy1Z0mrFR4lrowwkkWqACkz4rLiDD1oDq8vzNpnFX76xaq2hkkmepGwleb08+ho2vwQXO7MjJQhspqJRNOOn9L1dKGTmk3zci959TUkkSMnL5fu2C1Nqo22MawFsCoFsPgcc1tqd7gDX96naD12VMMhQBmL1itLTYui6hmwmGypATHvM4q40c1zgl9H2zTtUwuE5koiqZ+y4KhPF/fk25bqrVa6izfmUZCq1BdX+eP2S0Eyoj6BUd4/odR2heUDVGW8sP483nsdmWfzi+4NhFPc69RKYYq6129Rnb7KTa5xMpeHjD5JgTRCdKgMuU33asGoK2xS2eJMpncTR+DbiHw+qbdocpZhV0Sbk/14PKp43trffp9L7JhxQLkaVJ0qWFkClFDYxPaOtU1Hr2IZ52wkaWYsU1PA9gtr5msrDZLFbLreOl1ahNxtHV2YfaC1bj5ibUQAr0K4GWBXI8tyRRiQFpKHJPSztihGg/XLljdbxLpjflbL5jUz+IqUxYAe9+6ZKob8xatRUdXT7/3a86jazBv0drecRFcnszUP0rnbC97//y+vlEUEo+gHFe5y/j9om2XZmUTu9aOdHnjrdyo7mcmEc9+2RBlKd/0zYyaw7G1systtZfq3quyTtgo6sUol3gZ10eulnFt8wkFjwk7e53yvb9Edlq1qSsqa9PKjbuklkNd3UzbqK2wywhRIsJsr6vLkVVXHUd7qkfZTn+7wvQpXkbS/HLzZx4VKupP9mxVSxH+pLU27TQtVeiW8UznlR3n9/Es9PJfKRH2OelywsmWA/1yI5PlSxu5YiM7b2h4o3dSGAXd5DqKHGpobFIqmP7IX8/avTuZUrq52MqbOvdcMplWm4hjT3uX8vw2Co8nG1RjSyc7dOMK0C+fq6yYMUIoN5+TDh6hXIkKjrFTJ47SBuTlEl7GLSKiRC5GcX4PI7dUqQN0BNvU0NikXCLW1c20JXjfVMINyO5MSjUTVQk2LzWMajnA32fbpRFPoAajceedd0SoqOdgPVrAeW6qj6Y/aa1NO01LFVE/7qrxszuZwuqb0qMg/WRzmW+wEPY5Bcue+QlabYJyIxN/NZNcsXE3UFUfCoMucXJQDtmMR9073dzWl5O0uS2l9XElOEnXPXTvsc4woFslOHXiqFBBLGFXtgC7b6bqb6pVKFujgedy9Pqm3dql54EmU1jZyxO2gyOTD9Vuy2SbXlRYpoN1/pL1oa02Yf0Y/PdNNUutq45npT8eYZcvxtYmepcrTELN5tz+JfuwyxxBZPVoVc+NgFBJa20U7Gz7JpnGT6bRyIMBG7cLE6YlM52/qupjXBWPRV6Z0E1SgsqnLkVTJvgnYx6y8Xit67Zw9pFj+lmDbNOJ+FMOXXhMfb8Jt4DjZ+ilI8pF/WNvGduTTyornCcbVEv5wRyyQXTyz/Q3IF0ZtFkN8ayiJn/MgQgre0VEph8qlQKQq6WvsIIkqByEVWyjWEijoLqPsuVa/0zaxmldVyYqmLgWUN8jmc+eqi9BTGlMZi9YrbSiqtqpwsYCoEKVuFtHrlJ9lAoqGRP0wdNhU/YMkPur+n83+cSq0I0LGz+6qEu3Jjq60oPDVJa15rZUP+tiU0syrSqHDu9d9f7vJ5PkyDbIAgsBtVzW+SdmazImk5OypXTT+PL6FmUSU+ywz56PXPnsBYkSbm7jAxLFNzATbJZjPOWgKh5DR1cPeoTcTB6lrblartPdR5mPom26BdO5ZVGHptQOujxYsqTXQPRltEzHUpjqAKa6qyqi+AcNJmxkjCzdiGosmXw7w/qvNTQ2aaPKTePCpn8HX/9UzhS+MKlnMsVTDXXj3cb3NujS09bZpbUwZuIbnek3TkZYmaqb0Pgte7ql+lx9U6PAPntFis56p5tNHHz9U7j0+HG9pYRMMygbp9JMlSPT0g/BmUUHU6J0CyEtaxbGApPL5TrdfZQtgdqmWzCdO4guQtIrO9V443TpxxlQz57DLNmFteTpMKUsSMRjaE/1ZHStKP5BgwmT5UtVe/myqeOlCWa9Z2Tjr2rLHknCXEDufxrExrp+6fHjMvbZUxHsby4sa/5zA/rIVFPUr2dNtLWwZuobHTaC2SYQIow1P5OlZ9W5B4qPMFv2fOTDshclWaSfshj1KwBtO8uIMvuxGbymmXhYbC0wuZgh2pBPy5HJKuBZOWzzKAaj9Gyy42ezX/nwucy3dXugYXpvor5X2XgfTVYo27EYNhrXS9GkS2RuiyxRfhhfyLrqOFraUsb32Xv3n1yzVVqpQzXe/fdmeCKO1s6utPJxXsSrLL1XlETqUVevVJPYYF+jjhebVRjVJEZnOc23vGHLXpGim9ncOWuyUTB0B2LHba1htrOfsBYzz9qVLWXP1gKTSY4rHVFrGOfCcmSyCiRT3XhoxWbrZaLgvWmXJKCWtSEqqlJSuZwF58uvc6BisnxFfa9skyzrMEWA6xJr+7EJhrtlxqQ0S6Xqw20bOBKMhPXasnLjLitLohc4p0pn5VGbiOOco8ZIc+6ZJk7+e3PSbUvT5Lb3TVg2d1rkd0b3DbEN1tBlegi2V5WT1CS7bFZhVBPiMAFBxQIre3lGpyx4gyOspcxGwcllLctsRXyF+TjkQumKWsM4Vwk0bZZbw/ge+e+NTWoVf3RuWHSBALm0vALR0hYNFkzKcNT3Shd0oavV7cckR1o7u6yd46MsrWUaOBKMhPXwold1BK1mi/9va6+SQW6dV0+pqaksx5NrtkrbU11Rbn1/VBPJTOW57huybO40rNy4q1+OQ5m7SZhMD46rUJlUJmeyxNrQ2CStwRsvo4wnR4WAlb08Y6MsyKK6dNgoOLZCPMrgjeqXoktaacJW6QrzstvmDPP2zbXlyCaS1aYoN5B+b2yE0WVTx0fuV65nvAPFT6YY0SnDmUxmgu/GzU+s7VcHWbVK4D1L0yhOdQur8ZOJP6/u3sxesNrK0hT057JN9yFrOwCUEwEx9C636s5n815711ARZsIctnzkDQ1vYOGqJqXM8u5fGGXJU5RtKx4Bdn7d85es71fD26PGp1APJB9hVvbyjElZMFlcZD57NoLYVohHGbw2FqgYALgZzP1lzKJio3SFFfq2im4+LUcmh+JguSMVQR8SnYKeiMdw6wVHZtTHXM54OZde7shkMiOrgxxEpgyF8WmzGT+miUbUiUIYdwlbn1hvf13bZQqHCk9O6/qo+8aEWaUI+tR576EuX6DN0myYSiu6nKSZ5spTjTV/PltVCqzWDnsrdL5gZa8A6JQFnTC73M2aHkVQ2QrxKDN7U0QeANwxa3LWB75J6VIJ/ZufWCuNpFLllrMRoLlG9/y8MaFLJ2D7nLPlWJzLGe9A8pMZiESdzNhWXYlSUcbDZvzYWJbCThS8nHY21FbHIyWoBjKbDPmXLnWTId01bEt4quqBJ1PdqCyPKQMnbNRWT7bJfPtOtFgNMqVXsb3H1jJM0qmWZKroJqCs7BUZqgFWX5votYRFHTw2QjzqzN4L1FC1vRADXvVSN7elMGHuYtQGotFkip5OgHqZ8LNZvUOH6vnZphMIHgP09w+tisey1tYwk4awSvRA8pMZTIT5iNocE1QYbKoueOdXfehlliWbiYJt3xLxMggBa0XPNum6DFXJS5NFS/eNCVo+hyfiIOor0+bdO51P+e6kvnykDr+lDgj/HbKxFNtOOG1kmGqpFyi+CSgre0VGPgMAVESd2RdD2/2YBKdKYMlyy8kEKOAIwWKZwUURkH7/0Ez7ElTabJIiR1mSHUh+MqVE1Eh1P7bKjd8PK2zVBZ1bSZia3TZW/5qKMtRWV/S7J6a61brclbK2x2MEENJSpKgmmbrJUENjE1o70oMOvOcSXJr1y0jbxWQv2FA1+Q/m+lMl7Lb5DgXHZFtnl1bRC/M9spGnpklAMU1AOc+ej3xV0DAxkJ3Pi6ntujxJOmT5mUw573Kd3y8XZCtXoSrXos2ycJQ2FENuq8GGzT2X7RMvI9RUlGN3MhW5okzUMRLm3Y+SH0815jKtviCToYD9JE51/dpEHB1dPWl98tK1AHZBKDoIwJ2uy47OzzhsZRwZYf09w+QJtMVUjSgf3wXOszeAyWcAQLYZyG33kFmITFaLMDO4YlGIs7EcqhO4mSyP6dqQz4hoxiFXkeqZWE9MY8TWsiSz9qh8CW0qyqgsi7WJOOadZ3b50Llr2KBaYSGSLy976VpOum1pxoqeP4Lfdjw0NDYp0/NEDTQJEja5t+0Y1lmRC7mqJYOVPSarFIsiA4RzqvZQvaCmiGPbJcRiiiTNxnKoSeCaFMdM8rqxcpc/chmpbjpGNUZiRDhw7uLQwWY2liVVf3uEMFbxKPRkRHV91fKy19ewS47xGGFIVTla2uRWW68tJiumSh4C+tQpYfwobZWuKEUFgMyqjeQLVvaYrFFMigxgL7xibtJSnVCWBTR4hBEmxRRJmg0fSxtlLtdtYHJPIf0kVRMtz4dOJWcyUboy7W+hJyOy66ssnV6fbHwuVf51UdHJQ+//sr/pAk1qE3HUVKYHrmTaHtU5Cv2sbWFlj8kaxaTIAPaRbT3CEV5bWpK9QsYU9Rp11l5MkaTZsEDo8/WZlbZCW0EYOwqplAfHiCxYQiVnij3YLJ8rIaY+qZTqmooytHV256R9UeSh9zdVf3RL5ab7XUzyOdsUrbJHRF8G8C0A4wCsBfAtIcRzhmO+AuAiAEcCqALwJoCbhRB/yXFzGRTfi2KT7BnoS+kA2Fkjg0rf7AWrMX/JeitBWGyRpJnOSlX32FSjM5ttYHJPoZVy/xiZMHexdJ8oVXx01wNy2998r4SY+lSIZ2ySh7q/hW2vzf0uNvmcTYoyGpeILgHwIIB5AF4B8O8AZgL4lBDiTc1xmwA8A+ApAK0ALgfwBQAzhBCLTNctlmjcgUq2ojuzSTBnlD+vHpDurO1hanPUiNBSjCQtJj9NpvQ5+PqnpGlQyojw7q2fK0CLolGM8jLf6OQhkF6TOBNZaXO/B6J8HujRuDcDuF8I8X0AIKIXAUwBMBeOAqfiaCHEDt/vzxLRoQBmAzAqe0xmFKP/VdBqFFRMomZZj7pkXWgLSS5gyxyTT1R1VW1qRBcTxbYSUghs5GG2ZKXN/S5F+exRdMoeER0E4BMAvuFtE0L0ENEj/m0yAoqeRyOAU7LZxmwyUK0ippD4Yu1PUDFRzfZMZvtMBPVAUo4G6vhkSpd6TSLmgUQpLxkC9rJDJw9tonlt5ZPt/R5I8jkMRafsAZjo/rsusP0tACOIaJQQYnuI850A4B9ZaVmWKbboVVtM7c6k7flWLqJaI0tdUAMDd3wypU0xriBEoVT6ISMfsiPsNUr5ftuQvWKY2aPO/bclsL058HcjRPRFOMu/d2WhXVnHFHZerOSq3d7L29SShEDfy9vQ2JTReXXMmFKPWy+YhPraBAiOdcDGP2POGYchES/rt63UBMdAHZ9MaRP1nS02SqUfMvIhO8Jeo5Tvtw15sewR0XAAY0z7CSH81rygAwYptquueQyAnwP4qRDiec1+VwG4CgDGjx9vc+qsMVB9NnLV7kKlbomaCBYo7iXrTBmo45MpffzvrD8qfqC9h6W6ZJgP2RG1skop3m8b8rWMOxPAvRb7EfoseLUAdvv+Vuv+G7T4pZ/E8ftbDOA5ANfp9hVC3APgHsCJxrVoY9YYqEuBuWr3QFMuSl1wDNTxyQwe2NWgOMmH7GD5FI68LOMKIX4thCDTj7u7Z92bGDjNRAC7TP56RDQawBIAGwFcIoSwK55XAAbqUmCu2q16SYvl5fVqOB44dzFOum1pTpeXi4GBOj6ZwQO7GhQn+ZAdLJ/CUXQBGkKI94jon3CsgUsAgIhi7u9P644loiFwcuwBwDlCiLZctjVTBupSYK7anUsH2kwDPwajBWGgjk9m8DDQVgMGC/mQHSyfwlGsSZUvBfAAgJsALANwBYBZ8CVVJqKT4SzTflYI8aK77S9w0qxcCeA9/zmFEMtN1+WkyoUnF9G42UiUyQlQGab44PeSGewM6KTKQoiHXCvdfwP4LpxyaecEqmcQgDL0BW4AwOnuvw9KTkuSbUyREFTy7pw1OWsztGwEfrAFgWGKj8GeToNhbClKZQ8AhBD3QhPUIYR4AQEFzuf3xwwgcr1Emg1FjZ2BGab44KW87MOJ1EuTolX2mMFDrlOuZENRYwsCwxQnAykqPh+KVCbXGIy+yYOFYkyqzAwycr1Emo2orcGekJNhmMzIR9L4TK/B0c2lC1v2mIKT6yXSbC31DCQLAsMwxUU+ksZneg32TS5dWNljCk4+lkhZUWMYppAUa1UJP+ybXLrwMi5TcHiJlGGYUicfSeMzvQYnKi5d2LLHFAVseWMYppTJxwpGptfg6ObShZU9hmEYhskxA6WqBE+8S5OirKBRKLiCBsMwDMMwAwXbChrss8cwDMMwDFPCsLLHMAzDMAxTwrCyxzAMwzAMU8KwsscwDMMwDFPCsLLHMAzDMAxTwrCyxzAMwzAMU8KwsscwDMMwDFPCsLLHMAzDMAxTwrCyxzAMwzAMU8KwsscwDMMwDFPCcLk0H0S0HcDGHF9mJIAdOb5GMTOY+899H7wM5v4P5r4Dg7v/3Pfcc4AQYpRpJ1b28gwRrbSpY1eqDOb+c98HZ9+Bwd3/wdx3YHD3n/tePH3nZVyGYRiGYZgShpU9hmEYhmGYEoaVvfxzT6EbUGAGc/+574OXwdz/wdx3YHD3n/teJLDPHsMwDMMwTAnDlj2GYRiGYZgShpW9LEJEs4joMSLaSkSCiK5U7FdPRI8T0V4i2kFEvyCiaovzVxLR7US0jYhaiWgxEU3IcjeyAhFNcO+B7Ge94dh5iuPOzFf7M4WIXlD0ocri2JOIaAURJYloAxFdk482ZwsiGkZENxPRa0S0m4g+dMf7JyyOvVJx367OR9vDQkSHE9FzRNRGRFuI6HtEVGZx3HAi+i0RNbv36EEi2icfbc4GRDSTiBYRUZMrx1YR0aUWx8me7fJ8tDmbRB2nA/25A1rZJojoBMUxqu/Bn/Ld/jAQ0SFEdDcRrSGibiJ6QbIPEdG3iWizK7NfIqLJluc/n4jeIKJ2IvoHEc3KeidcynN14kHKRQAmAHgSwJdkOxBROYBEjzIdAAALFklEQVQlADoBzAJQC+AO99/LDef/mXuN2QC2A5gH4FkimiSEaM+8+VllK4Dgi58A8BcAT1scvxtAULl7KwvtyifPA/h2YFuH7gAiOgTO+HgSwPUAjgNwBxG1CSF+nZNWZp/xAL4M4D4A3wFQDacvK4joSCHEZotzTAOQ9P3+XtZbmSFEVAfgrwD+AeB8AAcDuB3OJPoGw+ELABwGR070APghgAYAn8lVe7PMfwHYAEcW7QDwOQB/JKKRQoifG469HcCjvt/35KaJeSHsOB3ozx0A/gPAsMC27wGYAuDvhmO/CWCZ7/diz8F3BJyxvRxAhWKfuQC+C2AOgHVw3o2/EtEnhRAfqk5MRJ8GsBDAXQCuca/zEBE1CyH+kr0uuAgh+CdLPwBi7r9DAAgAV0r2uRRAN4ADfdsuhvPiH6o59/4AugD8m29bPRyl8UuF7rvl/bnYvS/HG/abB2BHodubYV9fAPBohOPuBvBPAOW+bXcB2AzXx7bYfwDUAEgEto0AsBfATYZjr3THyJBC98Oin9cDaAYwzLftWwDa/Nskx53g9vFffduOc7edVuh+WfZ9pGTbHwFsMBwnAHy90O3PQv9Dj9NSeO6KflUA2AXgfzX7THD7eU6h2xuybzHf/x8F8ELg71VwDBM3+rbVwDHG3GI49xIASwPbngLwSi76wsu4WUQI0WOx21kA/i6E2ODb1gBHadMtU053/33Md70mAK+45xwIXALnY7Ci0A0pYs4C8JgQosu37U9wlP1PFqZJ4RBCtAohkoFtu+BUpxldmFblhLMALBFCfOzb9ic4FuyTDcd9JIR4ydsghHgNjqVsQLzLQgiZRaYRpfV8s82Af+4KzgRQB+ChQjck21h800+EY+V82HdMK4AnoHmmRFQJ4FT/cS5/AnACEQ2P1GANrOzln4lwTL29CCE6Abzr/k133AdCiL2B7W8ZjisKiGgYnMFvKxBqyfFnTBFRIxFdkMPm5Yrpri9XGxEtIaIjdTsTUQ2AcQiMD/QtXxf9c1ZBRKMAHAJnydOGd4moi4jWE9FXcti0TJC9y5vgWPZM73LwGQMD5F3WcCLsnu8899nuIKLfENGIXDcsh4QZp6X63C8B0ATgZYt9f+v6vm0lojuIKJHjtuWaiXBW6t4ObDc904MBxCGX9TEARv/msLDPXv6pA9Ai2d7s/i3bxxULM+CYvG0cct+Bsxy2Gs6S+FcALCSiC4UQj2mPLB5eBHA/nL4cAMd37WUiOkoI8b7imFr33+Bzbnb/HQjPWcXtcJZxTc9/Kxz/l9cAlMFxe/gVEVULIe7MbRNDk4t3+aAstCvvENFn4fgtftGw6/1wrB7bARwL51kfRUTHCSG6c9vKrBJlnJbic68GcC6Ae4S7DqmgA8Av4fhsfwzgFAD/DUfpOT/HzcwldQD2SsZuM4BqIqpwjTmy44A8ynpW9jS4ptQxpv2EELLZmvYQ2eUU27NxXFbI8H5cCmCtEOINi+MfCFz3CQB/A3AjfMvY+SRs34UQN/k2v0xEf4Uzi7vW/dGeJuT2nJPJsyeir8IJPrpQCLHTcPwSOL4sHk+7Sx43ENFPLV0l8smAfJezCTkZAf4I4M9CiN/p9hVCXOn79SUieguOn9K5cNxZBgQZjNOSee4u58KZkGtXbIQQWwF83bfpBSL6CMBdRDRZCLE6h23MNapnqvqb7ljb40LDyp6emQDutdiPzLv00ow+C46fWshnfZkel00i3Q83tcBpcAIvQiOEEET0GIAfElFZgSwAGY0FIcSHRLQMwNGaY73nGHzOqllgPon67M8D8HMA/y2EeDzitR+FE9wzAcUVlat6J4fD/C6PkmzP57ucFdwl2KcBbII5m4CMZ+BYfI/GAFL2FJjGack8dx+XAHhHCLEywrGPwgk+OxrOKs5ApBnAUMl3qRZAmxAipTnO28+PanUnY9hnT4MQ4tdCCDL9hDztOgTW8omoAo4ZX2chXAdgnOvX5UflB5J1MrgfF8GZWGSaU6lgs98sjgVlH1zH3s1I9/Xwfs/Lc5YRpf9EdCKcZ/4rIcT8bDQjC+fIJrJ3eRycaDzTuyzz58nbu5wN3CW8J+FEY57tjt9Q+Jb+iu3ZZoKqLyXx3D1ca38YP+wgpfDs18FZxj8ksN30TN8FkIJc1vfAyciQVVjZyz9PA/gUER3g23YegEo4s1wVXt6dz3sbiGgsnPxMNnnrCsmlAF4TQrwb5WAiIjj9XjPA/Hp6IaJ9AZwEYJVh16cBfJ76J+adBUcJfDNHzcs6RHQEHEXgGTg5pDLhQjj5uDZm2q4s8zSAM4hoqG/bLDh51140HLefm2cLAEBEx8KZ8BX7uwygN1/oIwAOBXCWEGJbxPOcCWcZ0PReDARM43TAP/cAn4fz3Yqq7F3k/juQn/3f4PggzvQ2+PwYlc9UCNEBJw/rzMCfZgF4VQixO+stzUU+l8H6A+BwOAP4cjizlV+4v5/s2ycO56O9Ck4SxUsBfAjggcC5ngPwXGDb3XCEyRfghLsvhxMFVFXovmvuyVg40UrXKv5+Mpz8gf579CIcBWE6HIHyFJzZznmF7o9ln48EsBhOLq5TAVwBZ5a3C8B4Q98PgbOs9Uf32G/BmQEOiFyKbh9Gw1FON8FxxJ7q+znct98BSM8duRCO4/ZZAM4B8Af3XfrPQvdL0s86OI76z8JxU7jKfXa3BPZ7B8B9gW3PwFnquwBO8NJ6AC8Xuk8h+n6P+1yuCTzfqQAq3X36yTD3/twDZ6lzGpwEuy0AVgAoK3SfQvbfOE5L8blL+rJa8bd+fYfjwnO72+/T4CRhTgJYWOh+GPpYDecbfhGAVwGs9f1e7e5zPZwI/K8B+Kwr+3cA2Nd3nn9zZd0Bvm2fdrf9xJWTP4LznZuek74U+maW0o87oIXk54XAfvvD8U/ZC2AnnCil6sA+L0iOq4RTbWM7gFY4StCBuexTFu7JtXCUvbGKv5/i3qNTfNvucwVi0u3ny3CsBwXvj2Wf691nsxVO/sSd7sdhoqnv7vZPw4nyawfwPoBrCt2nkP33+qV9F9CXaPVK37b/cT+Abe7zXwXgC4Xuk6avhwNY6rZ1K4DvI6C4uM/wd4FttQB+C0fZ+RiOcp+WqLhYf9w+qZ7xBHeffjIMzodwmfs+pOBMCH4GYHih+xOh/8ZxWorP3dePke4znKsZH7/z/X4JgJVwEhB3wlEGvwd3YlCsPz4ZpRvnBCfbwgfuWHgZwJTAea70H+PbPgOO8acDjkHgklz1hdwLMgzDMAzDMCUI++wxDMMwDMOUMKzsMQzDMAzDlDCs7DEMwzAMw5QwrOwxDMMwDMOUMKzsMQzDMAzDlDCs7DEMwzAMw5QwrOwxDMMwDMOUMKzsMQzDMAzDlDCs7DEMw+QAIvoqEd3l+/0WIvpDIdvEMMzghCtoMAzD5AC3IPp6AJPglMD7PoAThRDJgjaMYZhBByt7DMMwOYKIfgSgBsBZAE4XQrxb4CYxDDMIYWWPYRgmRxDRRABvAThfCLGo0O1hGGZwwj57DMMwueNGANsBlBe6IQzDDF5Y2WMYhskBRHQdgCoAFwP4RoGbwzDMIIZnmwzDMFmGiKYB+HcAJwgh9hDRMCKaLIRYXei2MQwz+GDLHsMwTBYhovEAfg1gphBij7v5pwCuLVyrGIYZzHCABsMwDMMwTAnDlj2GYRiGYZgShpU9hmEYhmGYEoaVPYZhGIZhmBKGlT2GYRiGYZgShpU9hmEYhmGYEoaVPYZhGIZhmBKGlT2GYRiGYZgShpU9hmEYhmGYEub/A7F+tVOe6bRGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "fig, ax = plt.subplots(1, 1, figsize=FIG_SIZE)\n",
    "ax.scatter(X_train, Y_train, label='Training data')\n",
    "ax.plot(X_range, y_pred, lw=4, color='r', label=f'MLP with one hidden layer and {H} nodes')\n",
    "ax.set_xlabel(r'$X$', fontsize=FONT_SIZE)\n",
    "ax.set_ylabel(r'$Y$', fontsize=FONT_SIZE)\n",
    "ax.set_title(f'NN with {len(model_history.model.layers)-1} layers, {H} nodes in each layer', fontsize=LABEL_SIZE)\n",
    "ax.tick_params(labelsize=LABEL_SIZE)\n",
    "\n",
    "ax.legend(loc=0, fontsize=FONT_SIZE)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 2:</b></div>\n",
    "\n",
    "Change the number of neurons in the layer. Try changing the activation function to `reLU`.  Can you get better results?  What worked the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 367 samples, validate on 368 samples\n",
      "Epoch 1/1200\n",
      "367/367 [==============================] - 0s 853us/step - loss: 0.0637 - val_loss: 0.0782\n",
      "Epoch 2/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0622 - val_loss: 0.0767\n",
      "Epoch 3/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0611 - val_loss: 0.0756\n",
      "Epoch 4/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0604 - val_loss: 0.0748\n",
      "Epoch 5/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0598 - val_loss: 0.0742\n",
      "Epoch 6/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0593 - val_loss: 0.0737\n",
      "Epoch 7/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0588 - val_loss: 0.0732\n",
      "Epoch 8/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0584 - val_loss: 0.0727\n",
      "Epoch 9/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0579 - val_loss: 0.0722\n",
      "Epoch 10/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0573 - val_loss: 0.0716\n",
      "Epoch 11/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0568 - val_loss: 0.0711\n",
      "Epoch 12/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0563 - val_loss: 0.0706\n",
      "Epoch 13/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0559 - val_loss: 0.0700\n",
      "Epoch 14/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0554 - val_loss: 0.0693\n",
      "Epoch 15/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0549 - val_loss: 0.0687\n",
      "Epoch 16/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0544 - val_loss: 0.0681\n",
      "Epoch 17/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0539 - val_loss: 0.0674\n",
      "Epoch 18/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0533 - val_loss: 0.0667\n",
      "Epoch 19/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0527 - val_loss: 0.0661\n",
      "Epoch 20/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0522 - val_loss: 0.0654\n",
      "Epoch 21/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0517 - val_loss: 0.0647\n",
      "Epoch 22/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0511 - val_loss: 0.0640\n",
      "Epoch 23/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0505 - val_loss: 0.0633\n",
      "Epoch 24/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0498 - val_loss: 0.0627\n",
      "Epoch 25/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0494 - val_loss: 0.0620\n",
      "Epoch 26/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0487 - val_loss: 0.0613\n",
      "Epoch 27/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0482 - val_loss: 0.0606\n",
      "Epoch 28/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0476 - val_loss: 0.0598\n",
      "Epoch 29/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0470 - val_loss: 0.0592\n",
      "Epoch 30/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0464 - val_loss: 0.0585\n",
      "Epoch 31/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0459 - val_loss: 0.0578\n",
      "Epoch 32/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0453 - val_loss: 0.0571\n",
      "Epoch 33/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0448 - val_loss: 0.0564\n",
      "Epoch 34/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0443 - val_loss: 0.0557\n",
      "Epoch 35/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0436 - val_loss: 0.0551\n",
      "Epoch 36/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0432 - val_loss: 0.0544\n",
      "Epoch 37/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0427 - val_loss: 0.0537\n",
      "Epoch 38/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0422 - val_loss: 0.0531\n",
      "Epoch 39/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0417 - val_loss: 0.0525\n",
      "Epoch 40/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0412 - val_loss: 0.0519\n",
      "Epoch 41/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0408 - val_loss: 0.0514\n",
      "Epoch 42/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0404 - val_loss: 0.0508\n",
      "Epoch 43/1200\n",
      "367/367 [==============================] - 0s 19us/step - loss: 0.0400 - val_loss: 0.0503\n",
      "Epoch 44/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0397 - val_loss: 0.0498\n",
      "Epoch 45/1200\n",
      "367/367 [==============================] - 0s 10us/step - loss: 0.0393 - val_loss: 0.0493\n",
      "Epoch 46/1200\n",
      "367/367 [==============================] - 0s 5us/step - loss: 0.0390 - val_loss: 0.0488\n",
      "Epoch 47/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0387 - val_loss: 0.0484\n",
      "Epoch 48/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0384 - val_loss: 0.0481\n",
      "Epoch 49/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0381 - val_loss: 0.0478\n",
      "Epoch 50/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0378 - val_loss: 0.0474\n",
      "Epoch 51/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0376 - val_loss: 0.0469\n",
      "Epoch 52/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0373 - val_loss: 0.0463\n",
      "Epoch 53/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0371 - val_loss: 0.0459\n",
      "Epoch 54/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0370 - val_loss: 0.0457\n",
      "Epoch 55/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0368 - val_loss: 0.0456\n",
      "Epoch 56/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0365 - val_loss: 0.0453\n",
      "Epoch 57/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0363 - val_loss: 0.0450\n",
      "Epoch 58/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0361 - val_loss: 0.0448\n",
      "Epoch 59/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0360 - val_loss: 0.0446\n",
      "Epoch 60/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0359 - val_loss: 0.0444\n",
      "Epoch 61/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0357 - val_loss: 0.0442\n",
      "Epoch 62/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0356 - val_loss: 0.0439\n",
      "Epoch 63/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0355 - val_loss: 0.0435\n",
      "Epoch 64/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0354 - val_loss: 0.0433\n",
      "Epoch 65/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0353 - val_loss: 0.0432\n",
      "Epoch 66/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0351 - val_loss: 0.0432\n",
      "Epoch 67/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0351 - val_loss: 0.0431\n",
      "Epoch 68/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0350 - val_loss: 0.0428\n",
      "Epoch 69/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0348 - val_loss: 0.0427\n",
      "Epoch 70/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0347 - val_loss: 0.0426\n",
      "Epoch 71/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0346 - val_loss: 0.0424\n",
      "Epoch 72/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0345 - val_loss: 0.0422\n",
      "Epoch 73/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0344 - val_loss: 0.0421\n",
      "Epoch 74/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0343 - val_loss: 0.0419\n",
      "Epoch 75/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0342 - val_loss: 0.0418\n",
      "Epoch 76/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0341 - val_loss: 0.0419\n",
      "Epoch 77/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0340 - val_loss: 0.0421\n",
      "Epoch 78/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0340 - val_loss: 0.0419\n",
      "Epoch 79/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 11us/step - loss: 0.0338 - val_loss: 0.0415\n",
      "Epoch 80/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0338 - val_loss: 0.0412\n",
      "Epoch 81/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0337 - val_loss: 0.0412\n",
      "Epoch 82/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0335 - val_loss: 0.0414\n",
      "Epoch 83/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0335 - val_loss: 0.0416\n",
      "Epoch 84/1200\n",
      "367/367 [==============================] - 0s 0us/step - loss: 0.0335 - val_loss: 0.0413\n",
      "Epoch 85/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0334 - val_loss: 0.0409\n",
      "Epoch 86/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0333 - val_loss: 0.0407\n",
      "Epoch 87/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0332 - val_loss: 0.0407\n",
      "Epoch 88/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0331 - val_loss: 0.0408\n",
      "Epoch 89/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0330 - val_loss: 0.0406\n",
      "Epoch 90/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0329 - val_loss: 0.0405\n",
      "Epoch 91/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0329 - val_loss: 0.0404\n",
      "Epoch 92/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0329 - val_loss: 0.0404\n",
      "Epoch 93/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0327 - val_loss: 0.0405\n",
      "Epoch 94/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0327 - val_loss: 0.0403\n",
      "Epoch 95/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0327 - val_loss: 0.0400\n",
      "Epoch 96/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0325 - val_loss: 0.0398\n",
      "Epoch 97/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0324 - val_loss: 0.0398\n",
      "Epoch 98/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0324 - val_loss: 0.0397\n",
      "Epoch 99/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0323 - val_loss: 0.0397\n",
      "Epoch 100/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0323 - val_loss: 0.0395\n",
      "Epoch 101/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0322 - val_loss: 0.0392\n",
      "Epoch 102/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0323 - val_loss: 0.0391\n",
      "Epoch 103/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0321 - val_loss: 0.0393\n",
      "Epoch 104/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0319 - val_loss: 0.0396\n",
      "Epoch 105/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0321 - val_loss: 0.0394\n",
      "Epoch 106/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0319 - val_loss: 0.0389\n",
      "Epoch 107/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0317 - val_loss: 0.0387\n",
      "Epoch 108/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0318 - val_loss: 0.0387\n",
      "Epoch 109/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0317 - val_loss: 0.0387\n",
      "Epoch 110/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0316 - val_loss: 0.0388\n",
      "Epoch 111/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0316 - val_loss: 0.0387\n",
      "Epoch 112/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0315 - val_loss: 0.0384\n",
      "Epoch 113/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0314 - val_loss: 0.0382\n",
      "Epoch 114/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0314 - val_loss: 0.0382\n",
      "Epoch 115/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0313 - val_loss: 0.0383\n",
      "Epoch 116/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0312 - val_loss: 0.0384\n",
      "Epoch 117/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0312 - val_loss: 0.0384\n",
      "Epoch 118/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0312 - val_loss: 0.0381\n",
      "Epoch 119/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0310 - val_loss: 0.0379\n",
      "Epoch 120/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0310 - val_loss: 0.0379\n",
      "Epoch 121/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0309 - val_loss: 0.0378\n",
      "Epoch 122/1200\n",
      "367/367 [==============================] - 0s 0us/step - loss: 0.0308 - val_loss: 0.0377\n",
      "Epoch 123/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0308 - val_loss: 0.0376\n",
      "Epoch 124/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0308 - val_loss: 0.0376\n",
      "Epoch 125/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0307 - val_loss: 0.0375\n",
      "Epoch 126/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0306 - val_loss: 0.0374\n",
      "Epoch 127/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0306 - val_loss: 0.0373\n",
      "Epoch 128/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0305 - val_loss: 0.0373\n",
      "Epoch 129/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0304 - val_loss: 0.0374\n",
      "Epoch 130/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0305 - val_loss: 0.0373\n",
      "Epoch 131/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0304 - val_loss: 0.0372\n",
      "Epoch 132/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0303 - val_loss: 0.0371\n",
      "Epoch 133/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0303 - val_loss: 0.0375\n",
      "Epoch 134/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0305 - val_loss: 0.0373\n",
      "Epoch 135/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0303 - val_loss: 0.0370\n",
      "Epoch 136/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0301 - val_loss: 0.0368\n",
      "Epoch 137/1200\n",
      "367/367 [==============================] - 0s 54us/step - loss: 0.0301 - val_loss: 0.0366\n",
      "Epoch 138/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0301 - val_loss: 0.0365\n",
      "Epoch 139/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0299 - val_loss: 0.0364\n",
      "Epoch 140/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0300 - val_loss: 0.0364\n",
      "Epoch 141/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0299 - val_loss: 0.0364\n",
      "Epoch 142/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0298 - val_loss: 0.0364\n",
      "Epoch 143/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0298 - val_loss: 0.0364\n",
      "Epoch 144/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0297 - val_loss: 0.0364\n",
      "Epoch 145/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0296 - val_loss: 0.0365\n",
      "Epoch 146/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0296 - val_loss: 0.0363\n",
      "Epoch 147/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0296 - val_loss: 0.0361\n",
      "Epoch 148/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0296 - val_loss: 0.0359\n",
      "Epoch 149/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0295 - val_loss: 0.0360\n",
      "Epoch 150/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0294 - val_loss: 0.0360\n",
      "Epoch 151/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0294 - val_loss: 0.0359\n",
      "Epoch 152/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0293 - val_loss: 0.0358\n",
      "Epoch 153/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0292 - val_loss: 0.0357\n",
      "Epoch 154/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0292 - val_loss: 0.0357\n",
      "Epoch 155/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0292 - val_loss: 0.0357\n",
      "Epoch 156/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0291 - val_loss: 0.0357\n",
      "Epoch 157/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 11us/step - loss: 0.0291 - val_loss: 0.0357\n",
      "Epoch 158/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0291 - val_loss: 0.0354\n",
      "Epoch 159/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0289 - val_loss: 0.0352\n",
      "Epoch 160/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0290 - val_loss: 0.0353\n",
      "Epoch 161/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0291 - val_loss: 0.0352\n",
      "Epoch 162/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0288 - val_loss: 0.0356\n",
      "Epoch 163/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0290 - val_loss: 0.0359\n",
      "Epoch 164/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0291 - val_loss: 0.0352\n",
      "Epoch 165/1200\n",
      "367/367 [==============================] - 0s 44us/step - loss: 0.0287 - val_loss: 0.0349\n",
      "Epoch 166/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0286 - val_loss: 0.0349\n",
      "Epoch 167/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0286 - val_loss: 0.0348\n",
      "Epoch 168/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0285 - val_loss: 0.0349\n",
      "Epoch 169/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0284 - val_loss: 0.0349\n",
      "Epoch 170/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0284 - val_loss: 0.0348\n",
      "Epoch 171/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0283 - val_loss: 0.0346\n",
      "Epoch 172/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0283 - val_loss: 0.0346\n",
      "Epoch 173/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0282 - val_loss: 0.0346\n",
      "Epoch 174/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0282 - val_loss: 0.0346\n",
      "Epoch 175/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0282 - val_loss: 0.0345\n",
      "Epoch 176/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0281 - val_loss: 0.0343\n",
      "Epoch 177/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0281 - val_loss: 0.0342\n",
      "Epoch 178/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0280 - val_loss: 0.0343\n",
      "Epoch 179/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0280 - val_loss: 0.0346\n",
      "Epoch 180/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0280 - val_loss: 0.0343\n",
      "Epoch 181/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0279 - val_loss: 0.0341\n",
      "Epoch 182/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0280 - val_loss: 0.0339\n",
      "Epoch 183/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0278 - val_loss: 0.0340\n",
      "Epoch 184/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0278 - val_loss: 0.0341\n",
      "Epoch 185/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0279 - val_loss: 0.0340\n",
      "Epoch 186/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0277 - val_loss: 0.0339\n",
      "Epoch 187/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0277 - val_loss: 0.0338\n",
      "Epoch 188/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0276 - val_loss: 0.0338\n",
      "Epoch 189/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0276 - val_loss: 0.0337\n",
      "Epoch 190/1200\n",
      "367/367 [==============================] - 0s 10us/step - loss: 0.0275 - val_loss: 0.0337\n",
      "Epoch 191/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0275 - val_loss: 0.0336\n",
      "Epoch 192/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0275 - val_loss: 0.0335\n",
      "Epoch 193/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0274 - val_loss: 0.0334\n",
      "Epoch 194/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0274 - val_loss: 0.0333\n",
      "Epoch 195/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0274 - val_loss: 0.0334\n",
      "Epoch 196/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0273 - val_loss: 0.0336\n",
      "Epoch 197/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0273 - val_loss: 0.0336\n",
      "Epoch 198/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0273 - val_loss: 0.0333\n",
      "Epoch 199/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0272 - val_loss: 0.0332\n",
      "Epoch 200/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0272 - val_loss: 0.0331\n",
      "Epoch 201/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0271 - val_loss: 0.0333\n",
      "Epoch 202/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0270 - val_loss: 0.0336\n",
      "Epoch 203/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0272 - val_loss: 0.0335\n",
      "Epoch 204/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0271 - val_loss: 0.0330\n",
      "Epoch 205/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0269 - val_loss: 0.0328\n",
      "Epoch 206/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0270 - val_loss: 0.0327\n",
      "Epoch 207/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0270 - val_loss: 0.0327\n",
      "Epoch 208/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0268 - val_loss: 0.0329\n",
      "Epoch 209/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0268 - val_loss: 0.0330\n",
      "Epoch 210/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0268 - val_loss: 0.0330\n",
      "Epoch 211/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0268 - val_loss: 0.0327\n",
      "Epoch 212/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0267 - val_loss: 0.0326\n",
      "Epoch 213/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0266 - val_loss: 0.0325\n",
      "Epoch 214/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0266 - val_loss: 0.0326\n",
      "Epoch 215/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0266 - val_loss: 0.0328\n",
      "Epoch 216/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0266 - val_loss: 0.0326\n",
      "Epoch 217/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0265 - val_loss: 0.0323\n",
      "Epoch 218/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0265 - val_loss: 0.0323\n",
      "Epoch 219/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0265 - val_loss: 0.0324\n",
      "Epoch 220/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0265 - val_loss: 0.0325\n",
      "Epoch 221/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0263 - val_loss: 0.0323\n",
      "Epoch 222/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0264 - val_loss: 0.0322\n",
      "Epoch 223/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0263 - val_loss: 0.0323\n",
      "Epoch 224/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0263 - val_loss: 0.0326\n",
      "Epoch 225/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0263 - val_loss: 0.0326\n",
      "Epoch 226/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0262 - val_loss: 0.0323\n",
      "Epoch 227/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0262 - val_loss: 0.0322\n",
      "Epoch 228/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0263 - val_loss: 0.0320\n",
      "Epoch 229/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0261 - val_loss: 0.0320\n",
      "Epoch 230/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0262 - val_loss: 0.0321\n",
      "Epoch 231/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0261 - val_loss: 0.0319\n",
      "Epoch 232/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0259 - val_loss: 0.0319\n",
      "Epoch 233/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0259 - val_loss: 0.0320\n",
      "Epoch 234/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0259 - val_loss: 0.0319\n",
      "Epoch 235/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 11us/step - loss: 0.0258 - val_loss: 0.0317\n",
      "Epoch 236/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0258 - val_loss: 0.0316\n",
      "Epoch 237/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0258 - val_loss: 0.0318\n",
      "Epoch 238/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0259 - val_loss: 0.0317\n",
      "Epoch 239/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0258 - val_loss: 0.0315\n",
      "Epoch 240/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0256 - val_loss: 0.0314\n",
      "Epoch 241/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0257 - val_loss: 0.0315\n",
      "Epoch 242/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0257 - val_loss: 0.0315\n",
      "Epoch 243/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0255 - val_loss: 0.0315\n",
      "Epoch 244/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0256 - val_loss: 0.0313\n",
      "Epoch 245/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0255 - val_loss: 0.0311\n",
      "Epoch 246/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0255 - val_loss: 0.0312\n",
      "Epoch 247/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0255 - val_loss: 0.0312\n",
      "Epoch 248/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0254 - val_loss: 0.0311\n",
      "Epoch 249/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0254 - val_loss: 0.0310\n",
      "Epoch 250/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0253 - val_loss: 0.0309\n",
      "Epoch 251/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0253 - val_loss: 0.0310\n",
      "Epoch 252/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0253 - val_loss: 0.0311\n",
      "Epoch 253/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0252 - val_loss: 0.0310\n",
      "Epoch 254/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0252 - val_loss: 0.0309\n",
      "Epoch 255/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0251 - val_loss: 0.0308\n",
      "Epoch 256/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0251 - val_loss: 0.0306\n",
      "Epoch 257/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0252 - val_loss: 0.0306\n",
      "Epoch 258/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0250 - val_loss: 0.0309\n",
      "Epoch 259/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0252 - val_loss: 0.0312\n",
      "Epoch 260/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0251 - val_loss: 0.0306\n",
      "Epoch 261/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0250 - val_loss: 0.0305\n",
      "Epoch 262/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0250 - val_loss: 0.0305\n",
      "Epoch 263/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0249 - val_loss: 0.0305\n",
      "Epoch 264/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0248 - val_loss: 0.0304\n",
      "Epoch 265/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0248 - val_loss: 0.0304\n",
      "Epoch 266/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0248 - val_loss: 0.0305\n",
      "Epoch 267/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0247 - val_loss: 0.0306\n",
      "Epoch 268/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0248 - val_loss: 0.0304\n",
      "Epoch 269/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0247 - val_loss: 0.0302\n",
      "Epoch 270/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0246 - val_loss: 0.0303\n",
      "Epoch 271/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0246 - val_loss: 0.0303\n",
      "Epoch 272/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0246 - val_loss: 0.0301\n",
      "Epoch 273/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0245 - val_loss: 0.0300\n",
      "Epoch 274/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0246 - val_loss: 0.0300\n",
      "Epoch 275/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0245 - val_loss: 0.0302\n",
      "Epoch 276/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0245 - val_loss: 0.0303\n",
      "Epoch 277/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0244 - val_loss: 0.0300\n",
      "Epoch 278/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0243 - val_loss: 0.0298\n",
      "Epoch 279/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0243 - val_loss: 0.0298\n",
      "Epoch 280/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0243 - val_loss: 0.0299\n",
      "Epoch 281/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0242 - val_loss: 0.0299\n",
      "Epoch 282/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0243 - val_loss: 0.0299\n",
      "Epoch 283/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0242 - val_loss: 0.0297\n",
      "Epoch 284/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0241 - val_loss: 0.0297\n",
      "Epoch 285/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0243 - val_loss: 0.0297\n",
      "Epoch 286/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0241 - val_loss: 0.0298\n",
      "Epoch 287/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0240 - val_loss: 0.0300\n",
      "Epoch 288/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0242 - val_loss: 0.0299\n",
      "Epoch 289/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0240 - val_loss: 0.0296\n",
      "Epoch 290/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0240 - val_loss: 0.0295\n",
      "Epoch 291/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0240 - val_loss: 0.0293\n",
      "Epoch 292/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0238 - val_loss: 0.0296\n",
      "Epoch 293/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0239 - val_loss: 0.0298\n",
      "Epoch 294/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0240 - val_loss: 0.0296\n",
      "Epoch 295/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0238 - val_loss: 0.0294\n",
      "Epoch 296/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0238 - val_loss: 0.0293\n",
      "Epoch 297/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0239 - val_loss: 0.0292\n",
      "Epoch 298/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0236 - val_loss: 0.0295\n",
      "Epoch 299/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0238 - val_loss: 0.0296\n",
      "Epoch 300/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0238 - val_loss: 0.0294\n",
      "Epoch 301/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0237 - val_loss: 0.0292\n",
      "Epoch 302/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0236 - val_loss: 0.0289\n",
      "Epoch 303/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0236 - val_loss: 0.0290\n",
      "Epoch 304/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0235 - val_loss: 0.0290\n",
      "Epoch 305/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0234 - val_loss: 0.0291\n",
      "Epoch 306/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0235 - val_loss: 0.0289\n",
      "Epoch 307/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0234 - val_loss: 0.0287\n",
      "Epoch 308/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0234 - val_loss: 0.0286\n",
      "Epoch 309/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0233 - val_loss: 0.0288\n",
      "Epoch 310/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0233 - val_loss: 0.0289\n",
      "Epoch 311/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0233 - val_loss: 0.0287\n",
      "Epoch 312/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0232 - val_loss: 0.0286\n",
      "Epoch 313/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 11us/step - loss: 0.0232 - val_loss: 0.0285\n",
      "Epoch 314/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0231 - val_loss: 0.0283\n",
      "Epoch 315/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0232 - val_loss: 0.0283\n",
      "Epoch 316/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0231 - val_loss: 0.0284\n",
      "Epoch 317/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0231 - val_loss: 0.0285\n",
      "Epoch 318/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0230 - val_loss: 0.0283\n",
      "Epoch 319/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0230 - val_loss: 0.0282\n",
      "Epoch 320/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0230 - val_loss: 0.0283\n",
      "Epoch 321/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0229 - val_loss: 0.0284\n",
      "Epoch 322/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0229 - val_loss: 0.0282\n",
      "Epoch 323/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0229 - val_loss: 0.0281\n",
      "Epoch 324/1200\n",
      "367/367 [==============================] - 0s 120us/step - loss: 0.0229 - val_loss: 0.0280\n",
      "Epoch 325/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0229 - val_loss: 0.0282\n",
      "Epoch 326/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0228 - val_loss: 0.0282\n",
      "Epoch 327/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0228 - val_loss: 0.0282\n",
      "Epoch 328/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0227 - val_loss: 0.0280\n",
      "Epoch 329/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0227 - val_loss: 0.0279\n",
      "Epoch 330/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0227 - val_loss: 0.0282\n",
      "Epoch 331/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0226 - val_loss: 0.0287\n",
      "Epoch 332/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0229 - val_loss: 0.0283\n",
      "Epoch 333/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0226 - val_loss: 0.0277\n",
      "Epoch 334/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0226 - val_loss: 0.0277\n",
      "Epoch 335/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0226 - val_loss: 0.0280\n",
      "Epoch 336/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0225 - val_loss: 0.0285\n",
      "Epoch 337/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0227 - val_loss: 0.0280\n",
      "Epoch 338/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0225 - val_loss: 0.0276\n",
      "Epoch 339/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0225 - val_loss: 0.0275\n",
      "Epoch 340/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0225 - val_loss: 0.0276\n",
      "Epoch 341/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0223 - val_loss: 0.0278\n",
      "Epoch 342/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0223 - val_loss: 0.0275\n",
      "Epoch 343/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0223 - val_loss: 0.0273\n",
      "Epoch 344/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0222 - val_loss: 0.0275\n",
      "Epoch 345/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0222 - val_loss: 0.0277\n",
      "Epoch 346/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0222 - val_loss: 0.0275\n",
      "Epoch 347/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0221 - val_loss: 0.0273\n",
      "Epoch 348/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0221 - val_loss: 0.0271\n",
      "Epoch 349/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0221 - val_loss: 0.0272\n",
      "Epoch 350/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0220 - val_loss: 0.0273\n",
      "Epoch 351/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0220 - val_loss: 0.0273\n",
      "Epoch 352/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0219 - val_loss: 0.0272\n",
      "Epoch 353/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0221 - val_loss: 0.0270\n",
      "Epoch 354/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0219 - val_loss: 0.0271\n",
      "Epoch 355/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0219 - val_loss: 0.0274\n",
      "Epoch 356/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0220 - val_loss: 0.0271\n",
      "Epoch 357/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0218 - val_loss: 0.0268\n",
      "Epoch 358/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0219 - val_loss: 0.0267\n",
      "Epoch 359/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0218 - val_loss: 0.0269\n",
      "Epoch 360/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0218 - val_loss: 0.0271\n",
      "Epoch 361/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0218 - val_loss: 0.0268\n",
      "Epoch 362/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0217 - val_loss: 0.0267\n",
      "Epoch 363/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0217 - val_loss: 0.0267\n",
      "Epoch 364/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0216 - val_loss: 0.0268\n",
      "Epoch 365/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0216 - val_loss: 0.0266\n",
      "Epoch 366/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0215 - val_loss: 0.0265\n",
      "Epoch 367/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0216 - val_loss: 0.0266\n",
      "Epoch 368/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0216 - val_loss: 0.0267\n",
      "Epoch 369/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0215 - val_loss: 0.0266\n",
      "Epoch 370/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0214 - val_loss: 0.0265\n",
      "Epoch 371/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0214 - val_loss: 0.0263\n",
      "Epoch 372/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0215 - val_loss: 0.0263\n",
      "Epoch 373/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0213 - val_loss: 0.0266\n",
      "Epoch 374/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0214 - val_loss: 0.0264\n",
      "Epoch 375/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0213 - val_loss: 0.0262\n",
      "Epoch 376/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0213 - val_loss: 0.0263\n",
      "Epoch 377/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0214 - val_loss: 0.0262\n",
      "Epoch 378/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0213 - val_loss: 0.0263\n",
      "Epoch 379/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0212 - val_loss: 0.0263\n",
      "Epoch 380/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0211 - val_loss: 0.0261\n",
      "Epoch 381/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0211 - val_loss: 0.0260\n",
      "Epoch 382/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0211 - val_loss: 0.0259\n",
      "Epoch 383/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0211 - val_loss: 0.0260\n",
      "Epoch 384/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0211 - val_loss: 0.0259\n",
      "Epoch 385/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0210 - val_loss: 0.0260\n",
      "Epoch 386/1200\n",
      "367/367 [==============================] - 0s 120us/step - loss: 0.0209 - val_loss: 0.0259\n",
      "Epoch 387/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0210 - val_loss: 0.0258\n",
      "Epoch 388/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0209 - val_loss: 0.0258\n",
      "Epoch 389/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0209 - val_loss: 0.0260\n",
      "Epoch 390/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0210 - val_loss: 0.0259\n",
      "Epoch 391/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 22us/step - loss: 0.0208 - val_loss: 0.0258\n",
      "Epoch 392/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0209 - val_loss: 0.0256\n",
      "Epoch 393/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0210 - val_loss: 0.0255\n",
      "Epoch 394/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0210 - val_loss: 0.0260\n",
      "Epoch 395/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0210 - val_loss: 0.0260\n",
      "Epoch 396/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0207 - val_loss: 0.0259\n",
      "Epoch 397/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0208 - val_loss: 0.0259\n",
      "Epoch 398/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0208 - val_loss: 0.0254\n",
      "Epoch 399/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0207 - val_loss: 0.0256\n",
      "Epoch 400/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0207 - val_loss: 0.0260\n",
      "Epoch 401/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0208 - val_loss: 0.0257\n",
      "Epoch 402/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0205 - val_loss: 0.0254\n",
      "Epoch 403/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0206 - val_loss: 0.0253\n",
      "Epoch 404/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0205 - val_loss: 0.0254\n",
      "Epoch 405/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0205 - val_loss: 0.0256\n",
      "Epoch 406/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0205 - val_loss: 0.0253\n",
      "Epoch 407/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0204 - val_loss: 0.0252\n",
      "Epoch 408/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0204 - val_loss: 0.0252\n",
      "Epoch 409/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0203 - val_loss: 0.0252\n",
      "Epoch 410/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0203 - val_loss: 0.0253\n",
      "Epoch 411/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0203 - val_loss: 0.0251\n",
      "Epoch 412/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0202 - val_loss: 0.0249\n",
      "Epoch 413/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0203 - val_loss: 0.0249\n",
      "Epoch 414/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0202 - val_loss: 0.0251\n",
      "Epoch 415/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0201 - val_loss: 0.0252\n",
      "Epoch 416/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0202 - val_loss: 0.0250\n",
      "Epoch 417/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0201 - val_loss: 0.0247\n",
      "Epoch 418/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0201 - val_loss: 0.0246\n",
      "Epoch 419/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0202 - val_loss: 0.0246\n",
      "Epoch 420/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0200 - val_loss: 0.0250\n",
      "Epoch 421/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0200 - val_loss: 0.0249\n",
      "Epoch 422/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0200 - val_loss: 0.0246\n",
      "Epoch 423/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0199 - val_loss: 0.0245\n",
      "Epoch 424/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0199 - val_loss: 0.0245\n",
      "Epoch 425/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0199 - val_loss: 0.0246\n",
      "Epoch 426/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0199 - val_loss: 0.0246\n",
      "Epoch 427/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0198 - val_loss: 0.0246\n",
      "Epoch 428/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0199 - val_loss: 0.0246\n",
      "Epoch 429/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0199 - val_loss: 0.0246\n",
      "Epoch 430/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0198 - val_loss: 0.0244\n",
      "Epoch 431/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0197 - val_loss: 0.0243\n",
      "Epoch 432/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0197 - val_loss: 0.0243\n",
      "Epoch 433/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0197 - val_loss: 0.0244\n",
      "Epoch 434/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0197 - val_loss: 0.0247\n",
      "Epoch 435/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0197 - val_loss: 0.0243\n",
      "Epoch 436/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0196 - val_loss: 0.0241\n",
      "Epoch 437/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0197 - val_loss: 0.0242\n",
      "Epoch 438/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0196 - val_loss: 0.0244\n",
      "Epoch 439/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0195 - val_loss: 0.0243\n",
      "Epoch 440/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0195 - val_loss: 0.0241\n",
      "Epoch 441/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0195 - val_loss: 0.0241\n",
      "Epoch 442/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0195 - val_loss: 0.0242\n",
      "Epoch 443/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0194 - val_loss: 0.0243\n",
      "Epoch 444/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0195 - val_loss: 0.0241\n",
      "Epoch 445/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0194 - val_loss: 0.0238\n",
      "Epoch 446/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0194 - val_loss: 0.0239\n",
      "Epoch 447/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0194 - val_loss: 0.0243\n",
      "Epoch 448/1200\n",
      "367/367 [==============================] - 0s 120us/step - loss: 0.0194 - val_loss: 0.0240\n",
      "Epoch 449/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0193 - val_loss: 0.0238\n",
      "Epoch 450/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0194 - val_loss: 0.0237\n",
      "Epoch 451/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0192 - val_loss: 0.0239\n",
      "Epoch 452/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0193 - val_loss: 0.0242\n",
      "Epoch 453/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0194 - val_loss: 0.0236\n",
      "Epoch 454/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0192 - val_loss: 0.0236\n",
      "Epoch 455/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0193 - val_loss: 0.0237\n",
      "Epoch 456/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0191 - val_loss: 0.0240\n",
      "Epoch 457/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0192 - val_loss: 0.0240\n",
      "Epoch 458/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0191 - val_loss: 0.0235\n",
      "Epoch 459/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0190 - val_loss: 0.0234\n",
      "Epoch 460/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0192 - val_loss: 0.0235\n",
      "Epoch 461/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0190 - val_loss: 0.0241\n",
      "Epoch 462/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0191 - val_loss: 0.0238\n",
      "Epoch 463/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0190 - val_loss: 0.0234\n",
      "Epoch 464/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0190 - val_loss: 0.0234\n",
      "Epoch 465/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0190 - val_loss: 0.0234\n",
      "Epoch 466/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0189 - val_loss: 0.0237\n",
      "Epoch 467/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0188 - val_loss: 0.0237\n",
      "Epoch 468/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0188 - val_loss: 0.0234\n",
      "Epoch 469/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 11us/step - loss: 0.0188 - val_loss: 0.0232\n",
      "Epoch 470/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0188 - val_loss: 0.0232\n",
      "Epoch 471/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0188 - val_loss: 0.0232\n",
      "Epoch 472/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0187 - val_loss: 0.0232\n",
      "Epoch 473/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0187 - val_loss: 0.0231\n",
      "Epoch 474/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0187 - val_loss: 0.0230\n",
      "Epoch 475/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0186 - val_loss: 0.0230\n",
      "Epoch 476/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0186 - val_loss: 0.0230\n",
      "Epoch 477/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0186 - val_loss: 0.0231\n",
      "Epoch 478/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0186 - val_loss: 0.0231\n",
      "Epoch 479/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0186 - val_loss: 0.0230\n",
      "Epoch 480/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0185 - val_loss: 0.0227\n",
      "Epoch 481/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0185 - val_loss: 0.0227\n",
      "Epoch 482/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0184 - val_loss: 0.0229\n",
      "Epoch 483/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0185 - val_loss: 0.0230\n",
      "Epoch 484/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0184 - val_loss: 0.0226\n",
      "Epoch 485/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0185 - val_loss: 0.0225\n",
      "Epoch 486/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0185 - val_loss: 0.0227\n",
      "Epoch 487/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0183 - val_loss: 0.0230\n",
      "Epoch 488/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0184 - val_loss: 0.0228\n",
      "Epoch 489/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0183 - val_loss: 0.0225\n",
      "Epoch 490/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0183 - val_loss: 0.0225\n",
      "Epoch 491/1200\n",
      "367/367 [==============================] - 0s 142us/step - loss: 0.0183 - val_loss: 0.0225\n",
      "Epoch 492/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0183 - val_loss: 0.0227\n",
      "Epoch 493/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0182 - val_loss: 0.0225\n",
      "Epoch 494/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0181 - val_loss: 0.0223\n",
      "Epoch 495/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0182 - val_loss: 0.0223\n",
      "Epoch 496/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0181 - val_loss: 0.0225\n",
      "Epoch 497/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0181 - val_loss: 0.0227\n",
      "Epoch 498/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0181 - val_loss: 0.0223\n",
      "Epoch 499/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0181 - val_loss: 0.0222\n",
      "Epoch 500/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0181 - val_loss: 0.0222\n",
      "Epoch 501/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0180 - val_loss: 0.0223\n",
      "Epoch 502/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0180 - val_loss: 0.0222\n",
      "Epoch 503/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0180 - val_loss: 0.0223\n",
      "Epoch 504/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0180 - val_loss: 0.0225\n",
      "Epoch 505/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0179 - val_loss: 0.0221\n",
      "Epoch 506/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0179 - val_loss: 0.0220\n",
      "Epoch 507/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0179 - val_loss: 0.0220\n",
      "Epoch 508/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0178 - val_loss: 0.0222\n",
      "Epoch 509/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0178 - val_loss: 0.0222\n",
      "Epoch 510/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0178 - val_loss: 0.0221\n",
      "Epoch 511/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0177 - val_loss: 0.0219\n",
      "Epoch 512/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0178 - val_loss: 0.0219\n",
      "Epoch 513/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0177 - val_loss: 0.0224\n",
      "Epoch 514/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0179 - val_loss: 0.0225\n",
      "Epoch 515/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0179 - val_loss: 0.0218\n",
      "Epoch 516/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0177 - val_loss: 0.0218\n",
      "Epoch 517/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0178 - val_loss: 0.0219\n",
      "Epoch 518/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0176 - val_loss: 0.0223\n",
      "Epoch 519/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0177 - val_loss: 0.0220\n",
      "Epoch 520/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0176 - val_loss: 0.0216\n",
      "Epoch 521/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0177 - val_loss: 0.0216\n",
      "Epoch 522/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0175 - val_loss: 0.0218\n",
      "Epoch 523/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0175 - val_loss: 0.0220\n",
      "Epoch 524/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0176 - val_loss: 0.0216\n",
      "Epoch 525/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0174 - val_loss: 0.0214\n",
      "Epoch 526/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0175 - val_loss: 0.0214\n",
      "Epoch 527/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0175 - val_loss: 0.0216\n",
      "Epoch 528/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0174 - val_loss: 0.0220\n",
      "Epoch 529/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0175 - val_loss: 0.0215\n",
      "Epoch 530/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0173 - val_loss: 0.0213\n",
      "Epoch 531/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0175 - val_loss: 0.0213\n",
      "Epoch 532/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0173 - val_loss: 0.0219\n",
      "Epoch 533/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0175 - val_loss: 0.0221\n",
      "Epoch 534/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0176 - val_loss: 0.0214\n",
      "Epoch 535/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0172 - val_loss: 0.0212\n",
      "Epoch 536/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0173 - val_loss: 0.0212\n",
      "Epoch 537/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0173 - val_loss: 0.0214\n",
      "Epoch 538/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0172 - val_loss: 0.0215\n",
      "Epoch 539/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0172 - val_loss: 0.0214\n",
      "Epoch 540/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0172 - val_loss: 0.0211\n",
      "Epoch 541/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0171 - val_loss: 0.0211\n",
      "Epoch 542/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0172 - val_loss: 0.0212\n",
      "Epoch 543/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0172 - val_loss: 0.0213\n",
      "Epoch 544/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0170 - val_loss: 0.0211\n",
      "Epoch 545/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0170 - val_loss: 0.0209\n",
      "Epoch 546/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0171 - val_loss: 0.0210\n",
      "Epoch 547/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 22us/step - loss: 0.0170 - val_loss: 0.0215\n",
      "Epoch 548/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0172 - val_loss: 0.0216\n",
      "Epoch 549/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0171 - val_loss: 0.0209\n",
      "Epoch 550/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0170 - val_loss: 0.0208\n",
      "Epoch 551/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0170 - val_loss: 0.0209\n",
      "Epoch 552/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0169 - val_loss: 0.0214\n",
      "Epoch 553/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0170 - val_loss: 0.0211\n",
      "Epoch 554/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0168 - val_loss: 0.0207\n",
      "Epoch 555/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0169 - val_loss: 0.0207\n",
      "Epoch 556/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0168 - val_loss: 0.0210\n",
      "Epoch 557/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0168 - val_loss: 0.0212\n",
      "Epoch 558/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0169 - val_loss: 0.0208\n",
      "Epoch 559/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0168 - val_loss: 0.0206\n",
      "Epoch 560/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0167 - val_loss: 0.0207\n",
      "Epoch 561/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0168 - val_loss: 0.0210\n",
      "Epoch 562/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0168 - val_loss: 0.0205\n",
      "Epoch 563/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0166 - val_loss: 0.0204\n",
      "Epoch 564/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0166 - val_loss: 0.0204\n",
      "Epoch 565/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0166 - val_loss: 0.0205\n",
      "Epoch 566/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0166 - val_loss: 0.0208\n",
      "Epoch 567/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0166 - val_loss: 0.0205\n",
      "Epoch 568/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0166 - val_loss: 0.0203\n",
      "Epoch 569/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0167 - val_loss: 0.0203\n",
      "Epoch 570/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0165 - val_loss: 0.0204\n",
      "Epoch 571/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0165 - val_loss: 0.0206\n",
      "Epoch 572/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0165 - val_loss: 0.0206\n",
      "Epoch 573/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0165 - val_loss: 0.0204\n",
      "Epoch 574/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0164 - val_loss: 0.0203\n",
      "Epoch 575/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0164 - val_loss: 0.0203\n",
      "Epoch 576/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0164 - val_loss: 0.0203\n",
      "Epoch 577/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0164 - val_loss: 0.0203\n",
      "Epoch 578/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0163 - val_loss: 0.0203\n",
      "Epoch 579/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0164 - val_loss: 0.0201\n",
      "Epoch 580/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0164 - val_loss: 0.0202\n",
      "Epoch 581/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0164 - val_loss: 0.0206\n",
      "Epoch 582/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0164 - val_loss: 0.0201\n",
      "Epoch 583/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0163 - val_loss: 0.0201\n",
      "Epoch 584/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0165 - val_loss: 0.0200\n",
      "Epoch 585/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0164 - val_loss: 0.0203\n",
      "Epoch 586/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0163 - val_loss: 0.0201\n",
      "Epoch 587/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0162 - val_loss: 0.0200\n",
      "Epoch 588/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0162 - val_loss: 0.0200\n",
      "Epoch 589/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0162 - val_loss: 0.0198\n",
      "Epoch 590/1200\n",
      "367/367 [==============================] - 0s 8us/step - loss: 0.0161 - val_loss: 0.0199\n",
      "Epoch 591/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0162 - val_loss: 0.0201\n",
      "Epoch 592/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0161 - val_loss: 0.0202\n",
      "Epoch 593/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0163 - val_loss: 0.0200\n",
      "Epoch 594/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0161 - val_loss: 0.0197\n",
      "Epoch 595/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0160 - val_loss: 0.0199\n",
      "Epoch 596/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0161 - val_loss: 0.0199\n",
      "Epoch 597/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0160 - val_loss: 0.0200\n",
      "Epoch 598/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0161 - val_loss: 0.0198\n",
      "Epoch 599/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0160 - val_loss: 0.0195\n",
      "Epoch 600/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0160 - val_loss: 0.0196\n",
      "Epoch 601/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0161 - val_loss: 0.0200\n",
      "Epoch 602/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0160 - val_loss: 0.0199\n",
      "Epoch 603/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0159 - val_loss: 0.0198\n",
      "Epoch 604/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0160 - val_loss: 0.0195\n",
      "Epoch 605/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0159 - val_loss: 0.0196\n",
      "Epoch 606/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0158 - val_loss: 0.0196\n",
      "Epoch 607/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0158 - val_loss: 0.0194\n",
      "Epoch 608/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0158 - val_loss: 0.0193\n",
      "Epoch 609/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0158 - val_loss: 0.0193\n",
      "Epoch 610/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0158 - val_loss: 0.0195\n",
      "Epoch 611/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0158 - val_loss: 0.0195\n",
      "Epoch 612/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0157 - val_loss: 0.0195\n",
      "Epoch 613/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0157 - val_loss: 0.0193\n",
      "Epoch 614/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0157 - val_loss: 0.0192\n",
      "Epoch 615/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0158 - val_loss: 0.0193\n",
      "Epoch 616/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0157 - val_loss: 0.0196\n",
      "Epoch 617/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0157 - val_loss: 0.0194\n",
      "Epoch 618/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0156 - val_loss: 0.0191\n",
      "Epoch 619/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0157 - val_loss: 0.0191\n",
      "Epoch 620/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0156 - val_loss: 0.0194\n",
      "Epoch 621/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0156 - val_loss: 0.0192\n",
      "Epoch 622/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0156 - val_loss: 0.0191\n",
      "Epoch 623/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0155 - val_loss: 0.0192\n",
      "Epoch 624/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0155 - val_loss: 0.0193\n",
      "Epoch 625/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 11us/step - loss: 0.0155 - val_loss: 0.0191\n",
      "Epoch 626/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0155 - val_loss: 0.0191\n",
      "Epoch 627/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0155 - val_loss: 0.0192\n",
      "Epoch 628/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0154 - val_loss: 0.0190\n",
      "Epoch 629/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0155 - val_loss: 0.0190\n",
      "Epoch 630/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0154 - val_loss: 0.0193\n",
      "Epoch 631/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0155 - val_loss: 0.0190\n",
      "Epoch 632/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0154 - val_loss: 0.0188\n",
      "Epoch 633/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0154 - val_loss: 0.0189\n",
      "Epoch 634/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0153 - val_loss: 0.0194\n",
      "Epoch 635/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0155 - val_loss: 0.0191\n",
      "Epoch 636/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0153 - val_loss: 0.0188\n",
      "Epoch 637/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0154 - val_loss: 0.0188\n",
      "Epoch 638/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0153 - val_loss: 0.0189\n",
      "Epoch 639/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0153 - val_loss: 0.0189\n",
      "Epoch 640/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0152 - val_loss: 0.0187\n",
      "Epoch 641/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0153 - val_loss: 0.0187\n",
      "Epoch 642/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0152 - val_loss: 0.0190\n",
      "Epoch 643/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0152 - val_loss: 0.0193\n",
      "Epoch 644/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0153 - val_loss: 0.0189\n",
      "Epoch 645/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0151 - val_loss: 0.0186\n",
      "Epoch 646/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0153 - val_loss: 0.0186\n",
      "Epoch 647/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0152 - val_loss: 0.0189\n",
      "Epoch 648/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0152 - val_loss: 0.0188\n",
      "Epoch 649/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0151 - val_loss: 0.0186\n",
      "Epoch 650/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0151 - val_loss: 0.0186\n",
      "Epoch 651/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0151 - val_loss: 0.0186\n",
      "Epoch 652/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0151 - val_loss: 0.0185\n",
      "Epoch 653/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0150 - val_loss: 0.0184\n",
      "Epoch 654/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0150 - val_loss: 0.0185\n",
      "Epoch 655/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0150 - val_loss: 0.0184\n",
      "Epoch 656/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0149 - val_loss: 0.0184\n",
      "Epoch 657/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0150 - val_loss: 0.0184\n",
      "Epoch 658/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0150 - val_loss: 0.0183\n",
      "Epoch 659/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0149 - val_loss: 0.0186\n",
      "Epoch 660/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0151 - val_loss: 0.0188\n",
      "Epoch 661/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0150 - val_loss: 0.0182\n",
      "Epoch 662/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0151 - val_loss: 0.0181\n",
      "Epoch 663/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0149 - val_loss: 0.0185\n",
      "Epoch 664/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0149 - val_loss: 0.0187\n",
      "Epoch 665/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0149 - val_loss: 0.0183\n",
      "Epoch 666/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0148 - val_loss: 0.0182\n",
      "Epoch 667/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0150 - val_loss: 0.0183\n",
      "Epoch 668/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0148 - val_loss: 0.0189\n",
      "Epoch 669/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0150 - val_loss: 0.0185\n",
      "Epoch 670/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0147 - val_loss: 0.0181\n",
      "Epoch 671/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0151 - val_loss: 0.0181\n",
      "Epoch 672/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0150 - val_loss: 0.0184\n",
      "Epoch 673/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0148 - val_loss: 0.0185\n",
      "Epoch 674/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0148 - val_loss: 0.0181\n",
      "Epoch 675/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0147 - val_loss: 0.0180\n",
      "Epoch 676/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0147 - val_loss: 0.0182\n",
      "Epoch 677/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0146 - val_loss: 0.0182\n",
      "Epoch 678/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0147 - val_loss: 0.0181\n",
      "Epoch 679/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0147 - val_loss: 0.0179\n",
      "Epoch 680/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0146 - val_loss: 0.0180\n",
      "Epoch 681/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0146 - val_loss: 0.0179\n",
      "Epoch 682/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0146 - val_loss: 0.0178\n",
      "Epoch 683/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0146 - val_loss: 0.0180\n",
      "Epoch 684/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0145 - val_loss: 0.0179\n",
      "Epoch 685/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0145 - val_loss: 0.0179\n",
      "Epoch 686/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0146 - val_loss: 0.0178\n",
      "Epoch 687/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0145 - val_loss: 0.0176\n",
      "Epoch 688/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0146 - val_loss: 0.0178\n",
      "Epoch 689/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0144 - val_loss: 0.0180\n",
      "Epoch 690/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0145 - val_loss: 0.0179\n",
      "Epoch 691/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0146 - val_loss: 0.0177\n",
      "Epoch 692/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0144 - val_loss: 0.0179\n",
      "Epoch 693/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0146 - val_loss: 0.0178\n",
      "Epoch 694/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0144 - val_loss: 0.0179\n",
      "Epoch 695/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0147 - val_loss: 0.0177\n",
      "Epoch 696/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0145 - val_loss: 0.0177\n",
      "Epoch 697/1200\n",
      "367/367 [==============================] - 0s 120us/step - loss: 0.0145 - val_loss: 0.0179\n",
      "Epoch 698/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0145 - val_loss: 0.0175\n",
      "Epoch 699/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0144 - val_loss: 0.0176\n",
      "Epoch 700/1200\n",
      "367/367 [==============================] - 0s 0us/step - loss: 0.0144 - val_loss: 0.0177\n",
      "Epoch 701/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0144 - val_loss: 0.0179\n",
      "Epoch 702/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0144 - val_loss: 0.0175\n",
      "Epoch 703/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 11us/step - loss: 0.0143 - val_loss: 0.0174\n",
      "Epoch 704/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0143 - val_loss: 0.0175\n",
      "Epoch 705/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0142 - val_loss: 0.0177\n",
      "Epoch 706/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0142 - val_loss: 0.0176\n",
      "Epoch 707/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0142 - val_loss: 0.0173\n",
      "Epoch 708/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0142 - val_loss: 0.0173\n",
      "Epoch 709/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0142 - val_loss: 0.0175\n",
      "Epoch 710/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0144 - val_loss: 0.0177\n",
      "Epoch 711/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0142 - val_loss: 0.0172\n",
      "Epoch 712/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0144 - val_loss: 0.0172\n",
      "Epoch 713/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0142 - val_loss: 0.0177\n",
      "Epoch 714/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0144 - val_loss: 0.0181\n",
      "Epoch 715/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0144 - val_loss: 0.0172\n",
      "Epoch 716/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0142 - val_loss: 0.0171\n",
      "Epoch 717/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0142 - val_loss: 0.0173\n",
      "Epoch 718/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0142 - val_loss: 0.0178\n",
      "Epoch 719/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0142 - val_loss: 0.0172\n",
      "Epoch 720/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0140 - val_loss: 0.0170\n",
      "Epoch 721/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0141 - val_loss: 0.0170\n",
      "Epoch 722/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0140 - val_loss: 0.0171\n",
      "Epoch 723/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0140 - val_loss: 0.0172\n",
      "Epoch 724/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0140 - val_loss: 0.0169\n",
      "Epoch 725/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0141 - val_loss: 0.0168\n",
      "Epoch 726/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0139 - val_loss: 0.0173\n",
      "Epoch 727/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0141 - val_loss: 0.0176\n",
      "Epoch 728/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0142 - val_loss: 0.0170\n",
      "Epoch 729/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0140 - val_loss: 0.0170\n",
      "Epoch 730/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0140 - val_loss: 0.0169\n",
      "Epoch 731/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0139 - val_loss: 0.0170\n",
      "Epoch 732/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0139 - val_loss: 0.0169\n",
      "Epoch 733/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0138 - val_loss: 0.0169\n",
      "Epoch 734/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0138 - val_loss: 0.0170\n",
      "Epoch 735/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0138 - val_loss: 0.0168\n",
      "Epoch 736/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0138 - val_loss: 0.0168\n",
      "Epoch 737/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0138 - val_loss: 0.0168\n",
      "Epoch 738/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0138 - val_loss: 0.0169\n",
      "Epoch 739/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0138 - val_loss: 0.0169\n",
      "Epoch 740/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0138 - val_loss: 0.0169\n",
      "Epoch 741/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0138 - val_loss: 0.0169\n",
      "Epoch 742/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0138 - val_loss: 0.0167\n",
      "Epoch 743/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0138 - val_loss: 0.0166\n",
      "Epoch 744/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0138 - val_loss: 0.0165\n",
      "Epoch 745/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0137 - val_loss: 0.0169\n",
      "Epoch 746/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0138 - val_loss: 0.0168\n",
      "Epoch 747/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0136 - val_loss: 0.0166\n",
      "Epoch 748/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0138 - val_loss: 0.0166\n",
      "Epoch 749/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0137 - val_loss: 0.0167\n",
      "Epoch 750/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0136 - val_loss: 0.0172\n",
      "Epoch 751/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0139 - val_loss: 0.0166\n",
      "Epoch 752/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0138 - val_loss: 0.0166\n",
      "Epoch 753/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0137 - val_loss: 0.0168\n",
      "Epoch 754/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0136 - val_loss: 0.0171\n",
      "Epoch 755/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0137 - val_loss: 0.0168\n",
      "Epoch 756/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0137 - val_loss: 0.0165\n",
      "Epoch 757/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0136 - val_loss: 0.0166\n",
      "Epoch 758/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0136 - val_loss: 0.0167\n",
      "Epoch 759/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0136 - val_loss: 0.0165\n",
      "Epoch 760/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0135 - val_loss: 0.0164\n",
      "Epoch 761/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0135 - val_loss: 0.0165\n",
      "Epoch 762/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0135 - val_loss: 0.0165\n",
      "Epoch 763/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0166\n",
      "Epoch 764/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0135 - val_loss: 0.0166\n",
      "Epoch 765/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0135 - val_loss: 0.0163\n",
      "Epoch 766/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0164\n",
      "Epoch 767/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0135 - val_loss: 0.0163\n",
      "Epoch 768/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0165\n",
      "Epoch 769/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0135 - val_loss: 0.0164\n",
      "Epoch 770/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0161\n",
      "Epoch 771/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0136 - val_loss: 0.0165\n",
      "Epoch 772/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0138 - val_loss: 0.0165\n",
      "Epoch 773/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0162\n",
      "Epoch 774/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0161\n",
      "Epoch 775/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0162\n",
      "Epoch 776/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0135 - val_loss: 0.0162\n",
      "Epoch 777/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0161\n",
      "Epoch 778/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0161\n",
      "Epoch 779/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0133 - val_loss: 0.0163\n",
      "Epoch 780/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0162\n",
      "Epoch 781/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0161\n",
      "Epoch 782/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0161\n",
      "Epoch 783/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0160\n",
      "Epoch 784/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0160\n",
      "Epoch 785/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0132 - val_loss: 0.0160\n",
      "Epoch 786/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0161\n",
      "Epoch 787/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0160\n",
      "Epoch 788/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0159\n",
      "Epoch 789/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0133 - val_loss: 0.0159\n",
      "Epoch 790/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0165\n",
      "Epoch 791/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0162\n",
      "Epoch 792/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0158\n",
      "Epoch 793/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0133 - val_loss: 0.0158\n",
      "Epoch 794/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0162\n",
      "Epoch 795/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0131 - val_loss: 0.0159\n",
      "Epoch 796/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0158\n",
      "Epoch 797/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0158\n",
      "Epoch 798/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0130 - val_loss: 0.0158\n",
      "Epoch 799/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0160\n",
      "Epoch 800/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0131 - val_loss: 0.0159\n",
      "Epoch 801/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0156\n",
      "Epoch 802/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0157\n",
      "Epoch 803/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0160\n",
      "Epoch 804/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0131 - val_loss: 0.0162\n",
      "Epoch 805/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0131 - val_loss: 0.0157\n",
      "Epoch 806/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0129 - val_loss: 0.0157\n",
      "Epoch 807/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0158\n",
      "Epoch 808/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0159\n",
      "Epoch 809/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0157\n",
      "Epoch 810/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0130 - val_loss: 0.0155\n",
      "Epoch 811/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0157\n",
      "Epoch 812/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0129 - val_loss: 0.0161\n",
      "Epoch 813/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0130 - val_loss: 0.0158\n",
      "Epoch 814/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0129 - val_loss: 0.0155\n",
      "Epoch 815/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 816/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0130 - val_loss: 0.0156\n",
      "Epoch 817/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0128 - val_loss: 0.0158\n",
      "Epoch 818/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0129 - val_loss: 0.0157\n",
      "Epoch 819/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0128 - val_loss: 0.0155\n",
      "Epoch 820/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0128 - val_loss: 0.0155\n",
      "Epoch 821/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 822/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0129 - val_loss: 0.0155\n",
      "Epoch 823/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0128 - val_loss: 0.0154\n",
      "Epoch 824/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 825/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 826/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0156\n",
      "Epoch 827/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 828/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 829/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 830/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 831/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 832/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 833/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0127 - val_loss: 0.0153\n",
      "Epoch 834/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0152\n",
      "Epoch 835/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0152\n",
      "Epoch 836/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0152\n",
      "Epoch 837/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 838/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0126 - val_loss: 0.0153\n",
      "Epoch 839/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0154\n",
      "Epoch 840/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 841/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0128 - val_loss: 0.0153\n",
      "Epoch 842/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0152\n",
      "Epoch 843/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 844/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0154\n",
      "Epoch 845/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 846/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0151\n",
      "Epoch 847/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0151\n",
      "Epoch 848/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 849/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0152\n",
      "Epoch 850/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0125 - val_loss: 0.0150\n",
      "Epoch 851/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0150\n",
      "Epoch 852/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0155\n",
      "Epoch 853/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0155\n",
      "Epoch 854/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0151\n",
      "Epoch 855/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0125 - val_loss: 0.0150\n",
      "Epoch 856/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0125 - val_loss: 0.0150\n",
      "Epoch 857/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 858/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 859/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0149\n",
      "Epoch 860/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0150\n",
      "Epoch 861/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0153\n",
      "Epoch 862/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 863/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0149\n",
      "Epoch 864/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 865/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 866/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 867/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0149\n",
      "Epoch 868/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 869/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0123 - val_loss: 0.0148\n",
      "Epoch 870/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0148\n",
      "Epoch 871/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 872/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0149\n",
      "Epoch 873/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0123 - val_loss: 0.0148\n",
      "Epoch 874/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0123 - val_loss: 0.0148\n",
      "Epoch 875/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 876/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 877/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 878/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0123 - val_loss: 0.0149\n",
      "Epoch 879/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 880/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0123 - val_loss: 0.0148\n",
      "Epoch 881/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 882/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 883/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 884/1200\n",
      "367/367 [==============================] - 0s 120us/step - loss: 0.0122 - val_loss: 0.0149\n",
      "Epoch 885/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0149\n",
      "Epoch 886/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 887/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 888/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 889/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0147\n",
      "Epoch 890/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 891/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 892/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 893/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 894/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 895/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 896/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 897/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0121 - val_loss: 0.0146\n",
      "Epoch 898/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0145\n",
      "Epoch 899/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 900/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 901/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0120 - val_loss: 0.0148\n",
      "Epoch 902/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0146\n",
      "Epoch 903/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 904/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 905/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 906/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0149\n",
      "Epoch 907/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 908/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0142\n",
      "Epoch 909/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0143\n",
      "Epoch 910/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0145\n",
      "Epoch 911/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0120 - val_loss: 0.0145\n",
      "Epoch 912/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 913/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0119 - val_loss: 0.0143\n",
      "Epoch 914/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0119 - val_loss: 0.0144\n",
      "Epoch 915/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0119 - val_loss: 0.0146\n",
      "Epoch 916/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0144\n",
      "Epoch 917/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0119 - val_loss: 0.0143\n",
      "Epoch 918/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0142\n",
      "Epoch 919/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0120 - val_loss: 0.0143\n",
      "Epoch 920/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0119 - val_loss: 0.0145\n",
      "Epoch 921/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0142\n",
      "Epoch 922/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0119 - val_loss: 0.0141\n",
      "Epoch 923/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0141\n",
      "Epoch 924/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0118 - val_loss: 0.0148\n",
      "Epoch 925/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0150\n",
      "Epoch 926/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0141\n",
      "Epoch 927/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0142\n",
      "Epoch 928/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0121 - val_loss: 0.0147\n",
      "Epoch 929/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0147\n",
      "Epoch 930/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 931/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0140\n",
      "Epoch 932/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0145\n",
      "Epoch 933/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0121 - val_loss: 0.0142\n",
      "Epoch 934/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0118 - val_loss: 0.0142\n",
      "Epoch 935/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0141\n",
      "Epoch 936/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0117 - val_loss: 0.0143\n",
      "Epoch 937/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 11us/step - loss: 0.0119 - val_loss: 0.0144\n",
      "Epoch 938/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0120 - val_loss: 0.0140\n",
      "Epoch 939/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0118 - val_loss: 0.0142\n",
      "Epoch 940/1200\n",
      "367/367 [==============================] - 0s 0us/step - loss: 0.0118 - val_loss: 0.0142\n",
      "Epoch 941/1200\n",
      "367/367 [==============================] - 0s 0us/step - loss: 0.0117 - val_loss: 0.0140\n",
      "Epoch 942/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 943/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0117 - val_loss: 0.0141\n",
      "Epoch 944/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0119 - val_loss: 0.0142\n",
      "Epoch 945/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 946/1200\n",
      "367/367 [==============================] - 0s 98us/step - loss: 0.0117 - val_loss: 0.0141\n",
      "Epoch 947/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 948/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0117 - val_loss: 0.0140\n",
      "Epoch 949/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 950/1200\n",
      "367/367 [==============================] - 0s 0us/step - loss: 0.0119 - val_loss: 0.0139\n",
      "Epoch 951/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0117 - val_loss: 0.0145\n",
      "Epoch 952/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0119 - val_loss: 0.0141\n",
      "Epoch 953/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 954/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0117 - val_loss: 0.0140\n",
      "Epoch 955/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0117 - val_loss: 0.0144\n",
      "Epoch 956/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 957/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0116 - val_loss: 0.0138\n",
      "Epoch 958/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0118 - val_loss: 0.0138\n",
      "Epoch 959/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 960/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 961/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0116 - val_loss: 0.0140\n",
      "Epoch 962/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0116 - val_loss: 0.0141\n",
      "Epoch 963/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0116 - val_loss: 0.0138\n",
      "Epoch 964/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0116 - val_loss: 0.0137\n",
      "Epoch 965/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 966/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0116 - val_loss: 0.0140\n",
      "Epoch 967/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 968/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0116 - val_loss: 0.0137\n",
      "Epoch 969/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0116 - val_loss: 0.0137\n",
      "Epoch 970/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0116 - val_loss: 0.0138\n",
      "Epoch 971/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 972/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 973/1200\n",
      "367/367 [==============================] - 0s 0us/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 974/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 975/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 976/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 977/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 978/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 979/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0136\n",
      "Epoch 980/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0136\n",
      "Epoch 981/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0115 - val_loss: 0.0136\n",
      "Epoch 982/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 983/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0137\n",
      "Epoch 984/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0136\n",
      "Epoch 985/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0137\n",
      "Epoch 986/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0137\n",
      "Epoch 987/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 988/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 989/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0136\n",
      "Epoch 990/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0137\n",
      "Epoch 991/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 992/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0136\n",
      "Epoch 993/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0140\n",
      "Epoch 994/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 995/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0134\n",
      "Epoch 996/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 997/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0114 - val_loss: 0.0141\n",
      "Epoch 998/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0116 - val_loss: 0.0138\n",
      "Epoch 999/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0134\n",
      "Epoch 1000/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0116 - val_loss: 0.0135\n",
      "Epoch 1001/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0140\n",
      "Epoch 1002/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0116 - val_loss: 0.0138\n",
      "Epoch 1003/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0134\n",
      "Epoch 1004/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 1005/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0114 - val_loss: 0.0138\n",
      "Epoch 1006/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0138\n",
      "Epoch 1007/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0134\n",
      "Epoch 1008/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0133\n",
      "Epoch 1009/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0113 - val_loss: 0.0139\n",
      "Epoch 1010/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0136\n",
      "Epoch 1011/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0133\n",
      "Epoch 1012/1200\n",
      "367/367 [==============================] - 0s 0us/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 1013/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 1014/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 1015/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 11us/step - loss: 0.0115 - val_loss: 0.0133\n",
      "Epoch 1016/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0137\n",
      "Epoch 1017/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0134\n",
      "Epoch 1018/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 1019/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0133\n",
      "Epoch 1020/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 1021/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0133\n",
      "Epoch 1022/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 1023/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 1024/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 1025/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0113 - val_loss: 0.0132\n",
      "Epoch 1026/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 1027/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 1028/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0112 - val_loss: 0.0133\n",
      "Epoch 1029/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0136\n",
      "Epoch 1030/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 1031/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 1032/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 1033/1200\n",
      "367/367 [==============================] - 0s 0us/step - loss: 0.0112 - val_loss: 0.0133\n",
      "Epoch 1034/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0132\n",
      "Epoch 1035/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0111 - val_loss: 0.0131\n",
      "Epoch 1036/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 1037/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 1038/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 1039/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 1040/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 1041/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 1042/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 1043/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0111 - val_loss: 0.0133\n",
      "Epoch 1044/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 1045/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 1046/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 1047/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0111 - val_loss: 0.0129\n",
      "Epoch 1048/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0130\n",
      "Epoch 1049/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 1050/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 1051/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0111 - val_loss: 0.0129\n",
      "Epoch 1052/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0111 - val_loss: 0.0129\n",
      "Epoch 1053/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0130\n",
      "Epoch 1054/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0113 - val_loss: 0.0132\n",
      "Epoch 1055/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 1056/1200\n",
      "367/367 [==============================] - 0s 0us/step - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 1057/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0111 - val_loss: 0.0135\n",
      "Epoch 1058/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 1059/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 1060/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0115 - val_loss: 0.0128\n",
      "Epoch 1061/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0114 - val_loss: 0.0134\n",
      "Epoch 1062/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 1063/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 1064/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 1065/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0109 - val_loss: 0.0132\n",
      "Epoch 1066/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0110 - val_loss: 0.0132\n",
      "Epoch 1067/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0110 - val_loss: 0.0128\n",
      "Epoch 1068/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 1069/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0111 - val_loss: 0.0128\n",
      "Epoch 1070/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0110 - val_loss: 0.0131\n",
      "Epoch 1071/1200\n",
      "367/367 [==============================] - 0s 87us/step - loss: 0.0110 - val_loss: 0.0128\n",
      "Epoch 1072/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0109 - val_loss: 0.0127\n",
      "Epoch 1073/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0110 - val_loss: 0.0128\n",
      "Epoch 1074/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0110 - val_loss: 0.0128\n",
      "Epoch 1075/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 1076/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 1077/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 1078/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0110 - val_loss: 0.0130\n",
      "Epoch 1079/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0110 - val_loss: 0.0132\n",
      "Epoch 1080/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0110 - val_loss: 0.0130\n",
      "Epoch 1081/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 1082/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 1083/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 1084/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 1085/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0109 - val_loss: 0.0127\n",
      "Epoch 1086/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 1087/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0111 - val_loss: 0.0130\n",
      "Epoch 1088/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 1089/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0111 - val_loss: 0.0126\n",
      "Epoch 1090/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0110 - val_loss: 0.0126\n",
      "Epoch 1091/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 1092/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 11us/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 1093/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 1094/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0109 - val_loss: 0.0127\n",
      "Epoch 1095/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 1096/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 1097/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0109 - val_loss: 0.0126\n",
      "Epoch 1098/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 1099/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 1100/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0127\n",
      "Epoch 1101/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 1102/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 1103/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 1104/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0125\n",
      "Epoch 1105/1200\n",
      "367/367 [==============================] - 0s 0us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 1106/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0110 - val_loss: 0.0130\n",
      "Epoch 1107/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 1108/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0109 - val_loss: 0.0125\n",
      "Epoch 1109/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0108 - val_loss: 0.0127\n",
      "Epoch 1110/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0131\n",
      "Epoch 1111/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 1112/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 1113/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 1114/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 1115/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0109 - val_loss: 0.0126\n",
      "Epoch 1116/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 1117/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0109 - val_loss: 0.0124\n",
      "Epoch 1118/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 1119/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 1120/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 1121/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 1122/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0126\n",
      "Epoch 1123/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 1124/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 1125/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 1126/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 1127/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0125\n",
      "Epoch 1128/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 1129/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 1130/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 1131/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 1132/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0127\n",
      "Epoch 1133/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0107 - val_loss: 0.0126\n",
      "Epoch 1134/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 1135/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 1136/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0129\n",
      "Epoch 1137/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0109 - val_loss: 0.0126\n",
      "Epoch 1138/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 1139/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 1140/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0107 - val_loss: 0.0125\n",
      "Epoch 1141/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 1142/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0126\n",
      "Epoch 1143/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 1144/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 1145/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 1146/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 1147/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 1148/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 1149/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 1150/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 1151/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0126\n",
      "Epoch 1152/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 1153/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 1154/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 1155/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 1156/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 1157/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 1158/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 1159/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 1160/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 1161/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 1162/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 1163/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 1164/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0129\n",
      "Epoch 1165/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 1166/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 1167/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 1168/1200\n",
      "367/367 [==============================] - 0s 20us/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 1169/1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 0s 12us/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 1170/1200\n",
      "367/367 [==============================] - 0s 12us/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 1171/1200\n",
      "367/367 [==============================] - 0s 12us/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 1172/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 1173/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 1174/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 1175/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 1176/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 1177/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 1178/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 1179/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 1180/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 1181/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 1182/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 1183/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0107 - val_loss: 0.0120\n",
      "Epoch 1184/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 1185/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 1186/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 1187/1200\n",
      "367/367 [==============================] - 0s 33us/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 1188/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 1189/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0104 - val_loss: 0.0121\n",
      "Epoch 1190/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 1191/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 1192/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 1193/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0106 - val_loss: 0.0120\n",
      "Epoch 1194/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 1195/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0107 - val_loss: 0.0120\n",
      "Epoch 1196/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0105 - val_loss: 0.0125\n",
      "Epoch 1197/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 1198/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 1199/1200\n",
      "367/367 [==============================] - 0s 22us/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 1200/1200\n",
      "367/367 [==============================] - 0s 11us/step - loss: 0.0105 - val_loss: 0.0122\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/NN_1_layer_16_nodes.py\n",
    "\n",
    "H = 40 # number of nodes in the layer\n",
    "input_dim = 1 # input dimension: just x\n",
    "\n",
    "model2 = models.Sequential() # create sequential multi-layer perceptron\n",
    "\n",
    "# layer 0, our hidden layer\n",
    "model2.add(layers.Dense(H, input_dim=input_dim, \n",
    "                kernel_initializer='normal', \n",
    "                activation='relu')) \n",
    "# layer 1\n",
    "model2.add(layers.Dense(1, kernel_initializer='normal', \n",
    "                activation='linear')) \n",
    "\n",
    "# compile the model\n",
    "model2.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# fit the model\n",
    "model2_history = model2.fit(X_train, Y_train, batch_size=256, epochs=1200, verbose=1, \\\n",
    "                          shuffle = True, validation_split=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the loss smaller now? You may access the results in a model by its `.history`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01053534220518387"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_history.history['loss'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again let's use the new model to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use our model to predict in the range we want\n",
    "X_range = np.linspace(-10, 10, 1000)\n",
    "y_pred = model2.predict(X_range)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=FIG_SIZE)\n",
    "ax.scatter(X_train, Y_train, label='Training data', alpha=0.3)\n",
    "ax.scatter(X_test, Y_test, label='Testing data' , alpha=0.3)\n",
    "ax.plot(X_range, y_pred, lw=4, color='r', label=f'NN with one hidden layer and {H} nodes')\n",
    "ax.set_xlabel(r'$X$', fontsize=FONT_SIZE)\n",
    "ax.set_ylabel(r'$Y$', fontsize=FONT_SIZE)\n",
    "ax.set_title(f'NN with {len(model2_history.model.layers)-1} layers, {H} nodes in each layer', fontsize=LABEL_SIZE)\n",
    "ax.tick_params(labelsize=LABEL_SIZE)\n",
    "\n",
    "ax.legend(loc=0, fontsize=FONT_SIZE)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 3:</b>\n",
    "</div>\n",
    "\n",
    "Plot the loss function as a function of the epochs. <b>Hint:</b> You can access the loss function values with the command:`model_history.history['loss']`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load solutions/print_history.py\n",
    "fig, ax = plt.subplots(1, 1, figsize=FIG_SIZE)\n",
    "ax.plot(np.sqrt(model2_history.history['loss']), 'r')\n",
    "ax.plot(np.sqrt(model2_history.history['val_loss']), 'b' ,label='Val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=FONT_SIZE)\n",
    "ax.set_ylabel(r'Loss', fontsize=FONT_SIZE)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=LABEL_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is the model?  We can compute the $R^{2}$ score to get a sense of the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735/735 [==============================] - 0s 125us/step\n",
      "Train loss: 0.012401290595227358\n",
      "Train R2: 0.8016549182866487\n",
      "315/315 [==============================] - 0s 25us/step\n",
      "Test loss: 0.013341756981043588\n",
      "Test R2: 0.8006992954368132\n"
     ]
    }
   ],
   "source": [
    "# evaluate the training and testing performance of your model \n",
    "# note: you should extract and check both the loss function and your evaluation metric\n",
    "from sklearn.metrics import r2_score as r2\n",
    "\n",
    "train_score = model.evaluate(X_train, Y_train, verbose=1)\n",
    "print('Train loss:', train_score)\n",
    "print('Train R2:', r2(Y_train, model.predict(X_train)))\n",
    "\n",
    "test_score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', test_score)\n",
    "print('Test R2:', r2(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 4</b> </div>\n",
    "\n",
    "Let's add more layers. Fix the width $H$ and fit a MLP network with <b>multiple</b> hidden layers, each with the same width. Start with logistic or hyperbolic-tan activation functions for the hidden nodes and linear activation for the output. Experiment with the number of layers and observe the effect of this on the quality of the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/NN_10_layers_100_nodes.py\n",
    "\n",
    "# number of hidden nodes\n",
    "H =  100\n",
    "# input dimension\n",
    "input_dim = 1\n",
    "\n",
    "# create sequential multi-layer perceptron\n",
    "model3 = models.Sequential()\n",
    "\n",
    "# Use a looping statement to write the code below\n",
    "# layer 0\n",
    "model3.add(layers.Dense(H, input_dim=input_dim,  \n",
    "                activation='tanh')) \n",
    "# layer 1\n",
    "model3.add(layers.Dense(H,\n",
    "                activation='tanh')) \n",
    "# layer 2\n",
    "model3.add(layers.Dense(H,\n",
    "                activation='tanh')) \n",
    "# layer 3\n",
    "model3.add(layers.Dense(H,  \n",
    "                activation='tanh')) \n",
    "# layer 4\n",
    "model3.add(layers.Dense(H,  \n",
    "                activation='tanh')) \n",
    "# layer 5\n",
    "model3.add(layers.Dense(H,  \n",
    "                activation='tanh')) \n",
    "# layer 6\n",
    "model3.add(layers.Dense(H,  \n",
    "                activation='tanh'))\n",
    "# layer 7\n",
    "model3.add(layers.Dense(H,  \n",
    "                activation='tanh'))\n",
    "# layer 8\n",
    "model3.add(layers.Dense(H,  \n",
    "                activation='tanh'))\n",
    "# layer 9\n",
    "model3.add(layers.Dense(H,  \n",
    "                activation='tanh'))\n",
    "# layer 10 - output\n",
    "model3.add(layers.Dense(1, \n",
    "                activation='linear')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the model\n",
    "model3.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 221 samples\n",
      "Epoch 1/1500\n",
      "514/514 [==============================] - 1s 2ms/step - loss: 0.3535 - val_loss: 0.0689\n",
      "Epoch 2/1500\n",
      "514/514 [==============================] - 0s 29us/step - loss: 0.1081 - val_loss: 0.0747\n",
      "Epoch 3/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0765 - val_loss: 0.0731\n",
      "Epoch 4/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0667 - val_loss: 0.0919\n",
      "Epoch 5/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0731 - val_loss: 0.0640\n",
      "Epoch 6/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0535 - val_loss: 0.0615\n",
      "Epoch 7/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0545 - val_loss: 0.0621\n",
      "Epoch 8/1500\n",
      "514/514 [==============================] - 0s 23us/step - loss: 0.0599 - val_loss: 0.0754\n",
      "Epoch 9/1500\n",
      "514/514 [==============================] - 0s 23us/step - loss: 0.0564 - val_loss: 0.0588\n",
      "Epoch 10/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0539 - val_loss: 0.0549\n",
      "Epoch 11/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0472 - val_loss: 0.0674\n",
      "Epoch 12/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0543 - val_loss: 0.0479\n",
      "Epoch 13/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0407 - val_loss: 0.0520\n",
      "Epoch 14/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0488 - val_loss: 0.0467\n",
      "Epoch 15/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0507 - val_loss: 0.0364\n",
      "Epoch 16/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0365 - val_loss: 0.0672\n",
      "Epoch 17/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0522 - val_loss: 0.0437\n",
      "Epoch 18/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0421 - val_loss: 0.0279\n",
      "Epoch 19/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0239 - val_loss: 0.0336\n",
      "Epoch 20/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0316 - val_loss: 0.0277\n",
      "Epoch 21/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0322 - val_loss: 0.0238\n",
      "Epoch 22/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0200 - val_loss: 0.0448\n",
      "Epoch 23/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0431 - val_loss: 0.0164\n",
      "Epoch 24/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0208 - val_loss: 0.0212\n",
      "Epoch 25/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0169 - val_loss: 0.0181\n",
      "Epoch 26/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0198 - val_loss: 0.0109\n",
      "Epoch 27/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0146 - val_loss: 0.0106\n",
      "Epoch 28/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0119 - val_loss: 0.0139\n",
      "Epoch 29/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0146 - val_loss: 0.0199\n",
      "Epoch 30/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0232 - val_loss: 0.0135\n",
      "Epoch 31/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0265 - val_loss: 0.0289\n",
      "Epoch 32/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0224 - val_loss: 0.0258\n",
      "Epoch 33/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0211 - val_loss: 0.0122\n",
      "Epoch 34/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0133 - val_loss: 0.0156\n",
      "Epoch 35/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0150 - val_loss: 0.0130\n",
      "Epoch 36/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0119 - val_loss: 0.0105\n",
      "Epoch 37/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 38/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 39/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0104 - val_loss: 0.0117\n",
      "Epoch 40/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0130 - val_loss: 0.0097\n",
      "Epoch 41/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0112 - val_loss: 0.0178\n",
      "Epoch 42/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0155 - val_loss: 0.0105\n",
      "Epoch 43/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0136 - val_loss: 0.0100\n",
      "Epoch 44/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0100 - val_loss: 0.0122\n",
      "Epoch 45/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0114 - val_loss: 0.0178\n",
      "Epoch 46/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0190 - val_loss: 0.0149\n",
      "Epoch 47/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0186 - val_loss: 0.0193\n",
      "Epoch 48/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0140 - val_loss: 0.0153\n",
      "Epoch 49/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0137 - val_loss: 0.0171\n",
      "Epoch 50/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0178 - val_loss: 0.0167\n",
      "Epoch 51/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0131 - val_loss: 0.0134\n",
      "Epoch 52/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0158 - val_loss: 0.0128\n",
      "Epoch 53/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0182 - val_loss: 0.0196\n",
      "Epoch 54/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0137 - val_loss: 0.0155\n",
      "Epoch 55/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0163 - val_loss: 0.0131\n",
      "Epoch 56/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0156 - val_loss: 0.0167\n",
      "Epoch 57/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0155 - val_loss: 0.0152\n",
      "Epoch 58/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0154 - val_loss: 0.0128\n",
      "Epoch 59/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0128 - val_loss: 0.0135\n",
      "Epoch 60/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0120 - val_loss: 0.0137\n",
      "Epoch 61/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0145 - val_loss: 0.0096\n",
      "Epoch 62/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0105 - val_loss: 0.0155\n",
      "Epoch 63/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0136 - val_loss: 0.0101\n",
      "Epoch 64/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 65/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 66/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0097 - val_loss: 0.0171\n",
      "Epoch 67/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0200 - val_loss: 0.0116\n",
      "Epoch 68/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0153 - val_loss: 0.0171\n",
      "Epoch 69/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0147 - val_loss: 0.0206\n",
      "Epoch 70/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0193 - val_loss: 0.0127\n",
      "Epoch 71/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 72/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 73/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0119 - val_loss: 0.0130\n",
      "Epoch 74/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0098\n",
      "Epoch 75/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0098 - val_loss: 0.0138\n",
      "Epoch 76/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0152 - val_loss: 0.0106\n",
      "Epoch 77/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 78/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 79/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 27us/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 80/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 81/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0136 - val_loss: 0.0145\n",
      "Epoch 82/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0144 - val_loss: 0.0120\n",
      "Epoch 83/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 84/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0106 - val_loss: 0.0154\n",
      "Epoch 85/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0155 - val_loss: 0.0125\n",
      "Epoch 86/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 87/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 88/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 89/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0117 - val_loss: 0.0144\n",
      "Epoch 90/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0133 - val_loss: 0.0209\n",
      "Epoch 91/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0236 - val_loss: 0.0187\n",
      "Epoch 92/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0233 - val_loss: 0.0243\n",
      "Epoch 93/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0159 - val_loss: 0.0221\n",
      "Epoch 94/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0192 - val_loss: 0.0166\n",
      "Epoch 95/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 96/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0115 - val_loss: 0.0120\n",
      "Epoch 97/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0138 - val_loss: 0.0127\n",
      "Epoch 98/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0157 - val_loss: 0.0142\n",
      "Epoch 99/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 100/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0117 - val_loss: 0.0163\n",
      "Epoch 101/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0149 - val_loss: 0.0123\n",
      "Epoch 102/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0148 - val_loss: 0.0134\n",
      "Epoch 103/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0226 - val_loss: 0.0129\n",
      "Epoch 104/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0134 - val_loss: 0.0144\n",
      "Epoch 105/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0122 - val_loss: 0.0161\n",
      "Epoch 106/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0133 - val_loss: 0.0157\n",
      "Epoch 107/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0133 - val_loss: 0.0147\n",
      "Epoch 108/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0173 - val_loss: 0.0111\n",
      "Epoch 109/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0134 - val_loss: 0.0294\n",
      "Epoch 110/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0226 - val_loss: 0.0120\n",
      "Epoch 111/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0155 - val_loss: 0.0108\n",
      "Epoch 112/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0113 - val_loss: 0.0127\n",
      "Epoch 113/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0111 - val_loss: 0.0152\n",
      "Epoch 114/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0174 - val_loss: 0.0119\n",
      "Epoch 115/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0118 - val_loss: 0.0123\n",
      "Epoch 116/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 117/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 118/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 119/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 120/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 121/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0101 - val_loss: 0.0158\n",
      "Epoch 122/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0170 - val_loss: 0.0094\n",
      "Epoch 123/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0114 - val_loss: 0.0246\n",
      "Epoch 124/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0225 - val_loss: 0.0138\n",
      "Epoch 125/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0155 - val_loss: 0.0168\n",
      "Epoch 126/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0177 - val_loss: 0.0107\n",
      "Epoch 127/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 128/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0141\n",
      "Epoch 129/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0137 - val_loss: 0.0214\n",
      "Epoch 130/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0189 - val_loss: 0.0193\n",
      "Epoch 131/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0213 - val_loss: 0.0307\n",
      "Epoch 132/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0374 - val_loss: 0.0335\n",
      "Epoch 133/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0519 - val_loss: 0.0421\n",
      "Epoch 134/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0749 - val_loss: 0.0453\n",
      "Epoch 135/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0487 - val_loss: 0.0376\n",
      "Epoch 136/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0393 - val_loss: 0.0324\n",
      "Epoch 137/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0396 - val_loss: 0.0406\n",
      "Epoch 138/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0399 - val_loss: 0.0458\n",
      "Epoch 139/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0461 - val_loss: 0.0304\n",
      "Epoch 140/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0309 - val_loss: 0.0221\n",
      "Epoch 141/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0267 - val_loss: 0.0188\n",
      "Epoch 142/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0178 - val_loss: 0.0368\n",
      "Epoch 143/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0313 - val_loss: 0.0160\n",
      "Epoch 144/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0159 - val_loss: 0.0183\n",
      "Epoch 145/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0174 - val_loss: 0.0193\n",
      "Epoch 146/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0175 - val_loss: 0.0147\n",
      "Epoch 147/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0135 - val_loss: 0.0168\n",
      "Epoch 148/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 149/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0140 - val_loss: 0.0162\n",
      "Epoch 150/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0155 - val_loss: 0.0180\n",
      "Epoch 151/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0153 - val_loss: 0.0133\n",
      "Epoch 152/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0112 - val_loss: 0.0162\n",
      "Epoch 153/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0198 - val_loss: 0.0118\n",
      "Epoch 154/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0146 - val_loss: 0.0169\n",
      "Epoch 155/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0164 - val_loss: 0.0102\n",
      "Epoch 156/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 157/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 47us/step - loss: 0.0108 - val_loss: 0.0155\n",
      "Epoch 158/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0126 - val_loss: 0.0138\n",
      "Epoch 159/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 160/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0108 - val_loss: 0.0149\n",
      "Epoch 161/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0134 - val_loss: 0.0106\n",
      "Epoch 162/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 163/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 164/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 165/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0120 - val_loss: 0.0108\n",
      "Epoch 166/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 167/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 168/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 169/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0155\n",
      "Epoch 170/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0173 - val_loss: 0.0196\n",
      "Epoch 171/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0144 - val_loss: 0.0154\n",
      "Epoch 172/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0166 - val_loss: 0.0119\n",
      "Epoch 173/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0115 - val_loss: 0.0147\n",
      "Epoch 174/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 175/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0110\n",
      "Epoch 176/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0134 - val_loss: 0.0163\n",
      "Epoch 177/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0169 - val_loss: 0.0119\n",
      "Epoch 178/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0148 - val_loss: 0.0121\n",
      "Epoch 179/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 180/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 181/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 182/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0110 - val_loss: 0.0141\n",
      "Epoch 183/1500\n",
      "514/514 [==============================] - 0s 70us/step - loss: 0.0165 - val_loss: 0.0102\n",
      "Epoch 184/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0105 - val_loss: 0.0301\n",
      "Epoch 185/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0293 - val_loss: 0.0192\n",
      "Epoch 186/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0145 - val_loss: 0.0197\n",
      "Epoch 187/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0173 - val_loss: 0.0196\n",
      "Epoch 188/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0196 - val_loss: 0.0140\n",
      "Epoch 189/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0116 - val_loss: 0.0155\n",
      "Epoch 190/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0143 - val_loss: 0.0340\n",
      "Epoch 191/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0648 - val_loss: 0.0153\n",
      "Epoch 192/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0217 - val_loss: 0.0508\n",
      "Epoch 193/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0464 - val_loss: 0.0701\n",
      "Epoch 194/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0562 - val_loss: 0.0510\n",
      "Epoch 195/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0488 - val_loss: 0.0523\n",
      "Epoch 196/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0467 - val_loss: 0.0384\n",
      "Epoch 197/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0415 - val_loss: 0.0294\n",
      "Epoch 198/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0241 - val_loss: 0.0290\n",
      "Epoch 199/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0231 - val_loss: 0.0321\n",
      "Epoch 200/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0263 - val_loss: 0.0404\n",
      "Epoch 201/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0370 - val_loss: 0.0262\n",
      "Epoch 202/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0323 - val_loss: 0.0206\n",
      "Epoch 203/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0186 - val_loss: 0.0247\n",
      "Epoch 204/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0188 - val_loss: 0.0197\n",
      "Epoch 205/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0244 - val_loss: 0.0313\n",
      "Epoch 206/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0322 - val_loss: 0.0369\n",
      "Epoch 207/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0410 - val_loss: 0.0261\n",
      "Epoch 208/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0342 - val_loss: 0.0292\n",
      "Epoch 209/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0234 - val_loss: 0.0244\n",
      "Epoch 210/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0255 - val_loss: 0.0137\n",
      "Epoch 211/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0137 - val_loss: 0.0224\n",
      "Epoch 212/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0167 - val_loss: 0.0137\n",
      "Epoch 213/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0162 - val_loss: 0.0111\n",
      "Epoch 214/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0113 - val_loss: 0.0281\n",
      "Epoch 215/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0288 - val_loss: 0.0155\n",
      "Epoch 216/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0207 - val_loss: 0.0282\n",
      "Epoch 217/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0277 - val_loss: 0.0189\n",
      "Epoch 218/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0227 - val_loss: 0.0308\n",
      "Epoch 219/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0441 - val_loss: 0.0514\n",
      "Epoch 220/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0585 - val_loss: 0.0832\n",
      "Epoch 221/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0768 - val_loss: 0.0458\n",
      "Epoch 222/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0435 - val_loss: 0.0408\n",
      "Epoch 223/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0493 - val_loss: 0.0385\n",
      "Epoch 224/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0439 - val_loss: 0.0792\n",
      "Epoch 225/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.1242 - val_loss: 0.0182\n",
      "Epoch 226/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0378 - val_loss: 0.0195\n",
      "Epoch 227/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0513 - val_loss: 0.0226\n",
      "Epoch 228/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0245 - val_loss: 0.0597\n",
      "Epoch 229/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0426 - val_loss: 0.0283\n",
      "Epoch 230/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0263 - val_loss: 0.0213\n",
      "Epoch 231/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0195 - val_loss: 0.0291\n",
      "Epoch 232/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0373 - val_loss: 0.0132\n",
      "Epoch 233/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0138 - val_loss: 0.0326\n",
      "Epoch 234/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0240 - val_loss: 0.0117\n",
      "Epoch 235/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0116\n",
      "Epoch 236/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 237/1500\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.011 - 0s 39us/step - loss: 0.0156 - val_loss: 0.0251\n",
      "Epoch 238/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0209 - val_loss: 0.0286\n",
      "Epoch 239/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0224 - val_loss: 0.0192\n",
      "Epoch 240/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0195 - val_loss: 0.0226\n",
      "Epoch 241/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0224 - val_loss: 0.0105\n",
      "Epoch 242/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0109 - val_loss: 0.0140\n",
      "Epoch 243/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0161 - val_loss: 0.0211\n",
      "Epoch 244/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0235 - val_loss: 0.0204\n",
      "Epoch 245/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0171 - val_loss: 0.0114\n",
      "Epoch 246/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 247/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0127 - val_loss: 0.0166\n",
      "Epoch 248/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0140 - val_loss: 0.0118\n",
      "Epoch 249/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 250/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 251/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0131 - val_loss: 0.0101\n",
      "Epoch 252/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 253/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 254/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0134 - val_loss: 0.0100\n",
      "Epoch 255/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0102 - val_loss: 0.0136\n",
      "Epoch 256/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 257/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 258/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0101 - val_loss: 0.0142\n",
      "Epoch 259/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0129 - val_loss: 0.0108\n",
      "Epoch 260/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0110 - val_loss: 0.0138\n",
      "Epoch 261/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0127 - val_loss: 0.0133\n",
      "Epoch 262/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0113 - val_loss: 0.0130\n",
      "Epoch 263/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0121 - val_loss: 0.0106\n",
      "Epoch 264/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 265/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 266/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0099\n",
      "Epoch 267/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 268/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0143\n",
      "Epoch 269/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0135 - val_loss: 0.0223\n",
      "Epoch 270/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0161 - val_loss: 0.0148\n",
      "Epoch 271/1500\n",
      "514/514 [==============================] - 0s 23us/step - loss: 0.0157 - val_loss: 0.0164\n",
      "Epoch 272/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0163 - val_loss: 0.0122\n",
      "Epoch 273/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0145 - val_loss: 0.0187\n",
      "Epoch 274/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0155 - val_loss: 0.0116\n",
      "Epoch 275/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0143 - val_loss: 0.0122\n",
      "Epoch 276/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0121 - val_loss: 0.0123\n",
      "Epoch 277/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 278/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 279/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0112 - val_loss: 0.0154\n",
      "Epoch 280/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0156 - val_loss: 0.0121\n",
      "Epoch 281/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0121 - val_loss: 0.0218\n",
      "Epoch 282/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0215 - val_loss: 0.0151\n",
      "Epoch 283/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0134 - val_loss: 0.0169\n",
      "Epoch 284/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0140 - val_loss: 0.0121\n",
      "Epoch 285/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 286/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0130 - val_loss: 0.0109\n",
      "Epoch 287/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 288/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0124 - val_loss: 0.0126\n",
      "Epoch 289/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 290/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 291/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0237\n",
      "Epoch 292/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0174 - val_loss: 0.0131\n",
      "Epoch 293/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0152 - val_loss: 0.0167\n",
      "Epoch 294/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0146 - val_loss: 0.0120\n",
      "Epoch 295/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0123 - val_loss: 0.0152\n",
      "Epoch 296/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0140 - val_loss: 0.0105\n",
      "Epoch 297/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0147 - val_loss: 0.0204\n",
      "Epoch 298/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0185 - val_loss: 0.0213\n",
      "Epoch 299/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0178 - val_loss: 0.0174\n",
      "Epoch 300/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0145 - val_loss: 0.0142\n",
      "Epoch 301/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 302/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 303/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0169 - val_loss: 0.0208\n",
      "Epoch 304/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0216 - val_loss: 0.0293\n",
      "Epoch 305/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0238 - val_loss: 0.0412\n",
      "Epoch 306/1500\n",
      "514/514 [==============================] - 0s 35us/step - loss: 0.0302 - val_loss: 0.0489\n",
      "Epoch 307/1500\n",
      "514/514 [==============================] - 0s 40us/step - loss: 0.0339 - val_loss: 0.0454\n",
      "Epoch 308/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0297 - val_loss: 0.0477\n",
      "Epoch 309/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0347 - val_loss: 0.0403\n",
      "Epoch 310/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0328 - val_loss: 0.0476\n",
      "Epoch 311/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0324 - val_loss: 0.0896\n",
      "Epoch 312/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.1045 - val_loss: 0.0373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0312 - val_loss: 0.0751\n",
      "Epoch 314/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0556 - val_loss: 0.0784\n",
      "Epoch 315/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0625 - val_loss: 0.0544\n",
      "Epoch 316/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0532 - val_loss: 0.0225\n",
      "Epoch 317/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0183 - val_loss: 0.0274\n",
      "Epoch 318/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0263 - val_loss: 0.0254\n",
      "Epoch 319/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0257 - val_loss: 0.0221\n",
      "Epoch 320/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0237 - val_loss: 0.0242\n",
      "Epoch 321/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0243 - val_loss: 0.0187\n",
      "Epoch 322/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0218 - val_loss: 0.0194\n",
      "Epoch 323/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0188 - val_loss: 0.0144\n",
      "Epoch 324/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0138 - val_loss: 0.0127\n",
      "Epoch 325/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0179 - val_loss: 0.0140\n",
      "Epoch 326/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0130 - val_loss: 0.0341\n",
      "Epoch 327/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0329 - val_loss: 0.0114\n",
      "Epoch 328/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0152 - val_loss: 0.0296\n",
      "Epoch 329/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0254 - val_loss: 0.0205\n",
      "Epoch 330/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0234 - val_loss: 0.0235\n",
      "Epoch 331/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0163 - val_loss: 0.0118\n",
      "Epoch 332/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0119 - val_loss: 0.0129\n",
      "Epoch 333/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0120 - val_loss: 0.0231\n",
      "Epoch 334/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0186 - val_loss: 0.0116\n",
      "Epoch 335/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0151 - val_loss: 0.0262\n",
      "Epoch 336/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0248 - val_loss: 0.0107\n",
      "Epoch 337/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0136 - val_loss: 0.0191\n",
      "Epoch 338/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0143 - val_loss: 0.0115\n",
      "Epoch 339/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0124 - val_loss: 0.0116\n",
      "Epoch 340/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0119 - val_loss: 0.0179\n",
      "Epoch 341/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0169 - val_loss: 0.0121\n",
      "Epoch 342/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0101 - val_loss: 0.0210\n",
      "Epoch 343/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0230 - val_loss: 0.0179\n",
      "Epoch 344/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0173 - val_loss: 0.0307\n",
      "Epoch 345/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0265 - val_loss: 0.0112\n",
      "Epoch 346/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0139 - val_loss: 0.0146\n",
      "Epoch 347/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0135 - val_loss: 0.0186\n",
      "Epoch 348/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0179 - val_loss: 0.0139\n",
      "Epoch 349/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0112 - val_loss: 0.0136\n",
      "Epoch 350/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0151 - val_loss: 0.0103\n",
      "Epoch 351/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0099 - val_loss: 0.0115\n",
      "Epoch 352/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 353/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 354/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 355/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 356/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0099 - val_loss: 0.0090\n",
      "Epoch 357/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0096 - val_loss: 0.0092\n",
      "Epoch 358/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0096 - val_loss: 0.0114\n",
      "Epoch 359/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0093\n",
      "Epoch 360/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0095 - val_loss: 0.0124\n",
      "Epoch 361/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 362/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 363/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 364/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0113 - val_loss: 0.0090\n",
      "Epoch 365/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 366/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0099 - val_loss: 0.0093\n",
      "Epoch 367/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0095\n",
      "Epoch 368/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0158 - val_loss: 0.0290\n",
      "Epoch 369/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0331 - val_loss: 0.0121\n",
      "Epoch 370/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0121 - val_loss: 0.0125\n",
      "Epoch 371/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0118 - val_loss: 0.0181\n",
      "Epoch 372/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0154 - val_loss: 0.0242\n",
      "Epoch 373/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0239 - val_loss: 0.0185\n",
      "Epoch 374/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0154 - val_loss: 0.0141\n",
      "Epoch 375/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0124 - val_loss: 0.0108\n",
      "Epoch 376/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 377/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 378/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0134 - val_loss: 0.0104\n",
      "Epoch 379/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 380/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 381/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0137 - val_loss: 0.0184\n",
      "Epoch 382/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0157 - val_loss: 0.0149\n",
      "Epoch 383/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0160 - val_loss: 0.0151\n",
      "Epoch 384/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0153 - val_loss: 0.0101\n",
      "Epoch 385/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 386/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 387/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 388/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 389/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0104 - val_loss: 0.0136\n",
      "Epoch 390/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0127 - val_loss: 0.0111\n",
      "Epoch 391/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 392/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0111 - val_loss: 0.0095\n",
      "Epoch 393/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0104 - val_loss: 0.0120\n",
      "Epoch 394/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 395/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 396/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0095 - val_loss: 0.0124\n",
      "Epoch 397/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0130 - val_loss: 0.0139\n",
      "Epoch 398/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0127 - val_loss: 0.0104\n",
      "Epoch 399/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 400/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 401/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0098 - val_loss: 0.0150\n",
      "Epoch 402/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0149 - val_loss: 0.0172\n",
      "Epoch 403/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0142 - val_loss: 0.0096\n",
      "Epoch 404/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0116 - val_loss: 0.0138\n",
      "Epoch 405/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0133 - val_loss: 0.0105\n",
      "Epoch 406/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 407/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0100 - val_loss: 0.0207\n",
      "Epoch 408/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0237 - val_loss: 0.0222\n",
      "Epoch 409/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0202 - val_loss: 0.0121\n",
      "Epoch 410/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 411/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0110 - val_loss: 0.0167\n",
      "Epoch 412/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0193 - val_loss: 0.0098\n",
      "Epoch 413/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0121 - val_loss: 0.0190\n",
      "Epoch 414/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0186 - val_loss: 0.0099\n",
      "Epoch 415/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 416/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0157 - val_loss: 0.0134\n",
      "Epoch 417/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0145 - val_loss: 0.0111\n",
      "Epoch 418/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0108 - val_loss: 0.0205\n",
      "Epoch 419/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0239 - val_loss: 0.0245\n",
      "Epoch 420/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0225 - val_loss: 0.0228\n",
      "Epoch 421/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0194 - val_loss: 0.0160\n",
      "Epoch 422/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0125 - val_loss: 0.0214\n",
      "Epoch 423/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0225 - val_loss: 0.0161\n",
      "Epoch 424/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0149 - val_loss: 0.0115\n",
      "Epoch 425/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0092\n",
      "Epoch 426/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0181\n",
      "Epoch 427/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0208 - val_loss: 0.0141\n",
      "Epoch 428/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0164 - val_loss: 0.0201\n",
      "Epoch 429/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0184 - val_loss: 0.0240\n",
      "Epoch 430/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0191 - val_loss: 0.0169\n",
      "Epoch 431/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0224 - val_loss: 0.0300\n",
      "Epoch 432/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0340 - val_loss: 0.0150\n",
      "Epoch 433/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0155 - val_loss: 0.0212\n",
      "Epoch 434/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0189 - val_loss: 0.0498\n",
      "Epoch 435/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0555 - val_loss: 0.0251\n",
      "Epoch 436/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0326 - val_loss: 0.0383\n",
      "Epoch 437/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0228 - val_loss: 0.0426\n",
      "Epoch 438/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0394 - val_loss: 0.0119\n",
      "Epoch 439/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0109 - val_loss: 0.0167\n",
      "Epoch 440/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0170 - val_loss: 0.0165\n",
      "Epoch 441/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0208 - val_loss: 0.0170\n",
      "Epoch 442/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0196 - val_loss: 0.0190\n",
      "Epoch 443/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0211 - val_loss: 0.0145\n",
      "Epoch 444/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0168 - val_loss: 0.0131\n",
      "Epoch 445/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0141 - val_loss: 0.0108\n",
      "Epoch 446/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0137\n",
      "Epoch 447/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0119 - val_loss: 0.0140\n",
      "Epoch 448/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0142\n",
      "Epoch 449/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0125 - val_loss: 0.0124\n",
      "Epoch 450/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0111 - val_loss: 0.0126\n",
      "Epoch 451/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0122\n",
      "Epoch 452/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 453/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0138 - val_loss: 0.0128\n",
      "Epoch 454/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 455/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0126 - val_loss: 0.0095\n",
      "Epoch 456/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0113 - val_loss: 0.0089\n",
      "Epoch 457/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 458/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 459/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 460/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 461/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0112 - val_loss: 0.0145\n",
      "Epoch 462/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0134 - val_loss: 0.0151\n",
      "Epoch 463/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0138 - val_loss: 0.0120\n",
      "Epoch 464/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 465/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 466/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0155\n",
      "Epoch 467/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0141 - val_loss: 0.0130\n",
      "Epoch 468/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 469/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 47us/step - loss: 0.0162 - val_loss: 0.0140\n",
      "Epoch 470/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0148 - val_loss: 0.0127\n",
      "Epoch 471/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0139 - val_loss: 0.0157\n",
      "Epoch 472/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0183 - val_loss: 0.0263\n",
      "Epoch 473/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0293 - val_loss: 0.0229\n",
      "Epoch 474/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0191 - val_loss: 0.0222\n",
      "Epoch 475/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0194 - val_loss: 0.0275\n",
      "Epoch 476/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0235 - val_loss: 0.0217\n",
      "Epoch 477/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0230 - val_loss: 0.0233\n",
      "Epoch 478/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0213 - val_loss: 0.0480\n",
      "Epoch 479/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0365 - val_loss: 0.0319\n",
      "Epoch 480/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0338 - val_loss: 0.0241\n",
      "Epoch 481/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0219 - val_loss: 0.0497\n",
      "Epoch 482/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0406 - val_loss: 0.0172\n",
      "Epoch 483/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0211 - val_loss: 0.0262\n",
      "Epoch 484/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0252 - val_loss: 0.0123\n",
      "Epoch 485/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0129 - val_loss: 0.0138\n",
      "Epoch 486/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0125 - val_loss: 0.0178\n",
      "Epoch 487/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0165 - val_loss: 0.0140\n",
      "Epoch 488/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0130 - val_loss: 0.0126\n",
      "Epoch 489/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0112 - val_loss: 0.0165\n",
      "Epoch 490/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0145 - val_loss: 0.0097\n",
      "Epoch 491/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 492/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0127 - val_loss: 0.0129\n",
      "Epoch 493/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 494/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0123 - val_loss: 0.0173\n",
      "Epoch 495/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0156 - val_loss: 0.0180\n",
      "Epoch 496/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0168 - val_loss: 0.0179\n",
      "Epoch 497/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0134 - val_loss: 0.0133\n",
      "Epoch 498/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0170 - val_loss: 0.0136\n",
      "Epoch 499/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0133\n",
      "Epoch 500/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 501/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 502/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 503/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 504/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 505/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0111 - val_loss: 0.0126\n",
      "Epoch 506/1500\n",
      "514/514 [==============================] - 0s 23us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 507/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0118 - val_loss: 0.0144\n",
      "Epoch 508/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 509/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 510/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 511/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 512/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 513/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 514/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0123 - val_loss: 0.0100\n",
      "Epoch 515/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 516/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 517/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 518/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0097\n",
      "Epoch 519/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 520/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0127 - val_loss: 0.0101\n",
      "Epoch 521/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0118 - val_loss: 0.0146\n",
      "Epoch 522/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0150 - val_loss: 0.0177\n",
      "Epoch 523/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0246 - val_loss: 0.0177\n",
      "Epoch 524/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0179 - val_loss: 0.0112\n",
      "Epoch 525/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0138 - val_loss: 0.0110\n",
      "Epoch 526/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0130 - val_loss: 0.0155\n",
      "Epoch 527/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0148 - val_loss: 0.0134\n",
      "Epoch 528/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0137 - val_loss: 0.0159\n",
      "Epoch 529/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0118 - val_loss: 0.0127\n",
      "Epoch 530/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 531/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 532/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 533/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 534/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 535/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0111 - val_loss: 0.0091\n",
      "Epoch 536/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0097 - val_loss: 0.0137\n",
      "Epoch 537/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0131 - val_loss: 0.0098\n",
      "Epoch 538/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0110 - val_loss: 0.0171\n",
      "Epoch 539/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0163 - val_loss: 0.0144\n",
      "Epoch 540/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0132 - val_loss: 0.0144\n",
      "Epoch 541/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 542/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0121 - val_loss: 0.0119\n",
      "Epoch 543/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0143 - val_loss: 0.0146\n",
      "Epoch 544/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0181 - val_loss: 0.0198\n",
      "Epoch 545/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0207 - val_loss: 0.0122\n",
      "Epoch 546/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0109 - val_loss: 0.0166\n",
      "Epoch 547/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 31us/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 548/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 549/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0122 - val_loss: 0.0126\n",
      "Epoch 550/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 551/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 552/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0136 - val_loss: 0.0160\n",
      "Epoch 553/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0156 - val_loss: 0.0112\n",
      "Epoch 554/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0106 - val_loss: 0.0154\n",
      "Epoch 555/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0133 - val_loss: 0.0128\n",
      "Epoch 556/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0129\n",
      "Epoch 557/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0131\n",
      "Epoch 558/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0139 - val_loss: 0.0184\n",
      "Epoch 559/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0178 - val_loss: 0.0125\n",
      "Epoch 560/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0148 - val_loss: 0.0107\n",
      "Epoch 561/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 562/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0125 - val_loss: 0.0130\n",
      "Epoch 563/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 564/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0127 - val_loss: 0.0099\n",
      "Epoch 565/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 566/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0095 - val_loss: 0.0112\n",
      "Epoch 567/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 568/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 569/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0096 - val_loss: 0.0108\n",
      "Epoch 570/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0104 - val_loss: 0.0125\n",
      "Epoch 571/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0097\n",
      "Epoch 572/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0109 - val_loss: 0.0137\n",
      "Epoch 573/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0156 - val_loss: 0.0105\n",
      "Epoch 574/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0117 - val_loss: 0.0173\n",
      "Epoch 575/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0183 - val_loss: 0.0170\n",
      "Epoch 576/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0137 - val_loss: 0.0126\n",
      "Epoch 577/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0125 - val_loss: 0.0129\n",
      "Epoch 578/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0134\n",
      "Epoch 579/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0125 - val_loss: 0.0116\n",
      "Epoch 580/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 581/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 582/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0098 - val_loss: 0.0138\n",
      "Epoch 583/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0148 - val_loss: 0.0117\n",
      "Epoch 584/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0098 - val_loss: 0.0157\n",
      "Epoch 585/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0169 - val_loss: 0.0160\n",
      "Epoch 586/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0152 - val_loss: 0.0146\n",
      "Epoch 587/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0133 - val_loss: 0.0139\n",
      "Epoch 588/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 589/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0157 - val_loss: 0.0245\n",
      "Epoch 590/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0276 - val_loss: 0.0157\n",
      "Epoch 591/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0183 - val_loss: 0.0167\n",
      "Epoch 592/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0208 - val_loss: 0.0147\n",
      "Epoch 593/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0133 - val_loss: 0.0254\n",
      "Epoch 594/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0198 - val_loss: 0.0194\n",
      "Epoch 595/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0150 - val_loss: 0.0166\n",
      "Epoch 596/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0143 - val_loss: 0.0161\n",
      "Epoch 597/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 598/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0129 - val_loss: 0.0138\n",
      "Epoch 599/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 600/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0137 - val_loss: 0.0105\n",
      "Epoch 601/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0111 - val_loss: 0.0129\n",
      "Epoch 602/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0137 - val_loss: 0.0145\n",
      "Epoch 603/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0132 - val_loss: 0.0096\n",
      "Epoch 604/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 605/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 606/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 607/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 608/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0112 - val_loss: 0.0099\n",
      "Epoch 609/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 610/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 611/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 612/1500\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.011 - 0s 39us/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 613/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0102 - val_loss: 0.0138\n",
      "Epoch 614/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0120 - val_loss: 0.0098\n",
      "Epoch 615/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 616/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 617/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 618/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 619/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 620/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 621/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0107 - val_loss: 0.0127\n",
      "Epoch 622/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0102\n",
      "Epoch 623/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 624/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0102 - val_loss: 0.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 626/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 627/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 628/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 629/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0102 - val_loss: 0.0122\n",
      "Epoch 630/1500\n",
      "514/514 [==============================] - 0s 62us/step - loss: 0.0144 - val_loss: 0.0159\n",
      "Epoch 631/1500\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.015 - 0s 47us/step - loss: 0.0150 - val_loss: 0.0125\n",
      "Epoch 632/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0114 - val_loss: 0.0137\n",
      "Epoch 633/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0129 - val_loss: 0.0129\n",
      "Epoch 634/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 635/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 636/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 637/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0127 - val_loss: 0.0115\n",
      "Epoch 638/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0122 - val_loss: 0.0093\n",
      "Epoch 639/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0102 - val_loss: 0.0124\n",
      "Epoch 640/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0111 - val_loss: 0.0094\n",
      "Epoch 641/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 642/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 643/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 644/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0100 - val_loss: 0.0122\n",
      "Epoch 645/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0097\n",
      "Epoch 646/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 647/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 648/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0117 - val_loss: 0.0094\n",
      "Epoch 649/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 650/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 651/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 652/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 653/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0094 - val_loss: 0.0142\n",
      "Epoch 654/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0132 - val_loss: 0.0170\n",
      "Epoch 655/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0140 - val_loss: 0.0113\n",
      "Epoch 656/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 657/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 658/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0094 - val_loss: 0.0094\n",
      "Epoch 659/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0094 - val_loss: 0.0093\n",
      "Epoch 660/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 661/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0099 - val_loss: 0.0118\n",
      "Epoch 662/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0117 - val_loss: 0.0143\n",
      "Epoch 663/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0125 - val_loss: 0.0107\n",
      "Epoch 664/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 665/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 666/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 667/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0095 - val_loss: 0.0093\n",
      "Epoch 668/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 669/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0092 - val_loss: 0.0090\n",
      "Epoch 670/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 671/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 672/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 673/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 674/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0097\n",
      "Epoch 675/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0097 - val_loss: 0.0146\n",
      "Epoch 676/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0131 - val_loss: 0.0093\n",
      "Epoch 677/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 678/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0141 - val_loss: 0.0096\n",
      "Epoch 679/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0098 - val_loss: 0.0119\n",
      "Epoch 680/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 681/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0129 - val_loss: 0.0101\n",
      "Epoch 682/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0144\n",
      "Epoch 683/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0143 - val_loss: 0.0107\n",
      "Epoch 684/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0104 - val_loss: 0.0138\n",
      "Epoch 685/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0125 - val_loss: 0.0114\n",
      "Epoch 686/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0102 - val_loss: 0.0118\n",
      "Epoch 687/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0132 - val_loss: 0.0141\n",
      "Epoch 688/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0133 - val_loss: 0.0143\n",
      "Epoch 689/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0120 - val_loss: 0.0137\n",
      "Epoch 690/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0125 - val_loss: 0.0136\n",
      "Epoch 691/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0141 - val_loss: 0.0144\n",
      "Epoch 692/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0209 - val_loss: 0.0223\n",
      "Epoch 693/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0241 - val_loss: 0.0115\n",
      "Epoch 694/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0179 - val_loss: 0.0345\n",
      "Epoch 695/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0319 - val_loss: 0.0371\n",
      "Epoch 696/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0303 - val_loss: 0.0348\n",
      "Epoch 697/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0247 - val_loss: 0.0265\n",
      "Epoch 698/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0230 - val_loss: 0.0181\n",
      "Epoch 699/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0262 - val_loss: 0.0496\n",
      "Epoch 700/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0476 - val_loss: 0.0235\n",
      "Epoch 701/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0306 - val_loss: 0.0206\n",
      "Epoch 702/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0253 - val_loss: 0.0185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 703/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0214 - val_loss: 0.0175\n",
      "Epoch 704/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0175 - val_loss: 0.0280\n",
      "Epoch 705/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0279 - val_loss: 0.0152\n",
      "Epoch 706/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0189 - val_loss: 0.0133\n",
      "Epoch 707/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0148 - val_loss: 0.0117\n",
      "Epoch 708/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0143 - val_loss: 0.0110\n",
      "Epoch 709/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0120 - val_loss: 0.0188\n",
      "Epoch 710/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0171 - val_loss: 0.0120\n",
      "Epoch 711/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 712/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 713/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 714/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 715/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 716/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 717/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 718/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0098 - val_loss: 0.0122\n",
      "Epoch 719/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 720/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0108 - val_loss: 0.0126\n",
      "Epoch 721/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0158 - val_loss: 0.0102\n",
      "Epoch 722/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0115 - val_loss: 0.0152\n",
      "Epoch 723/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0151 - val_loss: 0.0121\n",
      "Epoch 724/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0140 - val_loss: 0.0182\n",
      "Epoch 725/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0195 - val_loss: 0.0244\n",
      "Epoch 726/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0274 - val_loss: 0.0410\n",
      "Epoch 727/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0365 - val_loss: 0.0253\n",
      "Epoch 728/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0194 - val_loss: 0.0943\n",
      "Epoch 729/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0594 - val_loss: 0.0550\n",
      "Epoch 730/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0508 - val_loss: 0.0489\n",
      "Epoch 731/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0631 - val_loss: 0.0563\n",
      "Epoch 732/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0656 - val_loss: 0.0536\n",
      "Epoch 733/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0516 - val_loss: 0.0504\n",
      "Epoch 734/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0639 - val_loss: 0.0454\n",
      "Epoch 735/1500\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.049 - 0s 39us/step - loss: 0.0476 - val_loss: 0.0836\n",
      "Epoch 736/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0734 - val_loss: 0.0484\n",
      "Epoch 737/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0590 - val_loss: 0.0398\n",
      "Epoch 738/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0497 - val_loss: 0.0414\n",
      "Epoch 739/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0298 - val_loss: 0.0294\n",
      "Epoch 740/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0241 - val_loss: 0.0452\n",
      "Epoch 741/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0335 - val_loss: 0.0314\n",
      "Epoch 742/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0303 - val_loss: 0.0306\n",
      "Epoch 743/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0258 - val_loss: 0.0275\n",
      "Epoch 744/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0238 - val_loss: 0.0247\n",
      "Epoch 745/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0208 - val_loss: 0.0370\n",
      "Epoch 746/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0298 - val_loss: 0.0226\n",
      "Epoch 747/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0183 - val_loss: 0.0215\n",
      "Epoch 748/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0180 - val_loss: 0.0284\n",
      "Epoch 749/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0224 - val_loss: 0.0212\n",
      "Epoch 750/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0233 - val_loss: 0.0285\n",
      "Epoch 751/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0242 - val_loss: 0.0230\n",
      "Epoch 752/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0192 - val_loss: 0.0227\n",
      "Epoch 753/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0174 - val_loss: 0.0185\n",
      "Epoch 754/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0152 - val_loss: 0.0173\n",
      "Epoch 755/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0143 - val_loss: 0.0175\n",
      "Epoch 756/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0180 - val_loss: 0.0149\n",
      "Epoch 757/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0133 - val_loss: 0.0170\n",
      "Epoch 758/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0143 - val_loss: 0.0153\n",
      "Epoch 759/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0143 - val_loss: 0.0165\n",
      "Epoch 760/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0128 - val_loss: 0.0151\n",
      "Epoch 761/1500\n",
      "514/514 [==============================] - 0s 23us/step - loss: 0.0152 - val_loss: 0.0189\n",
      "Epoch 762/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0161 - val_loss: 0.0228\n",
      "Epoch 763/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0257 - val_loss: 0.0203\n",
      "Epoch 764/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0142 - val_loss: 0.0260\n",
      "Epoch 765/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0290 - val_loss: 0.0128\n",
      "Epoch 766/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0124 - val_loss: 0.0333\n",
      "Epoch 767/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0284 - val_loss: 0.0197\n",
      "Epoch 768/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0213 - val_loss: 0.0154\n",
      "Epoch 769/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0140 - val_loss: 0.0148\n",
      "Epoch 770/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0140 - val_loss: 0.0131\n",
      "Epoch 771/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0124 - val_loss: 0.0174\n",
      "Epoch 772/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0156 - val_loss: 0.0231\n",
      "Epoch 773/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0188 - val_loss: 0.0215\n",
      "Epoch 774/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0175 - val_loss: 0.0231\n",
      "Epoch 775/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0211 - val_loss: 0.0257\n",
      "Epoch 776/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0199 - val_loss: 0.0177\n",
      "Epoch 777/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0169 - val_loss: 0.0172\n",
      "Epoch 778/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0146 - val_loss: 0.0153\n",
      "Epoch 779/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0123 - val_loss: 0.0165\n",
      "Epoch 780/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0138 - val_loss: 0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0191 - val_loss: 0.0114\n",
      "Epoch 782/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0167 - val_loss: 0.0398\n",
      "Epoch 783/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0555 - val_loss: 0.0493\n",
      "Epoch 784/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0514 - val_loss: 0.0498\n",
      "Epoch 785/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0538 - val_loss: 0.0551\n",
      "Epoch 786/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0502 - val_loss: 0.0553\n",
      "Epoch 787/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0483 - val_loss: 0.0432\n",
      "Epoch 788/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0436 - val_loss: 0.0631\n",
      "Epoch 789/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0795 - val_loss: 0.0362\n",
      "Epoch 790/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0551 - val_loss: 0.0523\n",
      "Epoch 791/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0472 - val_loss: 0.0369\n",
      "Epoch 792/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0441 - val_loss: 0.0376\n",
      "Epoch 793/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0455 - val_loss: 0.0299\n",
      "Epoch 794/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0360 - val_loss: 0.0510\n",
      "Epoch 795/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0524 - val_loss: 0.0221\n",
      "Epoch 796/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0248 - val_loss: 0.0295\n",
      "Epoch 797/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0205 - val_loss: 0.0137\n",
      "Epoch 798/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0139 - val_loss: 0.0226\n",
      "Epoch 799/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0223 - val_loss: 0.0218\n",
      "Epoch 800/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0275 - val_loss: 0.0254\n",
      "Epoch 801/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0287 - val_loss: 0.0194\n",
      "Epoch 802/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0229 - val_loss: 0.0168\n",
      "Epoch 803/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0189 - val_loss: 0.0161\n",
      "Epoch 804/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0177 - val_loss: 0.0156\n",
      "Epoch 805/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0171 - val_loss: 0.0268\n",
      "Epoch 806/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0265 - val_loss: 0.0166\n",
      "Epoch 807/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0175 - val_loss: 0.0240\n",
      "Epoch 808/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0270 - val_loss: 0.0123\n",
      "Epoch 809/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0143 - val_loss: 0.0297\n",
      "Epoch 810/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0249 - val_loss: 0.0128\n",
      "Epoch 811/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0194\n",
      "Epoch 812/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0211 - val_loss: 0.0144\n",
      "Epoch 813/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0130 - val_loss: 0.0218\n",
      "Epoch 814/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0170 - val_loss: 0.0129\n",
      "Epoch 815/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0111 - val_loss: 0.0158\n",
      "Epoch 816/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0150 - val_loss: 0.0137\n",
      "Epoch 817/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0153 - val_loss: 0.0244\n",
      "Epoch 818/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0186 - val_loss: 0.0127\n",
      "Epoch 819/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0129 - val_loss: 0.0190\n",
      "Epoch 820/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0196 - val_loss: 0.0132\n",
      "Epoch 821/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0138\n",
      "Epoch 822/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0175\n",
      "Epoch 823/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0173 - val_loss: 0.0219\n",
      "Epoch 824/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0199 - val_loss: 0.0252\n",
      "Epoch 825/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0195 - val_loss: 0.0216\n",
      "Epoch 826/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0199 - val_loss: 0.0186\n",
      "Epoch 827/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0165 - val_loss: 0.0203\n",
      "Epoch 828/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0180 - val_loss: 0.0181\n",
      "Epoch 829/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0168 - val_loss: 0.0128\n",
      "Epoch 830/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 831/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 832/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 833/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 834/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 835/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 836/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 837/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 838/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0100 - val_loss: 0.0093\n",
      "Epoch 839/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 840/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 841/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0101 - val_loss: 0.0127\n",
      "Epoch 842/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 843/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0100 - val_loss: 0.0141\n",
      "Epoch 844/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0162 - val_loss: 0.0117\n",
      "Epoch 845/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0115 - val_loss: 0.0161\n",
      "Epoch 846/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0141 - val_loss: 0.0108\n",
      "Epoch 847/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0101 - val_loss: 0.0125\n",
      "Epoch 848/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0143 - val_loss: 0.0119\n",
      "Epoch 849/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0125 - val_loss: 0.0094\n",
      "Epoch 850/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 851/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 852/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 853/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 854/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0143 - val_loss: 0.0233\n",
      "Epoch 855/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0221 - val_loss: 0.0153\n",
      "Epoch 856/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0130 - val_loss: 0.0128\n",
      "Epoch 857/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0121 - val_loss: 0.0133\n",
      "Epoch 858/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0135 - val_loss: 0.0115\n",
      "Epoch 859/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 39us/step - loss: 0.0132 - val_loss: 0.0103\n",
      "Epoch 860/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0114 - val_loss: 0.0142\n",
      "Epoch 861/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0162 - val_loss: 0.0185\n",
      "Epoch 862/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0149 - val_loss: 0.0131\n",
      "Epoch 863/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0123 - val_loss: 0.0145\n",
      "Epoch 864/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 865/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 866/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 867/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 868/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0123 - val_loss: 0.0113\n",
      "Epoch 869/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0109 - val_loss: 0.0180\n",
      "Epoch 870/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0163 - val_loss: 0.0207\n",
      "Epoch 871/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0185 - val_loss: 0.0215\n",
      "Epoch 872/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0193 - val_loss: 0.0250\n",
      "Epoch 873/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0235 - val_loss: 0.0213\n",
      "Epoch 874/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0168 - val_loss: 0.0222\n",
      "Epoch 875/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0197 - val_loss: 0.0155\n",
      "Epoch 876/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0128 - val_loss: 0.0162\n",
      "Epoch 877/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0133 - val_loss: 0.0198\n",
      "Epoch 878/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0185 - val_loss: 0.0178\n",
      "Epoch 879/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0158 - val_loss: 0.0154\n",
      "Epoch 880/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0133 - val_loss: 0.0110\n",
      "Epoch 881/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 882/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0134 - val_loss: 0.0121\n",
      "Epoch 883/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0132 - val_loss: 0.0114\n",
      "Epoch 884/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0135 - val_loss: 0.0095\n",
      "Epoch 885/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 886/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0133 - val_loss: 0.0158\n",
      "Epoch 887/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0177 - val_loss: 0.0153\n",
      "Epoch 888/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0147 - val_loss: 0.0125\n",
      "Epoch 889/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0123 - val_loss: 0.0173\n",
      "Epoch 890/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 891/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 892/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 893/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 894/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 895/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 896/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 897/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 898/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 899/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0124\n",
      "Epoch 900/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0132 - val_loss: 0.0180\n",
      "Epoch 901/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0158 - val_loss: 0.0104\n",
      "Epoch 902/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0101 - val_loss: 0.0171\n",
      "Epoch 903/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0185 - val_loss: 0.0119\n",
      "Epoch 904/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0112 - val_loss: 0.0189\n",
      "Epoch 905/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0171 - val_loss: 0.0141\n",
      "Epoch 906/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0105 - val_loss: 0.0131\n",
      "Epoch 907/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0145 - val_loss: 0.0133\n",
      "Epoch 908/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0127 - val_loss: 0.0106\n",
      "Epoch 909/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0114 - val_loss: 0.0145\n",
      "Epoch 910/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 911/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0111 - val_loss: 0.0126\n",
      "Epoch 912/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0126 - val_loss: 0.0102\n",
      "Epoch 913/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0105 - val_loss: 0.0167\n",
      "Epoch 914/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0142 - val_loss: 0.0109\n",
      "Epoch 915/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0101 - val_loss: 0.0125\n",
      "Epoch 916/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0128 - val_loss: 0.0106\n",
      "Epoch 917/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 918/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0114 - val_loss: 0.0135\n",
      "Epoch 919/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0144 - val_loss: 0.0157\n",
      "Epoch 920/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0219 - val_loss: 0.0349\n",
      "Epoch 921/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0407 - val_loss: 0.0198\n",
      "Epoch 922/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0193 - val_loss: 0.0189\n",
      "Epoch 923/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0210 - val_loss: 0.0142\n",
      "Epoch 924/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0126\n",
      "Epoch 925/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0162 - val_loss: 0.0192\n",
      "Epoch 926/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0178 - val_loss: 0.0173\n",
      "Epoch 927/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0208 - val_loss: 0.0391\n",
      "Epoch 928/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0330 - val_loss: 0.0271\n",
      "Epoch 929/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0307 - val_loss: 0.0313\n",
      "Epoch 930/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0281 - val_loss: 0.0244\n",
      "Epoch 931/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0256 - val_loss: 0.0246\n",
      "Epoch 932/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0184 - val_loss: 0.0174\n",
      "Epoch 933/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0246 - val_loss: 0.0141\n",
      "Epoch 934/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0130 - val_loss: 0.0146\n",
      "Epoch 935/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0133 - val_loss: 0.0221\n",
      "Epoch 936/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0230 - val_loss: 0.0197\n",
      "Epoch 937/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 31us/step - loss: 0.0187 - val_loss: 0.0174\n",
      "Epoch 938/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0167 - val_loss: 0.0126\n",
      "Epoch 939/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0106 - val_loss: 0.0120\n",
      "Epoch 940/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0129\n",
      "Epoch 941/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0114 - val_loss: 0.0145\n",
      "Epoch 942/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0151\n",
      "Epoch 943/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0129 - val_loss: 0.0131\n",
      "Epoch 944/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 945/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 946/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 947/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 948/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0138\n",
      "Epoch 949/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0120 - val_loss: 0.0177\n",
      "Epoch 950/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0217 - val_loss: 0.0125\n",
      "Epoch 951/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0174 - val_loss: 0.0260\n",
      "Epoch 952/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0229 - val_loss: 0.0323\n",
      "Epoch 953/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0261 - val_loss: 0.0267\n",
      "Epoch 954/1500\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.021 - 0s 39us/step - loss: 0.0233 - val_loss: 0.0271\n",
      "Epoch 955/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0224 - val_loss: 0.0274\n",
      "Epoch 956/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0221 - val_loss: 0.0265\n",
      "Epoch 957/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0222 - val_loss: 0.0276\n",
      "Epoch 958/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0233 - val_loss: 0.0256\n",
      "Epoch 959/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0213 - val_loss: 0.0400\n",
      "Epoch 960/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0407 - val_loss: 0.0436\n",
      "Epoch 961/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0302 - val_loss: 0.0326\n",
      "Epoch 962/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0331 - val_loss: 0.0248\n",
      "Epoch 963/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0216 - val_loss: 0.0394\n",
      "Epoch 964/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0312 - val_loss: 0.0223\n",
      "Epoch 965/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0234 - val_loss: 0.0419\n",
      "Epoch 966/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0391 - val_loss: 0.0202\n",
      "Epoch 967/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0202 - val_loss: 0.0474\n",
      "Epoch 968/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0382 - val_loss: 0.0200\n",
      "Epoch 969/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0164 - val_loss: 0.0310\n",
      "Epoch 970/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0301 - val_loss: 0.0180\n",
      "Epoch 971/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0154 - val_loss: 0.0242\n",
      "Epoch 972/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0224 - val_loss: 0.0177\n",
      "Epoch 973/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0173 - val_loss: 0.0429\n",
      "Epoch 974/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0451 - val_loss: 0.0175\n",
      "Epoch 975/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0159 - val_loss: 0.0243\n",
      "Epoch 976/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0245 - val_loss: 0.0345\n",
      "Epoch 977/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0312 - val_loss: 0.0299\n",
      "Epoch 978/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0297 - val_loss: 0.0221\n",
      "Epoch 979/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0258 - val_loss: 0.0189\n",
      "Epoch 980/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0218 - val_loss: 0.0205\n",
      "Epoch 981/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0220 - val_loss: 0.0171\n",
      "Epoch 982/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0208 - val_loss: 0.0182\n",
      "Epoch 983/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0218 - val_loss: 0.0191\n",
      "Epoch 984/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0175 - val_loss: 0.0193\n",
      "Epoch 985/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0181 - val_loss: 0.0212\n",
      "Epoch 986/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0184 - val_loss: 0.0194\n",
      "Epoch 987/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0166 - val_loss: 0.0192\n",
      "Epoch 988/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0160 - val_loss: 0.0208\n",
      "Epoch 989/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0169 - val_loss: 0.0185\n",
      "Epoch 990/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0142 - val_loss: 0.0197\n",
      "Epoch 991/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0186 - val_loss: 0.0164\n",
      "Epoch 992/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0188 - val_loss: 0.0370\n",
      "Epoch 993/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0315 - val_loss: 0.0223\n",
      "Epoch 994/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0290 - val_loss: 0.0356\n",
      "Epoch 995/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0386 - val_loss: 0.0187\n",
      "Epoch 996/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0229 - val_loss: 0.0300\n",
      "Epoch 997/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0284 - val_loss: 0.0198\n",
      "Epoch 998/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0171 - val_loss: 0.0159\n",
      "Epoch 999/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0202 - val_loss: 0.0149\n",
      "Epoch 1000/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0187 - val_loss: 0.0370\n",
      "Epoch 1001/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0323 - val_loss: 0.0148\n",
      "Epoch 1002/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0139 - val_loss: 0.0153\n",
      "Epoch 1003/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0139 - val_loss: 0.0150\n",
      "Epoch 1004/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0176 - val_loss: 0.0143\n",
      "Epoch 1005/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0148 - val_loss: 0.0361\n",
      "Epoch 1006/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0327 - val_loss: 0.0480\n",
      "Epoch 1007/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0354 - val_loss: 0.0346\n",
      "Epoch 1008/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0279 - val_loss: 0.0284\n",
      "Epoch 1009/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0227 - val_loss: 0.0214\n",
      "Epoch 1010/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0184 - val_loss: 0.0381\n",
      "Epoch 1011/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0333 - val_loss: 0.0260\n",
      "Epoch 1012/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0183 - val_loss: 0.0156\n",
      "Epoch 1013/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 1014/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0139 - val_loss: 0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1015/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0154 - val_loss: 0.0161\n",
      "Epoch 1016/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0148 - val_loss: 0.0118\n",
      "Epoch 1017/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0128 - val_loss: 0.0112\n",
      "Epoch 1018/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0136 - val_loss: 0.0109\n",
      "Epoch 1019/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0128 - val_loss: 0.0104\n",
      "Epoch 1020/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 1021/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 1022/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 1023/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0101 - val_loss: 0.0124\n",
      "Epoch 1024/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0128 - val_loss: 0.0173\n",
      "Epoch 1025/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0203 - val_loss: 0.0147\n",
      "Epoch 1026/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0165 - val_loss: 0.0127\n",
      "Epoch 1027/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0147 - val_loss: 0.0155\n",
      "Epoch 1028/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0393 - val_loss: 0.1376\n",
      "Epoch 1029/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.1098 - val_loss: 0.0396\n",
      "Epoch 1030/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0454 - val_loss: 0.1129\n",
      "Epoch 1031/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.1026 - val_loss: 0.0813\n",
      "Epoch 1032/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0673 - val_loss: 0.0368\n",
      "Epoch 1033/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0368 - val_loss: 0.0108\n",
      "Epoch 1034/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0139 - val_loss: 0.0209\n",
      "Epoch 1035/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0199 - val_loss: 0.0157\n",
      "Epoch 1036/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0199 - val_loss: 0.0168\n",
      "Epoch 1037/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0207 - val_loss: 0.0128\n",
      "Epoch 1038/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0165 - val_loss: 0.0128\n",
      "Epoch 1039/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0150 - val_loss: 0.0124\n",
      "Epoch 1040/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0170 - val_loss: 0.0123\n",
      "Epoch 1041/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0145 - val_loss: 0.0158\n",
      "Epoch 1042/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0169 - val_loss: 0.0377\n",
      "Epoch 1043/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0334 - val_loss: 0.0307\n",
      "Epoch 1044/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0225 - val_loss: 0.0323\n",
      "Epoch 1045/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0322 - val_loss: 0.0172\n",
      "Epoch 1046/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0156 - val_loss: 0.0215\n",
      "Epoch 1047/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0196 - val_loss: 0.0153\n",
      "Epoch 1048/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0153 - val_loss: 0.0117\n",
      "Epoch 1049/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0147 - val_loss: 0.0101\n",
      "Epoch 1050/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 1051/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 1052/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0141 - val_loss: 0.0172\n",
      "Epoch 1053/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0149 - val_loss: 0.0150\n",
      "Epoch 1054/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0127 - val_loss: 0.0109\n",
      "Epoch 1055/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 1056/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 1057/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0136 - val_loss: 0.0174\n",
      "Epoch 1058/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0145 - val_loss: 0.0113\n",
      "Epoch 1059/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0149\n",
      "Epoch 1060/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0162 - val_loss: 0.0110\n",
      "Epoch 1061/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 1062/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 1063/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 1064/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0103 - val_loss: 0.0172\n",
      "Epoch 1065/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0256 - val_loss: 0.0481\n",
      "Epoch 1066/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0493 - val_loss: 0.0511\n",
      "Epoch 1067/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0512 - val_loss: 0.0512\n",
      "Epoch 1068/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0510 - val_loss: 0.0484\n",
      "Epoch 1069/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0474 - val_loss: 0.0557\n",
      "Epoch 1070/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0534 - val_loss: 0.0468\n",
      "Epoch 1071/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0462 - val_loss: 0.0419\n",
      "Epoch 1072/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0467 - val_loss: 0.0371\n",
      "Epoch 1073/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0429 - val_loss: 0.0374\n",
      "Epoch 1074/1500\n",
      "514/514 [==============================] - 0s 67us/step - loss: 0.0411 - val_loss: 0.0278\n",
      "Epoch 1075/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0355 - val_loss: 0.0251\n",
      "Epoch 1076/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0281 - val_loss: 0.0274\n",
      "Epoch 1077/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0322 - val_loss: 0.0173\n",
      "Epoch 1078/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0186 - val_loss: 0.0194\n",
      "Epoch 1079/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0210 - val_loss: 0.0131\n",
      "Epoch 1080/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0153 - val_loss: 0.0148\n",
      "Epoch 1081/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0160 - val_loss: 0.0137\n",
      "Epoch 1082/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0155 - val_loss: 0.0171\n",
      "Epoch 1083/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0175 - val_loss: 0.0129\n",
      "Epoch 1084/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0152 - val_loss: 0.0311\n",
      "Epoch 1085/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0297 - val_loss: 0.0296\n",
      "Epoch 1086/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0304 - val_loss: 0.0258\n",
      "Epoch 1087/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0355 - val_loss: 0.0335\n",
      "Epoch 1088/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0612 - val_loss: 0.0479\n",
      "Epoch 1089/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0634 - val_loss: 0.0303\n",
      "Epoch 1090/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0286 - val_loss: 0.0259\n",
      "Epoch 1091/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0270 - val_loss: 0.0275\n",
      "Epoch 1092/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 62us/step - loss: 0.0266 - val_loss: 0.0292\n",
      "Epoch 1093/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0254 - val_loss: 0.0259\n",
      "Epoch 1094/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0206 - val_loss: 0.0181\n",
      "Epoch 1095/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0148 - val_loss: 0.0157\n",
      "Epoch 1096/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0161 - val_loss: 0.0125\n",
      "Epoch 1097/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0130 - val_loss: 0.0192\n",
      "Epoch 1098/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0186 - val_loss: 0.0232\n",
      "Epoch 1099/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0189 - val_loss: 0.0255\n",
      "Epoch 1100/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0220 - val_loss: 0.0294\n",
      "Epoch 1101/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0239 - val_loss: 0.0275\n",
      "Epoch 1102/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0228 - val_loss: 0.0313\n",
      "Epoch 1103/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0241 - val_loss: 0.0300\n",
      "Epoch 1104/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0221 - val_loss: 0.0303\n",
      "Epoch 1105/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0229 - val_loss: 0.0309\n",
      "Epoch 1106/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0223 - val_loss: 0.0302\n",
      "Epoch 1107/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0217 - val_loss: 0.0317\n",
      "Epoch 1108/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0236 - val_loss: 0.0332\n",
      "Epoch 1109/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0245 - val_loss: 0.0450\n",
      "Epoch 1110/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0337 - val_loss: 0.0356\n",
      "Epoch 1111/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0256 - val_loss: 0.0306\n",
      "Epoch 1112/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0220 - val_loss: 0.0288\n",
      "Epoch 1113/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0215 - val_loss: 0.0291\n",
      "Epoch 1114/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0223 - val_loss: 0.0289\n",
      "Epoch 1115/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0217 - val_loss: 0.0300\n",
      "Epoch 1116/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0238 - val_loss: 0.0311\n",
      "Epoch 1117/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0240 - val_loss: 0.0294\n",
      "Epoch 1118/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0222 - val_loss: 0.0312\n",
      "Epoch 1119/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0227 - val_loss: 0.0300\n",
      "Epoch 1120/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0241 - val_loss: 0.0354\n",
      "Epoch 1121/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0315 - val_loss: 0.0398\n",
      "Epoch 1122/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0399 - val_loss: 0.0447\n",
      "Epoch 1123/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0386 - val_loss: 0.0380\n",
      "Epoch 1124/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0345 - val_loss: 0.0437\n",
      "Epoch 1125/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0351 - val_loss: 0.0319\n",
      "Epoch 1126/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0243 - val_loss: 0.0389\n",
      "Epoch 1127/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0359 - val_loss: 0.0434\n",
      "Epoch 1128/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0340 - val_loss: 0.0315\n",
      "Epoch 1129/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0232 - val_loss: 0.0426\n",
      "Epoch 1130/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0330 - val_loss: 0.0370\n",
      "Epoch 1131/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0256 - val_loss: 0.0318\n",
      "Epoch 1132/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0272 - val_loss: 0.0463\n",
      "Epoch 1133/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0395 - val_loss: 0.0334\n",
      "Epoch 1134/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0248 - val_loss: 0.0306\n",
      "Epoch 1135/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0241 - val_loss: 0.0352\n",
      "Epoch 1136/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0277 - val_loss: 0.0351\n",
      "Epoch 1137/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0273 - val_loss: 0.0315\n",
      "Epoch 1138/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0230 - val_loss: 0.0289\n",
      "Epoch 1139/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0219 - val_loss: 0.0305\n",
      "Epoch 1140/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0228 - val_loss: 0.0330\n",
      "Epoch 1141/1500\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.017 - 0s 39us/step - loss: 0.0262 - val_loss: 0.0306\n",
      "Epoch 1142/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0249 - val_loss: 0.0507\n",
      "Epoch 1143/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0460 - val_loss: 0.0444\n",
      "Epoch 1144/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0437 - val_loss: 0.0472\n",
      "Epoch 1145/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0495 - val_loss: 0.0501\n",
      "Epoch 1146/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0496 - val_loss: 0.0442\n",
      "Epoch 1147/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0435 - val_loss: 0.0422\n",
      "Epoch 1148/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0406 - val_loss: 0.0427\n",
      "Epoch 1149/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0392 - val_loss: 0.0404\n",
      "Epoch 1150/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0361 - val_loss: 0.0372\n",
      "Epoch 1151/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0307 - val_loss: 0.0387\n",
      "Epoch 1152/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0349 - val_loss: 0.0473\n",
      "Epoch 1153/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0411 - val_loss: 0.0363\n",
      "Epoch 1154/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0286 - val_loss: 0.0314\n",
      "Epoch 1155/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0257 - val_loss: 0.0321\n",
      "Epoch 1156/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0250 - val_loss: 0.0290\n",
      "Epoch 1157/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0245 - val_loss: 0.0298\n",
      "Epoch 1158/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0250 - val_loss: 0.0275\n",
      "Epoch 1159/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0228 - val_loss: 0.0270\n",
      "Epoch 1160/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0224 - val_loss: 0.0273\n",
      "Epoch 1161/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0225 - val_loss: 0.0294\n",
      "Epoch 1162/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0229 - val_loss: 0.0271\n",
      "Epoch 1163/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0213 - val_loss: 0.0265\n",
      "Epoch 1164/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0219 - val_loss: 0.0262\n",
      "Epoch 1165/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0223 - val_loss: 0.0238\n",
      "Epoch 1166/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0197 - val_loss: 0.0229\n",
      "Epoch 1167/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0201 - val_loss: 0.0230\n",
      "Epoch 1168/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0198 - val_loss: 0.0205\n",
      "Epoch 1169/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 47us/step - loss: 0.0170 - val_loss: 0.0241\n",
      "Epoch 1170/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0191 - val_loss: 0.0239\n",
      "Epoch 1171/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0187 - val_loss: 0.0177\n",
      "Epoch 1172/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0143 - val_loss: 0.0139\n",
      "Epoch 1173/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0146 - val_loss: 0.0126\n",
      "Epoch 1174/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0142 - val_loss: 0.0135\n",
      "Epoch 1175/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0124 - val_loss: 0.0119\n",
      "Epoch 1176/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 1177/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0132 - val_loss: 0.0113\n",
      "Epoch 1178/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0120\n",
      "Epoch 1179/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0128 - val_loss: 0.0120\n",
      "Epoch 1180/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0135 - val_loss: 0.0131\n",
      "Epoch 1181/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0138 - val_loss: 0.0152\n",
      "Epoch 1182/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0123 - val_loss: 0.0113\n",
      "Epoch 1183/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0141 - val_loss: 0.0125\n",
      "Epoch 1184/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0138 - val_loss: 0.0108\n",
      "Epoch 1185/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0113 - val_loss: 0.0144\n",
      "Epoch 1186/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0133 - val_loss: 0.0119\n",
      "Epoch 1187/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0125 - val_loss: 0.0136\n",
      "Epoch 1188/1500\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.013 - 0s 39us/step - loss: 0.0146 - val_loss: 0.0116\n",
      "Epoch 1189/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0120 - val_loss: 0.0112\n",
      "Epoch 1190/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0112 - val_loss: 0.0136\n",
      "Epoch 1191/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0126 - val_loss: 0.0146\n",
      "Epoch 1192/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0125 - val_loss: 0.0126\n",
      "Epoch 1193/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 1194/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 1195/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 1196/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0115 - val_loss: 0.0140\n",
      "Epoch 1197/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0105\n",
      "Epoch 1198/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 1199/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 1200/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 1201/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0104 - val_loss: 0.0148\n",
      "Epoch 1202/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0134 - val_loss: 0.0112\n",
      "Epoch 1203/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0105 - val_loss: 0.0118\n",
      "Epoch 1204/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0142 - val_loss: 0.0114\n",
      "Epoch 1205/1500\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.013 - 0s 39us/step - loss: 0.0122 - val_loss: 0.0128\n",
      "Epoch 1206/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0138 - val_loss: 0.0218\n",
      "Epoch 1207/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0171 - val_loss: 0.0125\n",
      "Epoch 1208/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 1209/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0110 - val_loss: 0.0186\n",
      "Epoch 1210/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0219 - val_loss: 0.0318\n",
      "Epoch 1211/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0340 - val_loss: 0.0251\n",
      "Epoch 1212/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0267 - val_loss: 0.0174\n",
      "Epoch 1213/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0233 - val_loss: 0.0151\n",
      "Epoch 1214/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0194 - val_loss: 0.0189\n",
      "Epoch 1215/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0216 - val_loss: 0.0115\n",
      "Epoch 1216/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0151 - val_loss: 0.0166\n",
      "Epoch 1217/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0193 - val_loss: 0.0142\n",
      "Epoch 1218/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0148 - val_loss: 0.0120\n",
      "Epoch 1219/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0277\n",
      "Epoch 1220/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0273 - val_loss: 0.0276\n",
      "Epoch 1221/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0209 - val_loss: 0.0107\n",
      "Epoch 1222/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0129 - val_loss: 0.0134\n",
      "Epoch 1223/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0145 - val_loss: 0.0103\n",
      "Epoch 1224/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0104 - val_loss: 0.0117\n",
      "Epoch 1225/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0109 - val_loss: 0.0135\n",
      "Epoch 1226/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0119 - val_loss: 0.0131\n",
      "Epoch 1227/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0123 - val_loss: 0.0125\n",
      "Epoch 1228/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 1229/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 1230/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 1231/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 1232/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0124 - val_loss: 0.0151\n",
      "Epoch 1233/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0190 - val_loss: 0.0138\n",
      "Epoch 1234/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0161 - val_loss: 0.0099\n",
      "Epoch 1235/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0110 - val_loss: 0.0191\n",
      "Epoch 1236/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0176 - val_loss: 0.0159\n",
      "Epoch 1237/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0131 - val_loss: 0.0096\n",
      "Epoch 1238/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 1239/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 1240/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0102 - val_loss: 0.0165\n",
      "Epoch 1241/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0142 - val_loss: 0.0170\n",
      "Epoch 1242/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0130 - val_loss: 0.0107\n",
      "Epoch 1243/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0101 - val_loss: 0.0136\n",
      "Epoch 1244/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0161 - val_loss: 0.0114\n",
      "Epoch 1245/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0116 - val_loss: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1246/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0161 - val_loss: 0.0160\n",
      "Epoch 1247/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0154 - val_loss: 0.0104\n",
      "Epoch 1248/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 1249/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 1250/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0101 - val_loss: 0.0181\n",
      "Epoch 1251/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0167 - val_loss: 0.0175\n",
      "Epoch 1252/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0128 - val_loss: 0.0132\n",
      "Epoch 1253/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0134 - val_loss: 0.0167\n",
      "Epoch 1254/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0172 - val_loss: 0.0145\n",
      "Epoch 1255/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0145 - val_loss: 0.0124\n",
      "Epoch 1256/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0120 - val_loss: 0.0137\n",
      "Epoch 1257/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0128 - val_loss: 0.0131\n",
      "Epoch 1258/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0119 - val_loss: 0.0101\n",
      "Epoch 1259/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 1260/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0127 - val_loss: 0.0098\n",
      "Epoch 1261/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0109 - val_loss: 0.0139\n",
      "Epoch 1262/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0140 - val_loss: 0.0201\n",
      "Epoch 1263/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0164 - val_loss: 0.0155\n",
      "Epoch 1264/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0144 - val_loss: 0.0161\n",
      "Epoch 1265/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0137 - val_loss: 0.0168\n",
      "Epoch 1266/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0134 - val_loss: 0.0166\n",
      "Epoch 1267/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0127 - val_loss: 0.0135\n",
      "Epoch 1268/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0134\n",
      "Epoch 1269/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0143 - val_loss: 0.0123\n",
      "Epoch 1270/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 1271/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 1272/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 1273/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0112 - val_loss: 0.0127\n",
      "Epoch 1274/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0127 - val_loss: 0.0140\n",
      "Epoch 1275/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0124 - val_loss: 0.0168\n",
      "Epoch 1276/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0143 - val_loss: 0.0177\n",
      "Epoch 1277/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0134 - val_loss: 0.0135\n",
      "Epoch 1278/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 1279/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0127 - val_loss: 0.0130\n",
      "Epoch 1280/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0126 - val_loss: 0.0114\n",
      "Epoch 1281/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0105 - val_loss: 0.0171\n",
      "Epoch 1282/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 1283/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 1284/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 1285/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0115 - val_loss: 0.0098\n",
      "Epoch 1286/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0158\n",
      "Epoch 1287/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0173 - val_loss: 0.0123\n",
      "Epoch 1288/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0128 - val_loss: 0.0101\n",
      "Epoch 1289/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 1290/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0117\n",
      "Epoch 1291/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0108 - val_loss: 0.0147\n",
      "Epoch 1292/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0128 - val_loss: 0.0161\n",
      "Epoch 1293/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0129 - val_loss: 0.0164\n",
      "Epoch 1294/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0129 - val_loss: 0.0161\n",
      "Epoch 1295/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0128 - val_loss: 0.0151\n",
      "Epoch 1296/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 1297/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 1298/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 1299/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 1300/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 1301/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 1302/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 1303/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 1304/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 1305/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 1306/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 1307/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0100 - val_loss: 0.0121\n",
      "Epoch 1308/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 1309/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0104 - val_loss: 0.0141\n",
      "Epoch 1310/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0143 - val_loss: 0.0121\n",
      "Epoch 1311/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 1312/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0113 - val_loss: 0.0209\n",
      "Epoch 1313/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0193 - val_loss: 0.0179\n",
      "Epoch 1314/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0140 - val_loss: 0.0115\n",
      "Epoch 1315/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0209\n",
      "Epoch 1316/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0208 - val_loss: 0.0177\n",
      "Epoch 1317/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0166 - val_loss: 0.0234\n",
      "Epoch 1318/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0244 - val_loss: 0.0225\n",
      "Epoch 1319/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0191 - val_loss: 0.0131\n",
      "Epoch 1320/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0113 - val_loss: 0.0161\n",
      "Epoch 1321/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0161 - val_loss: 0.0165\n",
      "Epoch 1322/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0155 - val_loss: 0.0129\n",
      "Epoch 1323/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 39us/step - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 1324/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 1325/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 1326/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 1327/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0135 - val_loss: 0.0106\n",
      "Epoch 1328/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 1329/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 1330/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0120 - val_loss: 0.0136\n",
      "Epoch 1331/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 1332/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0095 - val_loss: 0.0119\n",
      "Epoch 1333/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 1334/1500\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.013 - 0s 39us/step - loss: 0.0117 - val_loss: 0.0098\n",
      "Epoch 1335/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0095 - val_loss: 0.0131\n",
      "Epoch 1336/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0123 - val_loss: 0.0143\n",
      "Epoch 1337/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0124 - val_loss: 0.0107\n",
      "Epoch 1338/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0120 - val_loss: 0.0095\n",
      "Epoch 1339/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0097\n",
      "Epoch 1340/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 1341/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 1342/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 1343/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 1344/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 1345/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0117 - val_loss: 0.0132\n",
      "Epoch 1346/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 1347/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 1348/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 1349/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0097 - val_loss: 0.0123\n",
      "Epoch 1350/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 1351/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 1352/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 1353/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 1354/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0123 - val_loss: 0.0112\n",
      "Epoch 1355/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 1356/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 1357/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0095 - val_loss: 0.0119\n",
      "Epoch 1358/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 1359/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0101 - val_loss: 0.0120\n",
      "Epoch 1360/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 1361/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 1362/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 1363/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0093 - val_loss: 0.0105\n",
      "Epoch 1364/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0093 - val_loss: 0.0113\n",
      "Epoch 1365/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 1366/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0091 - val_loss: 0.0102\n",
      "Epoch 1367/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 1368/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0092 - val_loss: 0.0103\n",
      "Epoch 1369/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 1370/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 1371/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 1372/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0092 - val_loss: 0.0105\n",
      "Epoch 1373/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 1374/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 1375/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 1376/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 1377/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 1378/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0090 - val_loss: 0.0121\n",
      "Epoch 1379/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 1380/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0104 - val_loss: 0.0129\n",
      "Epoch 1381/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0127 - val_loss: 0.0155\n",
      "Epoch 1382/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0139 - val_loss: 0.0171\n",
      "Epoch 1383/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0150 - val_loss: 0.0186\n",
      "Epoch 1384/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0169 - val_loss: 0.0215\n",
      "Epoch 1385/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0202 - val_loss: 0.0233\n",
      "Epoch 1386/1500\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.020 - 0s 39us/step - loss: 0.0192 - val_loss: 0.0246\n",
      "Epoch 1387/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0243 - val_loss: 0.0258\n",
      "Epoch 1388/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0215 - val_loss: 0.0280\n",
      "Epoch 1389/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0234 - val_loss: 0.0275\n",
      "Epoch 1390/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0217 - val_loss: 0.0277\n",
      "Epoch 1391/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0206 - val_loss: 0.0245\n",
      "Epoch 1392/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0179 - val_loss: 0.0348\n",
      "Epoch 1393/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0273 - val_loss: 0.0297\n",
      "Epoch 1394/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0195 - val_loss: 0.0217\n",
      "Epoch 1395/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0163 - val_loss: 0.0204\n",
      "Epoch 1396/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0157 - val_loss: 0.0185\n",
      "Epoch 1397/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0129 - val_loss: 0.0187\n",
      "Epoch 1398/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0144 - val_loss: 0.0174\n",
      "Epoch 1399/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0119 - val_loss: 0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1400/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 1401/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0112 - val_loss: 0.0138\n",
      "Epoch 1402/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 1403/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0150 - val_loss: 0.0245\n",
      "Epoch 1404/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0256 - val_loss: 0.0266\n",
      "Epoch 1405/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0247 - val_loss: 0.0234\n",
      "Epoch 1406/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0193 - val_loss: 0.0268\n",
      "Epoch 1407/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0214 - val_loss: 0.0305\n",
      "Epoch 1408/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0260 - val_loss: 0.0337\n",
      "Epoch 1409/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0269 - val_loss: 0.0275\n",
      "Epoch 1410/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0222 - val_loss: 0.0274\n",
      "Epoch 1411/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0249 - val_loss: 0.0252\n",
      "Epoch 1412/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0219 - val_loss: 0.0213\n",
      "Epoch 1413/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0192 - val_loss: 0.0248\n",
      "Epoch 1414/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0222 - val_loss: 0.0324\n",
      "Epoch 1415/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0257 - val_loss: 0.0159\n",
      "Epoch 1416/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0149 - val_loss: 0.0331\n",
      "Epoch 1417/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0369 - val_loss: 0.0214\n",
      "Epoch 1418/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0186 - val_loss: 0.0244\n",
      "Epoch 1419/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0219 - val_loss: 0.0176\n",
      "Epoch 1420/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0156 - val_loss: 0.0110\n",
      "Epoch 1421/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 1422/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 1423/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 1424/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 1425/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 1426/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 1427/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0110 - val_loss: 0.0163\n",
      "Epoch 1428/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0142 - val_loss: 0.0225\n",
      "Epoch 1429/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0188 - val_loss: 0.0259\n",
      "Epoch 1430/1500\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.022 - 0s 39us/step - loss: 0.0223 - val_loss: 0.0259\n",
      "Epoch 1431/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0234 - val_loss: 0.0195\n",
      "Epoch 1432/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0165 - val_loss: 0.0180\n",
      "Epoch 1433/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0166 - val_loss: 0.0211\n",
      "Epoch 1434/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0163 - val_loss: 0.0116\n",
      "Epoch 1435/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 1436/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0130 - val_loss: 0.0118\n",
      "Epoch 1437/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0124 - val_loss: 0.0107\n",
      "Epoch 1438/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0101 - val_loss: 0.0128\n",
      "Epoch 1439/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0163\n",
      "Epoch 1440/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0130 - val_loss: 0.0150\n",
      "Epoch 1441/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0117 - val_loss: 0.0155\n",
      "Epoch 1442/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0127 - val_loss: 0.0143\n",
      "Epoch 1443/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0130 - val_loss: 0.0125\n",
      "Epoch 1444/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 1445/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0100 - val_loss: 0.0128\n",
      "Epoch 1446/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0116 - val_loss: 0.0146\n",
      "Epoch 1447/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 1448/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 1449/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 1450/1500\n",
      "514/514 [==============================] - 0s 86us/step - loss: 0.0097 - val_loss: 0.0111\n",
      "Epoch 1451/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0096 - val_loss: 0.0127\n",
      "Epoch 1452/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0106 - val_loss: 0.0127\n",
      "Epoch 1453/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0102 - val_loss: 0.0117\n",
      "Epoch 1454/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0095 - val_loss: 0.0115\n",
      "Epoch 1455/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0097 - val_loss: 0.0117\n",
      "Epoch 1456/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 1457/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 1458/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 1459/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 1460/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 1461/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0097 - val_loss: 0.0138\n",
      "Epoch 1462/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0122 - val_loss: 0.0147\n",
      "Epoch 1463/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0123 - val_loss: 0.0127\n",
      "Epoch 1464/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 1465/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0093 - val_loss: 0.0107\n",
      "Epoch 1466/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0093 - val_loss: 0.0105\n",
      "Epoch 1467/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 1468/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0094 - val_loss: 0.0106\n",
      "Epoch 1469/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0092 - val_loss: 0.0105\n",
      "Epoch 1470/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0091 - val_loss: 0.0107\n",
      "Epoch 1471/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 1472/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0099 - val_loss: 0.0104\n",
      "Epoch 1473/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0090 - val_loss: 0.0114\n",
      "Epoch 1474/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 1475/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 1476/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 1477/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 39us/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 1478/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0096 - val_loss: 0.0121\n",
      "Epoch 1479/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0111 - val_loss: 0.0154\n",
      "Epoch 1480/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0125 - val_loss: 0.0116\n",
      "Epoch 1481/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 1482/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 1483/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0092 - val_loss: 0.0105\n",
      "Epoch 1484/1500\n",
      "514/514 [==============================] - 0s 54us/step - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 1485/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 1486/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 1487/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0091 - val_loss: 0.0102\n",
      "Epoch 1488/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0091 - val_loss: 0.0154\n",
      "Epoch 1489/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0267 - val_loss: 0.0821\n",
      "Epoch 1490/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0538 - val_loss: 0.0140\n",
      "Epoch 1491/1500\n",
      "514/514 [==============================] - 0s 47us/step - loss: 0.0180 - val_loss: 0.0230\n",
      "Epoch 1492/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0256 - val_loss: 0.0147\n",
      "Epoch 1493/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0146 - val_loss: 0.0158\n",
      "Epoch 1494/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0159 - val_loss: 0.0216\n",
      "Epoch 1495/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0159 - val_loss: 0.0120\n",
      "Epoch 1496/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0124 - val_loss: 0.0139\n",
      "Epoch 1497/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0150 - val_loss: 0.0108\n",
      "Epoch 1498/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0113 - val_loss: 0.0099\n",
      "Epoch 1499/1500\n",
      "514/514 [==============================] - 0s 31us/step - loss: 0.0102 - val_loss: 0.0136\n",
      "Epoch 1500/1500\n",
      "514/514 [==============================] - 0s 39us/step - loss: 0.0127 - val_loss: 0.0119\n"
     ]
    }
   ],
   "source": [
    "# fit the model - INTENSIVE\n",
    "model3_history = model3.fit(X_train, Y_train, batch_size=256, epochs=1500, verbose=1, \\\n",
    "                            shuffle = True, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model3_history.model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use our model to predict in the range we want\n",
    "num_epochs = f'{len(model2_history.epoch)}'\n",
    "\n",
    "X_range = np.linspace(-10, 10, 500)\n",
    "y_pred = model3.predict(X_range)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(X_train, Y_train, label='Training data')\n",
    "ax.plot(X_range, y_pred, lw=4, color='r', label=f'NN ({num_epochs} epochs)')\n",
    "\n",
    "ax.set_xlabel(r'$X$', fontsize=20)\n",
    "ax.set_ylabel(r'$Y$', fontsize=20)\n",
    "ax.set_title(f'NN with {len(model3_history.model.layers)} layers, {H} nodes in each layer', fontsize=LABEL_SIZE)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(model2_history.history['loss']), 'r')\n",
    "ax.plot(np.sqrt(model2_history.history['val_loss']), 'b' ,label='Val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735/735 [==============================] - 0s 16us/step\n",
      "Train loss: 0.011322496814944712\n",
      "Train R2: 0.818909046860434\n"
     ]
    }
   ],
   "source": [
    "# evaluate the training and testing performance of your model \n",
    "# note: you should extract and check both the loss function and your evaluation metric\n",
    "score = model2.evaluate(X_train, Y_train, verbose=1)\n",
    "print('Train loss:', score)\n",
    "print('Train R2:', r2(Y_train, model2.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 0s 13us/step\n",
      "Test loss: 0.011951396028910365\n",
      "Test R2: 0.8214686701532138\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', score)\n",
    "print('Test R2:', r2(Y_test, model2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a better score this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"exercise\"><b>Exercise 5</b> </div>\n",
    "\n",
    "Usually we want to avoid overfitting of the data to our model. But here we want to achive overfitting! So we can regularize! There are a few reasons why a model overfits. One is the lack of data. So we will try to overfit by reducing the data. Try that with model3 and see if it overfits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having very few points in our data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50 # set the number of samples to take for each dataset\n",
    "test_size = 0.3 # set the proportion of data to hold out for testing\n",
    "\n",
    "# define the function and add noise\n",
    "\n",
    "def f_gauss(x):\n",
    "    return np.exp(-x * x) + np.random.normal(loc=0, scale=.1, size = x.shape[0])\n",
    "\n",
    "X = np.random.permutation(np.linspace(-10, 10, n_samples)) # choose some points from the function\n",
    "Y = f_gauss(X)\n",
    "\n",
    "# create training and testing data from this set of points\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1685784b38>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of hidden nodes\n",
    "H =  100\n",
    "# input dimension\n",
    "input_dim = 1\n",
    "\n",
    "# create sequential multi-layer perceptron\n",
    "model4 = models.Sequential()\n",
    "# layer 0\n",
    "model4.add(layers.Dense(H, input_dim=input_dim,  \n",
    "                activation='tanh')) \n",
    "# layer 1\n",
    "model4.add(layers.Dense(H,\n",
    "                activation='tanh')) \n",
    "# layer 2\n",
    "model4.add(layers.Dense(H,\n",
    "                activation='tanh')) \n",
    "# layer 3\n",
    "model4.add(layers.Dense(H,  \n",
    "                activation='tanh')) \n",
    "# layer 4\n",
    "model4.add(layers.Dense(H,  \n",
    "                activation='tanh')) \n",
    "# layer 5\n",
    "model4.add(layers.Dense(H,  \n",
    "                activation='tanh')) \n",
    "# layer 6\n",
    "model4.add(layers.Dense(H,  \n",
    "                activation='tanh'))\n",
    "# layer 7\n",
    "model4.add(layers.Dense(H,  \n",
    "                activation='tanh'))\n",
    "# layer 8\n",
    "model4.add(layers.Dense(H,  \n",
    "                activation='tanh'))\n",
    "# layer 9\n",
    "model4.add(layers.Dense(H,  \n",
    "                activation='tanh'))\n",
    "# layer 10 - output\n",
    "model4.add(layers.Dense(1, \n",
    "                activation='linear')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the model\n",
    "model4.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 7 samples\n",
      "Epoch 1/1500\n",
      "28/28 [==============================] - 1s 29ms/step - loss: 0.0826 - val_loss: 2.2811\n",
      "Epoch 2/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 2.0405 - val_loss: 0.0863\n",
      "Epoch 3/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.1419 - val_loss: 0.8414\n",
      "Epoch 4/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.7215 - val_loss: 0.9357\n",
      "Epoch 5/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8161 - val_loss: 0.3726\n",
      "Epoch 6/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3607 - val_loss: 0.0290\n",
      "Epoch 7/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0788 - val_loss: 0.0736\n",
      "Epoch 8/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.1190 - val_loss: 0.2319\n",
      "Epoch 9/1500\n",
      "28/28 [==============================] - 0s 161us/step - loss: 0.2565 - val_loss: 0.2298\n",
      "Epoch 10/1500\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.2573 - val_loss: 0.1042\n",
      "Epoch 11/1500\n",
      "28/28 [==============================] - 0s 161us/step - loss: 0.1503 - val_loss: 0.0116\n",
      "Epoch 12/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0691 - val_loss: 0.0382\n",
      "Epoch 13/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0881 - val_loss: 0.1245\n",
      "Epoch 14/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1583 - val_loss: 0.1547\n",
      "Epoch 15/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1815 - val_loss: 0.1073\n",
      "Epoch 16/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1400 - val_loss: 0.0396\n",
      "Epoch 17/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0828 - val_loss: 0.0077\n",
      "Epoch 18/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0579 - val_loss: 0.0220\n",
      "Epoch 19/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0732 - val_loss: 0.0528\n",
      "Epoch 20/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.1018 - val_loss: 0.0646\n",
      "Epoch 21/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1119 - val_loss: 0.0487\n",
      "Epoch 22/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0956 - val_loss: 0.0223\n",
      "Epoch 23/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0683 - val_loss: 0.0091\n",
      "Epoch 24/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0512 - val_loss: 0.0180\n",
      "Epoch 25/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0531 - val_loss: 0.0386\n",
      "Epoch 26/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0662 - val_loss: 0.0523\n",
      "Epoch 27/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0755 - val_loss: 0.0481\n",
      "Epoch 28/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0716 - val_loss: 0.0310\n",
      "Epoch 29/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0580 - val_loss: 0.0141\n",
      "Epoch 30/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0451 - val_loss: 0.0075\n",
      "Epoch 31/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0404 - val_loss: 0.0115\n",
      "Epoch 32/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0438 - val_loss: 0.0188\n",
      "Epoch 33/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0490 - val_loss: 0.0218\n",
      "Epoch 34/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0496 - val_loss: 0.0181\n",
      "Epoch 35/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0443 - val_loss: 0.0113\n",
      "Epoch 36/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0365 - val_loss: 0.0068\n",
      "Epoch 37/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0311 - val_loss: 0.0070\n",
      "Epoch 38/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0303 - val_loss: 0.0103\n",
      "Epoch 39/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0325 - val_loss: 0.0129\n",
      "Epoch 40/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0339 - val_loss: 0.0122\n",
      "Epoch 41/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0322 - val_loss: 0.0091\n",
      "Epoch 42/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0277 - val_loss: 0.0067\n",
      "Epoch 43/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0234 - val_loss: 0.0073\n",
      "Epoch 44/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0213 - val_loss: 0.0107\n",
      "Epoch 45/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0217 - val_loss: 0.0141\n",
      "Epoch 46/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0226 - val_loss: 0.0151\n",
      "Epoch 47/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0221 - val_loss: 0.0131\n",
      "Epoch 48/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0199 - val_loss: 0.0099\n",
      "Epoch 49/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0172 - val_loss: 0.0075\n",
      "Epoch 50/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0158 - val_loss: 0.0069\n",
      "Epoch 51/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0159 - val_loss: 0.0074\n",
      "Epoch 52/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0164 - val_loss: 0.0078\n",
      "Epoch 53/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0161 - val_loss: 0.0080\n",
      "Epoch 54/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0147 - val_loss: 0.0088\n",
      "Epoch 55/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0132 - val_loss: 0.0107\n",
      "Epoch 56/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0125 - val_loss: 0.0134\n",
      "Epoch 57/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0127 - val_loss: 0.0152\n",
      "Epoch 58/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0131 - val_loss: 0.0153\n",
      "Epoch 59/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0127 - val_loss: 0.0139\n",
      "Epoch 60/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 61/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 62/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 63/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 64/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0113 - val_loss: 0.0097\n",
      "Epoch 65/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 66/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 67/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 68/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0104 - val_loss: 0.0117\n",
      "Epoch 69/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 70/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 71/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 72/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 73/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 74/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 75/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 76/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 77/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0095 - val_loss: 0.0107\n",
      "Epoch 78/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 79/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0095 - val_loss: 0.0108\n",
      "Epoch 80/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0095 - val_loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 82/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0093 - val_loss: 0.0094\n",
      "Epoch 83/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 84/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 85/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 86/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 87/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 88/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0092 - val_loss: 0.0102\n",
      "Epoch 89/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 90/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 91/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 92/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 93/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 94/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 95/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 96/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0090 - val_loss: 0.0101\n",
      "Epoch 97/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0090 - val_loss: 0.0102\n",
      "Epoch 98/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0090 - val_loss: 0.0101\n",
      "Epoch 99/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 100/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 101/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 102/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 103/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 104/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 105/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 106/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0090 - val_loss: 0.0101\n",
      "Epoch 107/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0090 - val_loss: 0.0101\n",
      "Epoch 108/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 109/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0100\n",
      "Epoch 110/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0100\n",
      "Epoch 111/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0100\n",
      "Epoch 112/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 113/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 114/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 115/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 116/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 117/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 118/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 119/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 120/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0101\n",
      "Epoch 121/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 122/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 123/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 124/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 125/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 126/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 127/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 128/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 129/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 130/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 131/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 132/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 133/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 134/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 135/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 136/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 137/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 138/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0089 - val_loss: 0.0102\n",
      "Epoch 139/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 140/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 141/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 142/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0103\n",
      "Epoch 143/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 144/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 145/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 146/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 147/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 148/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 149/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 150/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 151/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 152/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0088 - val_loss: 0.0103\n",
      "Epoch 153/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 154/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 155/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 156/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 157/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 158/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 159/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 160/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 161/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 162/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 163/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 164/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 165/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 166/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 167/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 168/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 169/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 170/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 171/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 172/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 173/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 174/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 175/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 176/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 177/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 178/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 179/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 180/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 181/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 182/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 183/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 184/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 185/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 186/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 187/1500\n",
      "28/28 [==============================] - 0s 340us/step - loss: 0.0088 - val_loss: 0.0107\n",
      "Epoch 188/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 189/1500\n",
      "28/28 [==============================] - 0s 71us/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 190/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 191/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 192/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 193/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 194/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 195/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 196/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0108\n",
      "Epoch 197/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0087 - val_loss: 0.0108\n",
      "Epoch 198/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0108\n",
      "Epoch 199/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0087 - val_loss: 0.0108\n",
      "Epoch 200/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0087 - val_loss: 0.0108\n",
      "Epoch 201/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0108\n",
      "Epoch 202/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0108\n",
      "Epoch 203/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0108\n",
      "Epoch 204/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0087 - val_loss: 0.0108\n",
      "Epoch 205/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 206/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 207/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 208/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 209/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 210/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 211/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 212/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0110\n",
      "Epoch 213/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0087 - val_loss: 0.0110\n",
      "Epoch 214/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0110\n",
      "Epoch 215/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0110\n",
      "Epoch 216/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0087 - val_loss: 0.0110\n",
      "Epoch 217/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0110\n",
      "Epoch 218/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0110\n",
      "Epoch 219/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 220/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 221/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 222/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 223/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 224/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0111\n",
      "Epoch 225/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0111\n",
      "Epoch 226/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 227/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 228/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 229/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 230/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 231/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0086 - val_loss: 0.0112\n",
      "Epoch 232/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0086 - val_loss: 0.0113\n",
      "Epoch 233/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0113\n",
      "Epoch 234/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0086 - val_loss: 0.0113\n",
      "Epoch 235/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0113\n",
      "Epoch 236/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0113\n",
      "Epoch 237/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0113\n",
      "Epoch 238/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 239/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0086 - val_loss: 0.0114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 241/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 242/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 243/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 244/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0115\n",
      "Epoch 245/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0115\n",
      "Epoch 246/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0115\n",
      "Epoch 247/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0086 - val_loss: 0.0115\n",
      "Epoch 248/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0115\n",
      "Epoch 249/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0086 - val_loss: 0.0116\n",
      "Epoch 250/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0116\n",
      "Epoch 251/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0086 - val_loss: 0.0116\n",
      "Epoch 252/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0086 - val_loss: 0.0116\n",
      "Epoch 253/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0086 - val_loss: 0.0116\n",
      "Epoch 254/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0086 - val_loss: 0.0117\n",
      "Epoch 255/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0085 - val_loss: 0.0117\n",
      "Epoch 256/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0085 - val_loss: 0.0117\n",
      "Epoch 257/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0085 - val_loss: 0.0117\n",
      "Epoch 258/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0085 - val_loss: 0.0117\n",
      "Epoch 259/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0085 - val_loss: 0.0118\n",
      "Epoch 260/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0085 - val_loss: 0.0118\n",
      "Epoch 261/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0085 - val_loss: 0.0118\n",
      "Epoch 262/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0085 - val_loss: 0.0118\n",
      "Epoch 263/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0085 - val_loss: 0.0118\n",
      "Epoch 264/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0085 - val_loss: 0.0119\n",
      "Epoch 265/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0085 - val_loss: 0.0119\n",
      "Epoch 266/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0085 - val_loss: 0.0119\n",
      "Epoch 267/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0085 - val_loss: 0.0119\n",
      "Epoch 268/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0085 - val_loss: 0.0120\n",
      "Epoch 269/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0085 - val_loss: 0.0120\n",
      "Epoch 270/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0085 - val_loss: 0.0120\n",
      "Epoch 271/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0085 - val_loss: 0.0120\n",
      "Epoch 272/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0085 - val_loss: 0.0121\n",
      "Epoch 273/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0085 - val_loss: 0.0121\n",
      "Epoch 274/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0085 - val_loss: 0.0121\n",
      "Epoch 275/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0085 - val_loss: 0.0121\n",
      "Epoch 276/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0085 - val_loss: 0.0121\n",
      "Epoch 277/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.0085 - val_loss: 0.0122\n",
      "Epoch 278/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0085 - val_loss: 0.0122\n",
      "Epoch 279/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0085 - val_loss: 0.0122\n",
      "Epoch 280/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0085 - val_loss: 0.0122\n",
      "Epoch 281/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0084 - val_loss: 0.0123\n",
      "Epoch 282/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0084 - val_loss: 0.0123\n",
      "Epoch 283/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0084 - val_loss: 0.0123\n",
      "Epoch 284/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0084 - val_loss: 0.0123\n",
      "Epoch 285/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0084 - val_loss: 0.0124\n",
      "Epoch 286/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0084 - val_loss: 0.0124\n",
      "Epoch 287/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0084 - val_loss: 0.0124\n",
      "Epoch 288/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0084 - val_loss: 0.0124\n",
      "Epoch 289/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0084 - val_loss: 0.0125\n",
      "Epoch 290/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0084 - val_loss: 0.0125\n",
      "Epoch 291/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0084 - val_loss: 0.0125\n",
      "Epoch 292/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0084 - val_loss: 0.0126\n",
      "Epoch 293/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0084 - val_loss: 0.0126\n",
      "Epoch 294/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0084 - val_loss: 0.0126\n",
      "Epoch 295/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0084 - val_loss: 0.0126\n",
      "Epoch 296/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0084 - val_loss: 0.0127\n",
      "Epoch 297/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0084 - val_loss: 0.0127\n",
      "Epoch 298/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0084 - val_loss: 0.0127\n",
      "Epoch 299/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0084 - val_loss: 0.0127\n",
      "Epoch 300/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0084 - val_loss: 0.0128\n",
      "Epoch 301/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0084 - val_loss: 0.0128\n",
      "Epoch 302/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0084 - val_loss: 0.0128\n",
      "Epoch 303/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0084 - val_loss: 0.0129\n",
      "Epoch 304/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0129\n",
      "Epoch 305/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0129\n",
      "Epoch 306/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0083 - val_loss: 0.0129\n",
      "Epoch 307/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0130\n",
      "Epoch 308/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0083 - val_loss: 0.0130\n",
      "Epoch 309/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0130\n",
      "Epoch 310/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0131\n",
      "Epoch 311/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0083 - val_loss: 0.0131\n",
      "Epoch 312/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0131\n",
      "Epoch 313/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0132\n",
      "Epoch 314/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0132\n",
      "Epoch 315/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0083 - val_loss: 0.0132\n",
      "Epoch 316/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0133\n",
      "Epoch 317/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0133\n",
      "Epoch 318/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0133\n",
      "Epoch 320/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0083 - val_loss: 0.0134\n",
      "Epoch 321/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0134\n",
      "Epoch 322/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0134\n",
      "Epoch 323/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0083 - val_loss: 0.0135\n",
      "Epoch 324/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0135\n",
      "Epoch 325/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0135\n",
      "Epoch 326/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0136\n",
      "Epoch 327/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0136\n",
      "Epoch 328/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0136\n",
      "Epoch 329/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0137\n",
      "Epoch 330/1500\n",
      "28/28 [==============================] - 0s 429us/step - loss: 0.0082 - val_loss: 0.0137\n",
      "Epoch 331/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0137\n",
      "Epoch 332/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0138\n",
      "Epoch 333/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0138\n",
      "Epoch 334/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0082 - val_loss: 0.0138\n",
      "Epoch 335/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0139\n",
      "Epoch 336/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0082 - val_loss: 0.0139\n",
      "Epoch 337/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0082 - val_loss: 0.0139\n",
      "Epoch 338/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0140\n",
      "Epoch 339/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0140\n",
      "Epoch 340/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0082 - val_loss: 0.0140\n",
      "Epoch 341/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0141\n",
      "Epoch 342/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0141\n",
      "Epoch 343/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0081 - val_loss: 0.0141\n",
      "Epoch 344/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0081 - val_loss: 0.0142\n",
      "Epoch 345/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0081 - val_loss: 0.0142\n",
      "Epoch 346/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0081 - val_loss: 0.0142\n",
      "Epoch 347/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0081 - val_loss: 0.0143\n",
      "Epoch 348/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0081 - val_loss: 0.0143\n",
      "Epoch 349/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0081 - val_loss: 0.0143\n",
      "Epoch 350/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0081 - val_loss: 0.0144\n",
      "Epoch 351/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0081 - val_loss: 0.0144\n",
      "Epoch 352/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0081 - val_loss: 0.0145\n",
      "Epoch 353/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0081 - val_loss: 0.0145\n",
      "Epoch 354/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0081 - val_loss: 0.0145\n",
      "Epoch 355/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0081 - val_loss: 0.0146\n",
      "Epoch 356/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0081 - val_loss: 0.0146\n",
      "Epoch 357/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0081 - val_loss: 0.0146\n",
      "Epoch 358/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0081 - val_loss: 0.0147\n",
      "Epoch 359/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0081 - val_loss: 0.0147\n",
      "Epoch 360/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0081 - val_loss: 0.0147\n",
      "Epoch 361/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0080 - val_loss: 0.0148\n",
      "Epoch 362/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0080 - val_loss: 0.0148\n",
      "Epoch 363/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0080 - val_loss: 0.0148\n",
      "Epoch 364/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0080 - val_loss: 0.0149\n",
      "Epoch 365/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0080 - val_loss: 0.0149\n",
      "Epoch 366/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0080 - val_loss: 0.0150\n",
      "Epoch 367/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0080 - val_loss: 0.0150\n",
      "Epoch 368/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0080 - val_loss: 0.0150\n",
      "Epoch 369/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0080 - val_loss: 0.0151\n",
      "Epoch 370/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0080 - val_loss: 0.0151\n",
      "Epoch 371/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0080 - val_loss: 0.0151\n",
      "Epoch 372/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0080 - val_loss: 0.0152\n",
      "Epoch 373/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0080 - val_loss: 0.0152\n",
      "Epoch 374/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0080 - val_loss: 0.0152\n",
      "Epoch 375/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0080 - val_loss: 0.0153\n",
      "Epoch 376/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0080 - val_loss: 0.0153\n",
      "Epoch 377/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0079 - val_loss: 0.0153\n",
      "Epoch 378/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0079 - val_loss: 0.0154\n",
      "Epoch 379/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0079 - val_loss: 0.0154\n",
      "Epoch 380/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0079 - val_loss: 0.0155\n",
      "Epoch 381/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0079 - val_loss: 0.0155\n",
      "Epoch 382/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0079 - val_loss: 0.0155\n",
      "Epoch 383/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0079 - val_loss: 0.0156\n",
      "Epoch 384/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0079 - val_loss: 0.0156\n",
      "Epoch 385/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0079 - val_loss: 0.0156\n",
      "Epoch 386/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0079 - val_loss: 0.0157\n",
      "Epoch 387/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0079 - val_loss: 0.0157\n",
      "Epoch 388/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0079 - val_loss: 0.0157\n",
      "Epoch 389/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0079 - val_loss: 0.0158\n",
      "Epoch 390/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0079 - val_loss: 0.0158\n",
      "Epoch 391/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0079 - val_loss: 0.0158\n",
      "Epoch 392/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0079 - val_loss: 0.0159\n",
      "Epoch 393/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0078 - val_loss: 0.0159\n",
      "Epoch 394/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0078 - val_loss: 0.0160\n",
      "Epoch 395/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0078 - val_loss: 0.0160\n",
      "Epoch 396/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0078 - val_loss: 0.0160\n",
      "Epoch 397/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0078 - val_loss: 0.0161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0078 - val_loss: 0.0161\n",
      "Epoch 399/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0078 - val_loss: 0.0161\n",
      "Epoch 400/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0078 - val_loss: 0.0162\n",
      "Epoch 401/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0078 - val_loss: 0.0162\n",
      "Epoch 402/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0078 - val_loss: 0.0162\n",
      "Epoch 403/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0078 - val_loss: 0.0163\n",
      "Epoch 404/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0078 - val_loss: 0.0163\n",
      "Epoch 405/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0078 - val_loss: 0.0163\n",
      "Epoch 406/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0078 - val_loss: 0.0164\n",
      "Epoch 407/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0078 - val_loss: 0.0164\n",
      "Epoch 408/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0077 - val_loss: 0.0164\n",
      "Epoch 409/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0077 - val_loss: 0.0165\n",
      "Epoch 410/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0077 - val_loss: 0.0165\n",
      "Epoch 411/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0077 - val_loss: 0.0165\n",
      "Epoch 412/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0077 - val_loss: 0.0166\n",
      "Epoch 413/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0077 - val_loss: 0.0166\n",
      "Epoch 414/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0077 - val_loss: 0.0166\n",
      "Epoch 415/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0077 - val_loss: 0.0167\n",
      "Epoch 416/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0077 - val_loss: 0.0167\n",
      "Epoch 417/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0077 - val_loss: 0.0167\n",
      "Epoch 418/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0077 - val_loss: 0.0168\n",
      "Epoch 419/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0077 - val_loss: 0.0168\n",
      "Epoch 420/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0077 - val_loss: 0.0168\n",
      "Epoch 421/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0077 - val_loss: 0.0169\n",
      "Epoch 422/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0077 - val_loss: 0.0169\n",
      "Epoch 423/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0076 - val_loss: 0.0169\n",
      "Epoch 424/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0076 - val_loss: 0.0170\n",
      "Epoch 425/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0076 - val_loss: 0.0170\n",
      "Epoch 426/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0076 - val_loss: 0.0170\n",
      "Epoch 427/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0076 - val_loss: 0.0171\n",
      "Epoch 428/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0076 - val_loss: 0.0171\n",
      "Epoch 429/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0076 - val_loss: 0.0171\n",
      "Epoch 430/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0076 - val_loss: 0.0172\n",
      "Epoch 431/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0076 - val_loss: 0.0172\n",
      "Epoch 432/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0076 - val_loss: 0.0172\n",
      "Epoch 433/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0076 - val_loss: 0.0173\n",
      "Epoch 434/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0076 - val_loss: 0.0173\n",
      "Epoch 435/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0076 - val_loss: 0.0173\n",
      "Epoch 436/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0076 - val_loss: 0.0173\n",
      "Epoch 437/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0076 - val_loss: 0.0174\n",
      "Epoch 438/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0075 - val_loss: 0.0174\n",
      "Epoch 439/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0075 - val_loss: 0.0174\n",
      "Epoch 440/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0075 - val_loss: 0.0175\n",
      "Epoch 441/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0075 - val_loss: 0.0175\n",
      "Epoch 442/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0075 - val_loss: 0.0175\n",
      "Epoch 443/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0075 - val_loss: 0.0176\n",
      "Epoch 444/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0075 - val_loss: 0.0176\n",
      "Epoch 445/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0075 - val_loss: 0.0176\n",
      "Epoch 446/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0075 - val_loss: 0.0176\n",
      "Epoch 447/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0075 - val_loss: 0.0177\n",
      "Epoch 448/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0075 - val_loss: 0.0177\n",
      "Epoch 449/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0075 - val_loss: 0.0177\n",
      "Epoch 450/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0075 - val_loss: 0.0178\n",
      "Epoch 451/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0075 - val_loss: 0.0178\n",
      "Epoch 452/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0075 - val_loss: 0.0178\n",
      "Epoch 453/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0074 - val_loss: 0.0178\n",
      "Epoch 454/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0074 - val_loss: 0.0179\n",
      "Epoch 455/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0074 - val_loss: 0.0179\n",
      "Epoch 456/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0074 - val_loss: 0.0179\n",
      "Epoch 457/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0074 - val_loss: 0.0179\n",
      "Epoch 458/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0074 - val_loss: 0.0180\n",
      "Epoch 459/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0074 - val_loss: 0.0180\n",
      "Epoch 460/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0074 - val_loss: 0.0180\n",
      "Epoch 461/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0074 - val_loss: 0.0181\n",
      "Epoch 462/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0074 - val_loss: 0.0181\n",
      "Epoch 463/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0074 - val_loss: 0.0181\n",
      "Epoch 464/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0074 - val_loss: 0.0181\n",
      "Epoch 465/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0074 - val_loss: 0.0182\n",
      "Epoch 466/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0074 - val_loss: 0.0182\n",
      "Epoch 467/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0074 - val_loss: 0.0182\n",
      "Epoch 468/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0074 - val_loss: 0.0182\n",
      "Epoch 469/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0183\n",
      "Epoch 470/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0183\n",
      "Epoch 471/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0073 - val_loss: 0.0183\n",
      "Epoch 472/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0073 - val_loss: 0.0183\n",
      "Epoch 473/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0184\n",
      "Epoch 474/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0184\n",
      "Epoch 475/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0184\n",
      "Epoch 476/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0185\n",
      "Epoch 478/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0073 - val_loss: 0.0185\n",
      "Epoch 479/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0185\n",
      "Epoch 480/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0185\n",
      "Epoch 481/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0185\n",
      "Epoch 482/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0073 - val_loss: 0.0186\n",
      "Epoch 483/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0186\n",
      "Epoch 484/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0186\n",
      "Epoch 485/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0072 - val_loss: 0.0186\n",
      "Epoch 486/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0072 - val_loss: 0.0187\n",
      "Epoch 487/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0072 - val_loss: 0.0187\n",
      "Epoch 488/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0072 - val_loss: 0.0187\n",
      "Epoch 489/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0072 - val_loss: 0.0187\n",
      "Epoch 490/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0072 - val_loss: 0.0187\n",
      "Epoch 491/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0072 - val_loss: 0.0188\n",
      "Epoch 492/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0072 - val_loss: 0.0188\n",
      "Epoch 493/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0072 - val_loss: 0.0188\n",
      "Epoch 494/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0072 - val_loss: 0.0188\n",
      "Epoch 495/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0072 - val_loss: 0.0188\n",
      "Epoch 496/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0072 - val_loss: 0.0189\n",
      "Epoch 497/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0072 - val_loss: 0.0189\n",
      "Epoch 498/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0072 - val_loss: 0.0189\n",
      "Epoch 499/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0072 - val_loss: 0.0189\n",
      "Epoch 500/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0072 - val_loss: 0.0189\n",
      "Epoch 501/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0072 - val_loss: 0.0190\n",
      "Epoch 502/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0072 - val_loss: 0.0190\n",
      "Epoch 503/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0071 - val_loss: 0.0190\n",
      "Epoch 504/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0071 - val_loss: 0.0190\n",
      "Epoch 505/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0071 - val_loss: 0.0190\n",
      "Epoch 506/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0071 - val_loss: 0.0191\n",
      "Epoch 507/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0071 - val_loss: 0.0191\n",
      "Epoch 508/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0071 - val_loss: 0.0191\n",
      "Epoch 509/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0071 - val_loss: 0.0191\n",
      "Epoch 510/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0071 - val_loss: 0.0191\n",
      "Epoch 511/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0071 - val_loss: 0.0191\n",
      "Epoch 512/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0071 - val_loss: 0.0192\n",
      "Epoch 513/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0071 - val_loss: 0.0192\n",
      "Epoch 514/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0071 - val_loss: 0.0192\n",
      "Epoch 515/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0071 - val_loss: 0.0192\n",
      "Epoch 516/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0071 - val_loss: 0.0192\n",
      "Epoch 517/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0071 - val_loss: 0.0192\n",
      "Epoch 518/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0071 - val_loss: 0.0193\n",
      "Epoch 519/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0071 - val_loss: 0.0193\n",
      "Epoch 520/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0071 - val_loss: 0.0193\n",
      "Epoch 521/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0071 - val_loss: 0.0193\n",
      "Epoch 522/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0070 - val_loss: 0.0193\n",
      "Epoch 523/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0070 - val_loss: 0.0193\n",
      "Epoch 524/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0070 - val_loss: 0.0194\n",
      "Epoch 525/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0070 - val_loss: 0.0194\n",
      "Epoch 526/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0070 - val_loss: 0.0194\n",
      "Epoch 527/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0070 - val_loss: 0.0194\n",
      "Epoch 528/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0070 - val_loss: 0.0194\n",
      "Epoch 529/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0070 - val_loss: 0.0194\n",
      "Epoch 530/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0070 - val_loss: 0.0194\n",
      "Epoch 531/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0070 - val_loss: 0.0195\n",
      "Epoch 532/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0070 - val_loss: 0.0195\n",
      "Epoch 533/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0070 - val_loss: 0.0195\n",
      "Epoch 534/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0070 - val_loss: 0.0195\n",
      "Epoch 535/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0070 - val_loss: 0.0195\n",
      "Epoch 536/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0070 - val_loss: 0.0195\n",
      "Epoch 537/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0070 - val_loss: 0.0195\n",
      "Epoch 538/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0070 - val_loss: 0.0195\n",
      "Epoch 539/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0070 - val_loss: 0.0196\n",
      "Epoch 540/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0070 - val_loss: 0.0196\n",
      "Epoch 541/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0070 - val_loss: 0.0196\n",
      "Epoch 542/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0070 - val_loss: 0.0196\n",
      "Epoch 543/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0070 - val_loss: 0.0196\n",
      "Epoch 544/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0196\n",
      "Epoch 545/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0196\n",
      "Epoch 546/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0069 - val_loss: 0.0197\n",
      "Epoch 547/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0197\n",
      "Epoch 548/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.0069 - val_loss: 0.0197\n",
      "Epoch 549/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0069 - val_loss: 0.0197\n",
      "Epoch 550/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0197\n",
      "Epoch 551/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0197\n",
      "Epoch 552/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0069 - val_loss: 0.0197\n",
      "Epoch 553/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0197\n",
      "Epoch 554/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0197\n",
      "Epoch 555/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0198\n",
      "Epoch 557/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0198\n",
      "Epoch 558/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0198\n",
      "Epoch 559/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0069 - val_loss: 0.0198\n",
      "Epoch 560/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0069 - val_loss: 0.0198\n",
      "Epoch 561/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0198\n",
      "Epoch 562/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0069 - val_loss: 0.0198\n",
      "Epoch 563/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0198\n",
      "Epoch 564/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0199\n",
      "Epoch 565/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0199\n",
      "Epoch 566/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0069 - val_loss: 0.0199\n",
      "Epoch 567/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0199\n",
      "Epoch 568/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0068 - val_loss: 0.0199\n",
      "Epoch 569/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0068 - val_loss: 0.0199\n",
      "Epoch 570/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0068 - val_loss: 0.0199\n",
      "Epoch 571/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0068 - val_loss: 0.0199\n",
      "Epoch 572/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0068 - val_loss: 0.0199\n",
      "Epoch 573/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0068 - val_loss: 0.0200\n",
      "Epoch 574/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0068 - val_loss: 0.0200\n",
      "Epoch 575/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0068 - val_loss: 0.0200\n",
      "Epoch 576/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0068 - val_loss: 0.0200\n",
      "Epoch 577/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0068 - val_loss: 0.0200\n",
      "Epoch 578/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0068 - val_loss: 0.0200\n",
      "Epoch 579/1500\n",
      "28/28 [==============================] - 0s 429us/step - loss: 0.0068 - val_loss: 0.0200\n",
      "Epoch 580/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0068 - val_loss: 0.0200\n",
      "Epoch 581/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0068 - val_loss: 0.0200\n",
      "Epoch 582/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0068 - val_loss: 0.0200\n",
      "Epoch 583/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0068 - val_loss: 0.0201\n",
      "Epoch 584/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0068 - val_loss: 0.0201\n",
      "Epoch 585/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0068 - val_loss: 0.0201\n",
      "Epoch 586/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0068 - val_loss: 0.0201\n",
      "Epoch 587/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0068 - val_loss: 0.0201\n",
      "Epoch 588/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0068 - val_loss: 0.0201\n",
      "Epoch 589/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0068 - val_loss: 0.0201\n",
      "Epoch 590/1500\n",
      "28/28 [==============================] - 0s 429us/step - loss: 0.0068 - val_loss: 0.0201\n",
      "Epoch 591/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0068 - val_loss: 0.0201\n",
      "Epoch 592/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0068 - val_loss: 0.0201\n",
      "Epoch 593/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0068 - val_loss: 0.0202\n",
      "Epoch 594/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0068 - val_loss: 0.0202\n",
      "Epoch 595/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0067 - val_loss: 0.0202\n",
      "Epoch 596/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0067 - val_loss: 0.0202\n",
      "Epoch 597/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0202\n",
      "Epoch 598/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0202\n",
      "Epoch 599/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0067 - val_loss: 0.0202\n",
      "Epoch 600/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0202\n",
      "Epoch 601/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0202\n",
      "Epoch 602/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0067 - val_loss: 0.0202\n",
      "Epoch 603/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0067 - val_loss: 0.0203\n",
      "Epoch 604/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0203\n",
      "Epoch 605/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0067 - val_loss: 0.0203\n",
      "Epoch 606/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0067 - val_loss: 0.0203\n",
      "Epoch 607/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0203\n",
      "Epoch 608/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0203\n",
      "Epoch 609/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0203\n",
      "Epoch 610/1500\n",
      "28/28 [==============================] - 0s 428us/step - loss: 0.0067 - val_loss: 0.0203\n",
      "Epoch 611/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0203\n",
      "Epoch 612/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0067 - val_loss: 0.0204\n",
      "Epoch 613/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0204\n",
      "Epoch 614/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0204\n",
      "Epoch 615/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0067 - val_loss: 0.0204\n",
      "Epoch 616/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0204\n",
      "Epoch 617/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0067 - val_loss: 0.0204\n",
      "Epoch 618/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0204\n",
      "Epoch 619/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0204\n",
      "Epoch 620/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0067 - val_loss: 0.0204\n",
      "Epoch 621/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0204\n",
      "Epoch 622/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0067 - val_loss: 0.0205\n",
      "Epoch 623/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0204\n",
      "Epoch 624/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0207\n",
      "Epoch 625/1500\n",
      "28/28 [==============================] - 0s 429us/step - loss: 0.0067 - val_loss: 0.0206\n",
      "Epoch 626/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0219\n",
      "Epoch 627/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0076 - val_loss: 0.0230\n",
      "Epoch 628/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0095 - val_loss: 0.0305\n",
      "Epoch 629/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0147 - val_loss: 0.0346\n",
      "Epoch 630/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0211 - val_loss: 0.0393\n",
      "Epoch 631/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0227 - val_loss: 0.0211\n",
      "Epoch 632/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0096 - val_loss: 0.0204\n",
      "Epoch 633/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0094 - val_loss: 0.0281\n",
      "Epoch 634/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0143 - val_loss: 0.0175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 635/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0069 - val_loss: 0.0216\n",
      "Epoch 636/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0119 - val_loss: 0.0188\n",
      "Epoch 637/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0079 - val_loss: 0.0205\n",
      "Epoch 638/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0096 - val_loss: 0.0170\n",
      "Epoch 639/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0080 - val_loss: 0.0177\n",
      "Epoch 640/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0089 - val_loss: 0.0171\n",
      "Epoch 641/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0076 - val_loss: 0.0184\n",
      "Epoch 642/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0087 - val_loss: 0.0155\n",
      "Epoch 643/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0072 - val_loss: 0.0165\n",
      "Epoch 644/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0086 - val_loss: 0.0154\n",
      "Epoch 645/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0176\n",
      "Epoch 646/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0154\n",
      "Epoch 647/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0070 - val_loss: 0.0152\n",
      "Epoch 648/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0077 - val_loss: 0.0149\n",
      "Epoch 649/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0160\n",
      "Epoch 650/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0072 - val_loss: 0.0167\n",
      "Epoch 651/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0075 - val_loss: 0.0151\n",
      "Epoch 652/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0152\n",
      "Epoch 653/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0075 - val_loss: 0.0152\n",
      "Epoch 654/1500\n",
      "28/28 [==============================] - 0s 429us/step - loss: 0.0069 - val_loss: 0.0165\n",
      "Epoch 655/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0072 - val_loss: 0.0162\n",
      "Epoch 656/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0070 - val_loss: 0.0154\n",
      "Epoch 657/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0155\n",
      "Epoch 658/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0071 - val_loss: 0.0158\n",
      "Epoch 659/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0068 - val_loss: 0.0167\n",
      "Epoch 660/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0071 - val_loss: 0.0163\n",
      "Epoch 661/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0068 - val_loss: 0.0159\n",
      "Epoch 662/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0069 - val_loss: 0.0161\n",
      "Epoch 663/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0069 - val_loss: 0.0167\n",
      "Epoch 664/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0068 - val_loss: 0.0174\n",
      "Epoch 665/1500\n",
      "28/28 [==============================] - 0s 429us/step - loss: 0.0069 - val_loss: 0.0171\n",
      "Epoch 666/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0171\n",
      "Epoch 667/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0068 - val_loss: 0.0174\n",
      "Epoch 668/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0180\n",
      "Epoch 669/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0067 - val_loss: 0.0183\n",
      "Epoch 670/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0067 - val_loss: 0.0181\n",
      "Epoch 671/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0066 - val_loss: 0.0181\n",
      "Epoch 672/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0067 - val_loss: 0.0184\n",
      "Epoch 673/1500\n",
      "28/28 [==============================] - 0s 429us/step - loss: 0.0066 - val_loss: 0.0190\n",
      "Epoch 674/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0067 - val_loss: 0.0190\n",
      "Epoch 675/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0066 - val_loss: 0.0190\n",
      "Epoch 676/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0066 - val_loss: 0.0192\n",
      "Epoch 677/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0066 - val_loss: 0.0196\n",
      "Epoch 678/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0066 - val_loss: 0.0200\n",
      "Epoch 679/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0066 - val_loss: 0.0200\n",
      "Epoch 680/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0066 - val_loss: 0.0200\n",
      "Epoch 681/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0066 - val_loss: 0.0203\n",
      "Epoch 682/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0065 - val_loss: 0.0206\n",
      "Epoch 683/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0065 - val_loss: 0.0208\n",
      "Epoch 684/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0065 - val_loss: 0.0207\n",
      "Epoch 685/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0065 - val_loss: 0.0208\n",
      "Epoch 686/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0065 - val_loss: 0.0210\n",
      "Epoch 687/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0065 - val_loss: 0.0213\n",
      "Epoch 688/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0065 - val_loss: 0.0213\n",
      "Epoch 689/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0065 - val_loss: 0.0213\n",
      "Epoch 690/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0065 - val_loss: 0.0215\n",
      "Epoch 691/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0065 - val_loss: 0.0217\n",
      "Epoch 692/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0065 - val_loss: 0.0218\n",
      "Epoch 693/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0065 - val_loss: 0.0217\n",
      "Epoch 694/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0065 - val_loss: 0.0217\n",
      "Epoch 695/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0065 - val_loss: 0.0219\n",
      "Epoch 696/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0065 - val_loss: 0.0220\n",
      "Epoch 697/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0065 - val_loss: 0.0220\n",
      "Epoch 698/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0065 - val_loss: 0.0220\n",
      "Epoch 699/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0065 - val_loss: 0.0221\n",
      "Epoch 700/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0065 - val_loss: 0.0222\n",
      "Epoch 701/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 702/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 703/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 704/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 705/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0064 - val_loss: 0.0223\n",
      "Epoch 706/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 707/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 708/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 709/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0064 - val_loss: 0.0223\n",
      "Epoch 710/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0064 - val_loss: 0.0223\n",
      "Epoch 711/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 712/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 713/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0064 - val_loss: 0.0222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 714/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 715/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 716/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 717/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 718/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 719/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0064 - val_loss: 0.0222\n",
      "Epoch 720/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0064 - val_loss: 0.0221\n",
      "Epoch 721/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0064 - val_loss: 0.0221\n",
      "Epoch 722/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 723/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 724/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 725/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 726/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 727/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 728/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 729/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 730/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 731/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 732/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 733/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 734/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0063 - val_loss: 0.0222\n",
      "Epoch 735/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0063 - val_loss: 0.0223\n",
      "Epoch 736/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0063 - val_loss: 0.0223\n",
      "Epoch 737/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0063 - val_loss: 0.0223\n",
      "Epoch 738/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0063 - val_loss: 0.0223\n",
      "Epoch 739/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0063 - val_loss: 0.0223\n",
      "Epoch 740/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0063 - val_loss: 0.0224\n",
      "Epoch 741/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0063 - val_loss: 0.0224\n",
      "Epoch 742/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0063 - val_loss: 0.0224\n",
      "Epoch 743/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0063 - val_loss: 0.0224\n",
      "Epoch 744/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0063 - val_loss: 0.0224\n",
      "Epoch 745/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0062 - val_loss: 0.0224\n",
      "Epoch 746/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0224\n",
      "Epoch 747/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0062 - val_loss: 0.0225\n",
      "Epoch 748/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0062 - val_loss: 0.0225\n",
      "Epoch 749/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0225\n",
      "Epoch 750/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0225\n",
      "Epoch 751/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0062 - val_loss: 0.0225\n",
      "Epoch 752/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0226\n",
      "Epoch 753/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0062 - val_loss: 0.0226\n",
      "Epoch 754/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0062 - val_loss: 0.0226\n",
      "Epoch 755/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0226\n",
      "Epoch 756/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0062 - val_loss: 0.0226\n",
      "Epoch 757/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0226\n",
      "Epoch 758/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0062 - val_loss: 0.0227\n",
      "Epoch 759/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0227\n",
      "Epoch 760/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0227\n",
      "Epoch 761/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0227\n",
      "Epoch 762/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0062 - val_loss: 0.0227\n",
      "Epoch 763/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0227\n",
      "Epoch 764/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0227\n",
      "Epoch 765/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0227\n",
      "Epoch 766/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0062 - val_loss: 0.0228\n",
      "Epoch 767/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0228\n",
      "Epoch 768/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0228\n",
      "Epoch 769/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0228\n",
      "Epoch 770/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0228\n",
      "Epoch 771/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0228\n",
      "Epoch 772/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0228\n",
      "Epoch 773/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0228\n",
      "Epoch 774/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0228\n",
      "Epoch 775/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0228\n",
      "Epoch 776/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0061 - val_loss: 0.0229\n",
      "Epoch 777/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0229\n",
      "Epoch 778/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0229\n",
      "Epoch 779/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0229\n",
      "Epoch 780/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0061 - val_loss: 0.0229\n",
      "Epoch 781/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0061 - val_loss: 0.0229\n",
      "Epoch 782/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0061 - val_loss: 0.0229\n",
      "Epoch 783/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0229\n",
      "Epoch 784/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0229\n",
      "Epoch 785/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0061 - val_loss: 0.0229\n",
      "Epoch 786/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0229\n",
      "Epoch 787/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0229\n",
      "Epoch 788/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0229\n",
      "Epoch 789/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0229\n",
      "Epoch 790/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0230\n",
      "Epoch 791/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0230\n",
      "Epoch 792/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0061 - val_loss: 0.0230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 793/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0230\n",
      "Epoch 794/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0230\n",
      "Epoch 795/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0230\n",
      "Epoch 796/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0061 - val_loss: 0.0230\n",
      "Epoch 797/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0061 - val_loss: 0.0230\n",
      "Epoch 798/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0060 - val_loss: 0.0230\n",
      "Epoch 799/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0230\n",
      "Epoch 800/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0230\n",
      "Epoch 801/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0230\n",
      "Epoch 802/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0230\n",
      "Epoch 803/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0060 - val_loss: 0.0230\n",
      "Epoch 804/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0060 - val_loss: 0.0230\n",
      "Epoch 805/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0230\n",
      "Epoch 806/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0230\n",
      "Epoch 807/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 808/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 809/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 810/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 811/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 812/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 813/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 814/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 815/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 816/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 817/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 818/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 819/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 820/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 821/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 822/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 823/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 824/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 825/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 826/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 827/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 828/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0060 - val_loss: 0.0231\n",
      "Epoch 829/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 830/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 831/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 832/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 833/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 834/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 835/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 836/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 837/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 838/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 839/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 840/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 841/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 842/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 843/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 844/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 845/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 846/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 847/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 848/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 849/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 850/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 851/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 852/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 853/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 854/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 855/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 856/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 857/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 858/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 859/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 860/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 861/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0059 - val_loss: 0.0231\n",
      "Epoch 862/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 863/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 864/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 865/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 866/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 867/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 868/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 869/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 870/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 871/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 872/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 873/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 874/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 875/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 876/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 877/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 878/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0230\n",
      "Epoch 879/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0229\n",
      "Epoch 880/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0058 - val_loss: 0.0229\n",
      "Epoch 881/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0229\n",
      "Epoch 882/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0229\n",
      "Epoch 883/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0058 - val_loss: 0.0229\n",
      "Epoch 884/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0058 - val_loss: 0.0229\n",
      "Epoch 885/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0058 - val_loss: 0.0229\n",
      "Epoch 886/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0058 - val_loss: 0.0229\n",
      "Epoch 887/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0229\n",
      "Epoch 888/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0058 - val_loss: 0.0229\n",
      "Epoch 889/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0058 - val_loss: 0.0229\n",
      "Epoch 890/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0229\n",
      "Epoch 891/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0058 - val_loss: 0.0228\n",
      "Epoch 892/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0228\n",
      "Epoch 893/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0228\n",
      "Epoch 894/1500\n",
      "28/28 [==============================] - 0s 429us/step - loss: 0.0058 - val_loss: 0.0228\n",
      "Epoch 895/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0058 - val_loss: 0.0228\n",
      "Epoch 896/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0058 - val_loss: 0.0228\n",
      "Epoch 897/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0058 - val_loss: 0.0228\n",
      "Epoch 898/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0228\n",
      "Epoch 899/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0228\n",
      "Epoch 900/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0228\n",
      "Epoch 901/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0057 - val_loss: 0.0227\n",
      "Epoch 902/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0227\n",
      "Epoch 903/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0227\n",
      "Epoch 904/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0057 - val_loss: 0.0227\n",
      "Epoch 905/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0057 - val_loss: 0.0227\n",
      "Epoch 906/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0227\n",
      "Epoch 907/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0057 - val_loss: 0.0227\n",
      "Epoch 908/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0057 - val_loss: 0.0227\n",
      "Epoch 909/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0227\n",
      "Epoch 910/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0057 - val_loss: 0.0226\n",
      "Epoch 911/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0057 - val_loss: 0.0226\n",
      "Epoch 912/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0226\n",
      "Epoch 913/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0226\n",
      "Epoch 914/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0226\n",
      "Epoch 915/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0057 - val_loss: 0.0226\n",
      "Epoch 916/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0226\n",
      "Epoch 917/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0226\n",
      "Epoch 918/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0225\n",
      "Epoch 919/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0057 - val_loss: 0.0225\n",
      "Epoch 920/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0225\n",
      "Epoch 921/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0225\n",
      "Epoch 922/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0225\n",
      "Epoch 923/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0225\n",
      "Epoch 924/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0225\n",
      "Epoch 925/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0224\n",
      "Epoch 926/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0057 - val_loss: 0.0224\n",
      "Epoch 927/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0057 - val_loss: 0.0224\n",
      "Epoch 928/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0224\n",
      "Epoch 929/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0057 - val_loss: 0.0224\n",
      "Epoch 930/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0224\n",
      "Epoch 931/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0224\n",
      "Epoch 932/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0223\n",
      "Epoch 933/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0223\n",
      "Epoch 934/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0223\n",
      "Epoch 935/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0223\n",
      "Epoch 936/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0223\n",
      "Epoch 937/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0056 - val_loss: 0.0223\n",
      "Epoch 938/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0223\n",
      "Epoch 939/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0222\n",
      "Epoch 940/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0222\n",
      "Epoch 941/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0222\n",
      "Epoch 942/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0056 - val_loss: 0.0222\n",
      "Epoch 943/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0222\n",
      "Epoch 944/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0222\n",
      "Epoch 945/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0221\n",
      "Epoch 946/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0056 - val_loss: 0.0221\n",
      "Epoch 947/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0221\n",
      "Epoch 948/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0056 - val_loss: 0.0221\n",
      "Epoch 949/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0221\n",
      "Epoch 950/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 951/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0220\n",
      "Epoch 952/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0220\n",
      "Epoch 953/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0220\n",
      "Epoch 954/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0220\n",
      "Epoch 955/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0220\n",
      "Epoch 956/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0219\n",
      "Epoch 957/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0219\n",
      "Epoch 958/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0056 - val_loss: 0.0219\n",
      "Epoch 959/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0219\n",
      "Epoch 960/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0219\n",
      "Epoch 961/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0056 - val_loss: 0.0218\n",
      "Epoch 962/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0056 - val_loss: 0.0218\n",
      "Epoch 963/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0218\n",
      "Epoch 964/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0056 - val_loss: 0.0218\n",
      "Epoch 965/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0056 - val_loss: 0.0218\n",
      "Epoch 966/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0217\n",
      "Epoch 967/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0055 - val_loss: 0.0217\n",
      "Epoch 968/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0217\n",
      "Epoch 969/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0217\n",
      "Epoch 970/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0055 - val_loss: 0.0217\n",
      "Epoch 971/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0055 - val_loss: 0.0216\n",
      "Epoch 972/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0055 - val_loss: 0.0216\n",
      "Epoch 973/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0055 - val_loss: 0.0216\n",
      "Epoch 974/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0216\n",
      "Epoch 975/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0216\n",
      "Epoch 976/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0055 - val_loss: 0.0215\n",
      "Epoch 977/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0215\n",
      "Epoch 978/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0215\n",
      "Epoch 979/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0055 - val_loss: 0.0215\n",
      "Epoch 980/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0055 - val_loss: 0.0214\n",
      "Epoch 981/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0214\n",
      "Epoch 982/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0055 - val_loss: 0.0214\n",
      "Epoch 983/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0214\n",
      "Epoch 984/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0055 - val_loss: 0.0213\n",
      "Epoch 985/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0055 - val_loss: 0.0213\n",
      "Epoch 986/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0213\n",
      "Epoch 987/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0213\n",
      "Epoch 988/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0213\n",
      "Epoch 989/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0055 - val_loss: 0.0212\n",
      "Epoch 990/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0212\n",
      "Epoch 991/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0212\n",
      "Epoch 992/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0212\n",
      "Epoch 993/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0055 - val_loss: 0.0211\n",
      "Epoch 994/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0055 - val_loss: 0.0211\n",
      "Epoch 995/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0054 - val_loss: 0.0211\n",
      "Epoch 996/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0210\n",
      "Epoch 997/1500\n",
      "28/28 [==============================] - 0s 429us/step - loss: 0.0054 - val_loss: 0.0210\n",
      "Epoch 998/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0054 - val_loss: 0.0210\n",
      "Epoch 999/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0210\n",
      "Epoch 1000/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0054 - val_loss: 0.0209\n",
      "Epoch 1001/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0054 - val_loss: 0.0209\n",
      "Epoch 1002/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0209\n",
      "Epoch 1003/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0209\n",
      "Epoch 1004/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0208\n",
      "Epoch 1005/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0054 - val_loss: 0.0208\n",
      "Epoch 1006/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0208\n",
      "Epoch 1007/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0054 - val_loss: 0.0207\n",
      "Epoch 1008/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0207\n",
      "Epoch 1009/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0207\n",
      "Epoch 1010/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0054 - val_loss: 0.0206\n",
      "Epoch 1011/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0054 - val_loss: 0.0206\n",
      "Epoch 1012/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0206\n",
      "Epoch 1013/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0054 - val_loss: 0.0206\n",
      "Epoch 1014/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0205\n",
      "Epoch 1015/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0054 - val_loss: 0.0205\n",
      "Epoch 1016/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0054 - val_loss: 0.0205\n",
      "Epoch 1017/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0204\n",
      "Epoch 1018/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0204\n",
      "Epoch 1019/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0204\n",
      "Epoch 1020/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0203\n",
      "Epoch 1021/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0053 - val_loss: 0.0203\n",
      "Epoch 1022/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0203\n",
      "Epoch 1023/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0202\n",
      "Epoch 1024/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0202\n",
      "Epoch 1025/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0202\n",
      "Epoch 1026/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0201\n",
      "Epoch 1027/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0201\n",
      "Epoch 1028/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0201\n",
      "Epoch 1029/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1030/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0200\n",
      "Epoch 1031/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0053 - val_loss: 0.0200\n",
      "Epoch 1032/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0053 - val_loss: 0.0199\n",
      "Epoch 1033/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0053 - val_loss: 0.0199\n",
      "Epoch 1034/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0053 - val_loss: 0.0198\n",
      "Epoch 1035/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0198\n",
      "Epoch 1036/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0053 - val_loss: 0.0198\n",
      "Epoch 1037/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0197\n",
      "Epoch 1038/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0053 - val_loss: 0.0197\n",
      "Epoch 1039/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0197\n",
      "Epoch 1040/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0053 - val_loss: 0.0196\n",
      "Epoch 1041/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0053 - val_loss: 0.0196\n",
      "Epoch 1042/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0195\n",
      "Epoch 1043/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0195\n",
      "Epoch 1044/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0053 - val_loss: 0.0195\n",
      "Epoch 1045/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0194\n",
      "Epoch 1046/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0052 - val_loss: 0.0194\n",
      "Epoch 1047/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0052 - val_loss: 0.0193\n",
      "Epoch 1048/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0193\n",
      "Epoch 1049/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0052 - val_loss: 0.0193\n",
      "Epoch 1050/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0052 - val_loss: 0.0192\n",
      "Epoch 1051/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0192\n",
      "Epoch 1052/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0052 - val_loss: 0.0191\n",
      "Epoch 1053/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0052 - val_loss: 0.0191\n",
      "Epoch 1054/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0052 - val_loss: 0.0191\n",
      "Epoch 1055/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0190\n",
      "Epoch 1056/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0052 - val_loss: 0.0190\n",
      "Epoch 1057/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0189\n",
      "Epoch 1058/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0189\n",
      "Epoch 1059/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0052 - val_loss: 0.0189\n",
      "Epoch 1060/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0052 - val_loss: 0.0188\n",
      "Epoch 1061/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0188\n",
      "Epoch 1062/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0187\n",
      "Epoch 1063/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0187\n",
      "Epoch 1064/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0052 - val_loss: 0.0187\n",
      "Epoch 1065/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0186\n",
      "Epoch 1066/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0186\n",
      "Epoch 1067/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0185\n",
      "Epoch 1068/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0052 - val_loss: 0.0185\n",
      "Epoch 1069/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0052 - val_loss: 0.0184\n",
      "Epoch 1070/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0184\n",
      "Epoch 1071/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0184\n",
      "Epoch 1072/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0051 - val_loss: 0.0183\n",
      "Epoch 1073/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0183\n",
      "Epoch 1074/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0182\n",
      "Epoch 1075/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0051 - val_loss: 0.0182\n",
      "Epoch 1076/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0051 - val_loss: 0.0182\n",
      "Epoch 1077/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0181\n",
      "Epoch 1078/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0181\n",
      "Epoch 1079/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0180\n",
      "Epoch 1080/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0180\n",
      "Epoch 1081/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0179\n",
      "Epoch 1082/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0179\n",
      "Epoch 1083/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0179\n",
      "Epoch 1084/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0178\n",
      "Epoch 1085/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0051 - val_loss: 0.0178\n",
      "Epoch 1086/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0051 - val_loss: 0.0177\n",
      "Epoch 1087/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0177\n",
      "Epoch 1088/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0177\n",
      "Epoch 1089/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0176\n",
      "Epoch 1090/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0051 - val_loss: 0.0176\n",
      "Epoch 1091/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0176\n",
      "Epoch 1092/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0175\n",
      "Epoch 1093/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0175\n",
      "Epoch 1094/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0174\n",
      "Epoch 1095/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0051 - val_loss: 0.0174\n",
      "Epoch 1096/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0051 - val_loss: 0.0174\n",
      "Epoch 1097/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0051 - val_loss: 0.0173\n",
      "Epoch 1098/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0173\n",
      "Epoch 1099/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0051 - val_loss: 0.0173\n",
      "Epoch 1100/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0051 - val_loss: 0.0172\n",
      "Epoch 1101/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0172\n",
      "Epoch 1102/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0172\n",
      "Epoch 1103/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0171\n",
      "Epoch 1104/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0171\n",
      "Epoch 1105/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0171\n",
      "Epoch 1106/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0050 - val_loss: 0.0170\n",
      "Epoch 1107/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0170\n",
      "Epoch 1108/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1109/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0169\n",
      "Epoch 1110/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0050 - val_loss: 0.0169\n",
      "Epoch 1111/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0169\n",
      "Epoch 1112/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0050 - val_loss: 0.0169\n",
      "Epoch 1113/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0168\n",
      "Epoch 1114/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0168\n",
      "Epoch 1115/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0168\n",
      "Epoch 1116/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0167\n",
      "Epoch 1117/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0167\n",
      "Epoch 1118/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0167\n",
      "Epoch 1119/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0167\n",
      "Epoch 1120/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0167\n",
      "Epoch 1121/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0166\n",
      "Epoch 1122/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0166\n",
      "Epoch 1123/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0166\n",
      "Epoch 1124/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0050 - val_loss: 0.0166\n",
      "Epoch 1125/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0165\n",
      "Epoch 1126/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0165\n",
      "Epoch 1127/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0165\n",
      "Epoch 1128/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0165\n",
      "Epoch 1129/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0165\n",
      "Epoch 1130/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0164\n",
      "Epoch 1131/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0164\n",
      "Epoch 1132/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0164\n",
      "Epoch 1133/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0164\n",
      "Epoch 1134/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0164\n",
      "Epoch 1135/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0164\n",
      "Epoch 1136/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0163\n",
      "Epoch 1137/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0163\n",
      "Epoch 1138/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0163\n",
      "Epoch 1139/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0163\n",
      "Epoch 1140/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0163\n",
      "Epoch 1141/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0163\n",
      "Epoch 1142/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0163\n",
      "Epoch 1143/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0163\n",
      "Epoch 1144/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0162\n",
      "Epoch 1145/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0162\n",
      "Epoch 1146/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0162\n",
      "Epoch 1147/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0050 - val_loss: 0.0162\n",
      "Epoch 1148/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0162\n",
      "Epoch 1149/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0162\n",
      "Epoch 1150/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0162\n",
      "Epoch 1151/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0162\n",
      "Epoch 1152/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0049 - val_loss: 0.0162\n",
      "Epoch 1153/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0162\n",
      "Epoch 1154/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0162\n",
      "Epoch 1155/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0162\n",
      "Epoch 1156/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1157/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1158/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1159/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1160/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1161/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1162/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1163/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1164/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1165/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1166/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1167/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1168/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1169/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1170/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1171/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1172/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1173/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1174/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1175/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1176/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1177/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1178/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1179/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0161\n",
      "Epoch 1180/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1181/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1182/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1183/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1184/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1185/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1186/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1187/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1188/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1189/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1190/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1191/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1192/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1193/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1194/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1195/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1196/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1197/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1198/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1199/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1200/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1201/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1202/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1203/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1204/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0160\n",
      "Epoch 1205/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0048 - val_loss: 0.0160\n",
      "Epoch 1206/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0160\n",
      "Epoch 1207/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0048 - val_loss: 0.0160\n",
      "Epoch 1208/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0160\n",
      "Epoch 1209/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0160\n",
      "Epoch 1210/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1211/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1212/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1213/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1214/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1215/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1216/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1217/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1218/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1219/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1220/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1221/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1222/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1223/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1224/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1225/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1226/1500\n",
      "28/28 [==============================] - 0s 429us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1227/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1228/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1229/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 1230/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0048 - val_loss: 0.0158\n",
      "Epoch 1231/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0158\n",
      "Epoch 1232/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0158\n",
      "Epoch 1233/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0158\n",
      "Epoch 1234/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0048 - val_loss: 0.0158\n",
      "Epoch 1235/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0158\n",
      "Epoch 1236/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0158\n",
      "Epoch 1237/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0158\n",
      "Epoch 1238/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0048 - val_loss: 0.0158\n",
      "Epoch 1239/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0048 - val_loss: 0.0158\n",
      "Epoch 1240/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0048 - val_loss: 0.0158\n",
      "Epoch 1241/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0048 - val_loss: 0.0158\n",
      "Epoch 1242/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0158\n",
      "Epoch 1243/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0047 - val_loss: 0.0158\n",
      "Epoch 1244/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0047 - val_loss: 0.0158\n",
      "Epoch 1245/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0047 - val_loss: 0.0158\n",
      "Epoch 1246/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0158\n",
      "Epoch 1247/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0047 - val_loss: 0.0158\n",
      "Epoch 1248/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0158\n",
      "Epoch 1249/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0158\n",
      "Epoch 1250/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0047 - val_loss: 0.0158\n",
      "Epoch 1251/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0158\n",
      "Epoch 1252/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0047 - val_loss: 0.0157\n",
      "Epoch 1253/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0157\n",
      "Epoch 1254/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0047 - val_loss: 0.0157\n",
      "Epoch 1255/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0157\n",
      "Epoch 1256/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0157\n",
      "Epoch 1257/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0047 - val_loss: 0.0157\n",
      "Epoch 1258/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0157\n",
      "Epoch 1259/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0157\n",
      "Epoch 1260/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0157\n",
      "Epoch 1261/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0157\n",
      "Epoch 1262/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0157\n",
      "Epoch 1263/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0157\n",
      "Epoch 1264/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0157\n",
      "Epoch 1265/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0047 - val_loss: 0.0157\n",
      "Epoch 1266/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0046 - val_loss: 0.0157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1267/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0046 - val_loss: 0.0157\n",
      "Epoch 1268/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0046 - val_loss: 0.0157\n",
      "Epoch 1269/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0046 - val_loss: 0.0157\n",
      "Epoch 1270/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0046 - val_loss: 0.0157\n",
      "Epoch 1271/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0046 - val_loss: 0.0157\n",
      "Epoch 1272/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0046 - val_loss: 0.0157\n",
      "Epoch 1273/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0046 - val_loss: 0.0157\n",
      "Epoch 1274/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0046 - val_loss: 0.0157\n",
      "Epoch 1275/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0046 - val_loss: 0.0157\n",
      "Epoch 1276/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0046 - val_loss: 0.0157\n",
      "Epoch 1277/1500\n",
      "28/28 [==============================] - 0s 429us/step - loss: 0.0046 - val_loss: 0.0157\n",
      "Epoch 1278/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0046 - val_loss: 0.0157\n",
      "Epoch 1279/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0046 - val_loss: 0.0157\n",
      "Epoch 1280/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0046 - val_loss: 0.0158\n",
      "Epoch 1281/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0046 - val_loss: 0.0158\n",
      "Epoch 1282/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0046 - val_loss: 0.0158\n",
      "Epoch 1283/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0045 - val_loss: 0.0158\n",
      "Epoch 1284/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0045 - val_loss: 0.0158\n",
      "Epoch 1285/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0045 - val_loss: 0.0158\n",
      "Epoch 1286/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0045 - val_loss: 0.0158\n",
      "Epoch 1287/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0045 - val_loss: 0.0158\n",
      "Epoch 1288/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0045 - val_loss: 0.0158\n",
      "Epoch 1289/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0045 - val_loss: 0.0158\n",
      "Epoch 1290/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0045 - val_loss: 0.0158\n",
      "Epoch 1291/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0045 - val_loss: 0.0158\n",
      "Epoch 1292/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0045 - val_loss: 0.0158\n",
      "Epoch 1293/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0045 - val_loss: 0.0159\n",
      "Epoch 1294/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0045 - val_loss: 0.0159\n",
      "Epoch 1295/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0045 - val_loss: 0.0159\n",
      "Epoch 1296/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0045 - val_loss: 0.0159\n",
      "Epoch 1297/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0044 - val_loss: 0.0159\n",
      "Epoch 1298/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0044 - val_loss: 0.0159\n",
      "Epoch 1299/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0044 - val_loss: 0.0159\n",
      "Epoch 1300/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0044 - val_loss: 0.0159\n",
      "Epoch 1301/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0044 - val_loss: 0.0160\n",
      "Epoch 1302/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0044 - val_loss: 0.0160\n",
      "Epoch 1303/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0044 - val_loss: 0.0160\n",
      "Epoch 1304/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0044 - val_loss: 0.0160\n",
      "Epoch 1305/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0044 - val_loss: 0.0160\n",
      "Epoch 1306/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0044 - val_loss: 0.0160\n",
      "Epoch 1307/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0044 - val_loss: 0.0161\n",
      "Epoch 1308/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0043 - val_loss: 0.0161\n",
      "Epoch 1309/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0043 - val_loss: 0.0161\n",
      "Epoch 1310/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0043 - val_loss: 0.0161\n",
      "Epoch 1311/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0043 - val_loss: 0.0161\n",
      "Epoch 1312/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0043 - val_loss: 0.0162\n",
      "Epoch 1313/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0043 - val_loss: 0.0162\n",
      "Epoch 1314/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0043 - val_loss: 0.0162\n",
      "Epoch 1315/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0043 - val_loss: 0.0162\n",
      "Epoch 1316/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0043 - val_loss: 0.0163\n",
      "Epoch 1317/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0042 - val_loss: 0.0163\n",
      "Epoch 1318/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0042 - val_loss: 0.0163\n",
      "Epoch 1319/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0042 - val_loss: 0.0163\n",
      "Epoch 1320/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0042 - val_loss: 0.0163\n",
      "Epoch 1321/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0042 - val_loss: 0.0164\n",
      "Epoch 1322/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0042 - val_loss: 0.0164\n",
      "Epoch 1323/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0042 - val_loss: 0.0164\n",
      "Epoch 1324/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0042 - val_loss: 0.0165\n",
      "Epoch 1325/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0041 - val_loss: 0.0165\n",
      "Epoch 1326/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0041 - val_loss: 0.0165\n",
      "Epoch 1327/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0041 - val_loss: 0.0165\n",
      "Epoch 1328/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0041 - val_loss: 0.0166\n",
      "Epoch 1329/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0041 - val_loss: 0.0166\n",
      "Epoch 1330/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0041 - val_loss: 0.0166\n",
      "Epoch 1331/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0041 - val_loss: 0.0167\n",
      "Epoch 1332/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0041 - val_loss: 0.0167\n",
      "Epoch 1333/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0040 - val_loss: 0.0167\n",
      "Epoch 1334/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0040 - val_loss: 0.0168\n",
      "Epoch 1335/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0040 - val_loss: 0.0168\n",
      "Epoch 1336/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0040 - val_loss: 0.0168\n",
      "Epoch 1337/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0040 - val_loss: 0.0169\n",
      "Epoch 1338/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0040 - val_loss: 0.0169\n",
      "Epoch 1339/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0040 - val_loss: 0.0169\n",
      "Epoch 1340/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0039 - val_loss: 0.0170\n",
      "Epoch 1341/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0039 - val_loss: 0.0170\n",
      "Epoch 1342/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0039 - val_loss: 0.0171\n",
      "Epoch 1343/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0039 - val_loss: 0.0171\n",
      "Epoch 1344/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0039 - val_loss: 0.0171\n",
      "Epoch 1345/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 143us/step - loss: 0.0039 - val_loss: 0.0172\n",
      "Epoch 1346/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0038 - val_loss: 0.0172\n",
      "Epoch 1347/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0038 - val_loss: 0.0173\n",
      "Epoch 1348/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0038 - val_loss: 0.0173\n",
      "Epoch 1349/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0038 - val_loss: 0.0174\n",
      "Epoch 1350/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0038 - val_loss: 0.0172\n",
      "Epoch 1351/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0038 - val_loss: 0.0177\n",
      "Epoch 1352/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0038 - val_loss: 0.0169\n",
      "Epoch 1353/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0038 - val_loss: 0.0191\n",
      "Epoch 1354/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0039 - val_loss: 0.0161\n",
      "Epoch 1355/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0046 - val_loss: 0.0278\n",
      "Epoch 1356/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0078 - val_loss: 0.0222\n",
      "Epoch 1357/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0131 - val_loss: 0.0598\n",
      "Epoch 1358/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0246 - val_loss: 0.0139\n",
      "Epoch 1359/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0078 - val_loss: 0.0290\n",
      "Epoch 1360/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0180 - val_loss: 0.0473\n",
      "Epoch 1361/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0211 - val_loss: 0.0174\n",
      "Epoch 1362/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0218\n",
      "Epoch 1363/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0191 - val_loss: 0.0109\n",
      "Epoch 1364/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0089 - val_loss: 0.0316\n",
      "Epoch 1365/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0143 - val_loss: 0.0236\n",
      "Epoch 1366/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0104 - val_loss: 0.0158\n",
      "Epoch 1367/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0078 - val_loss: 0.0203\n",
      "Epoch 1368/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0124 - val_loss: 0.0218\n",
      "Epoch 1369/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0077 - val_loss: 0.0344\n",
      "Epoch 1370/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0104 - val_loss: 0.0357\n",
      "Epoch 1371/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0081 - val_loss: 0.0246\n",
      "Epoch 1372/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0082 - val_loss: 0.0160\n",
      "Epoch 1373/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0078 - val_loss: 0.0159\n",
      "Epoch 1374/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0073 - val_loss: 0.0219\n",
      "Epoch 1375/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0081 - val_loss: 0.0231\n",
      "Epoch 1376/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0061 - val_loss: 0.0197\n",
      "Epoch 1377/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0081 - val_loss: 0.0176\n",
      "Epoch 1378/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0065 - val_loss: 0.0166\n",
      "Epoch 1379/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0062 - val_loss: 0.0180\n",
      "Epoch 1380/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0072 - val_loss: 0.0180\n",
      "Epoch 1381/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0059 - val_loss: 0.0184\n",
      "Epoch 1382/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0061 - val_loss: 0.0188\n",
      "Epoch 1383/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0063 - val_loss: 0.0205\n",
      "Epoch 1384/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0059 - val_loss: 0.0213\n",
      "Epoch 1385/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0064 - val_loss: 0.0173\n",
      "Epoch 1386/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0056 - val_loss: 0.0158\n",
      "Epoch 1387/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0060 - val_loss: 0.0166\n",
      "Epoch 1388/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0058 - val_loss: 0.0196\n",
      "Epoch 1389/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0213\n",
      "Epoch 1390/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0057 - val_loss: 0.0213\n",
      "Epoch 1391/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0054 - val_loss: 0.0197\n",
      "Epoch 1392/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0055 - val_loss: 0.0185\n",
      "Epoch 1393/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0055 - val_loss: 0.0193\n",
      "Epoch 1394/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0205\n",
      "Epoch 1395/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0056 - val_loss: 0.0199\n",
      "Epoch 1396/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0053 - val_loss: 0.0196\n",
      "Epoch 1397/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0199\n",
      "Epoch 1398/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0054 - val_loss: 0.0191\n",
      "Epoch 1399/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0184\n",
      "Epoch 1400/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0176\n",
      "Epoch 1401/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0053 - val_loss: 0.0171\n",
      "Epoch 1402/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0052 - val_loss: 0.0173\n",
      "Epoch 1403/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0052 - val_loss: 0.0177\n",
      "Epoch 1404/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0173\n",
      "Epoch 1405/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0162\n",
      "Epoch 1406/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0052 - val_loss: 0.0156\n",
      "Epoch 1407/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0052 - val_loss: 0.0156\n",
      "Epoch 1408/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0158\n",
      "Epoch 1409/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0052 - val_loss: 0.0159\n",
      "Epoch 1410/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0158\n",
      "Epoch 1411/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0052 - val_loss: 0.0159\n",
      "Epoch 1412/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0051 - val_loss: 0.0162\n",
      "Epoch 1413/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0051 - val_loss: 0.0165\n",
      "Epoch 1414/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0051 - val_loss: 0.0164\n",
      "Epoch 1415/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0163\n",
      "Epoch 1416/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0166\n",
      "Epoch 1417/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0051 - val_loss: 0.0169\n",
      "Epoch 1418/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0170\n",
      "Epoch 1419/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0166\n",
      "Epoch 1420/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0051 - val_loss: 0.0160\n",
      "Epoch 1421/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0156\n",
      "Epoch 1422/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0051 - val_loss: 0.0155\n",
      "Epoch 1423/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1424/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0155\n",
      "Epoch 1425/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0154\n",
      "Epoch 1426/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0153\n",
      "Epoch 1427/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0152\n",
      "Epoch 1428/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0153\n",
      "Epoch 1429/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0051 - val_loss: 0.0153\n",
      "Epoch 1430/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0050 - val_loss: 0.0155\n",
      "Epoch 1431/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0050 - val_loss: 0.0157\n",
      "Epoch 1432/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0050 - val_loss: 0.0157\n",
      "Epoch 1433/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0156\n",
      "Epoch 1434/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0154\n",
      "Epoch 1435/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0152\n",
      "Epoch 1436/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0153\n",
      "Epoch 1437/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0155\n",
      "Epoch 1438/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0155\n",
      "Epoch 1439/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0153\n",
      "Epoch 1440/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0050 - val_loss: 0.0151\n",
      "Epoch 1441/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0050 - val_loss: 0.0151\n",
      "Epoch 1442/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0050 - val_loss: 0.0152\n",
      "Epoch 1443/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0153\n",
      "Epoch 1444/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0153\n",
      "Epoch 1445/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0153\n",
      "Epoch 1446/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0152\n",
      "Epoch 1447/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0151\n",
      "Epoch 1448/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0151\n",
      "Epoch 1449/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0151\n",
      "Epoch 1450/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0151\n",
      "Epoch 1451/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0050 - val_loss: 0.0152\n",
      "Epoch 1452/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0151\n",
      "Epoch 1453/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0150\n",
      "Epoch 1454/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0149\n",
      "Epoch 1455/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0050 - val_loss: 0.0150\n",
      "Epoch 1456/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0150\n",
      "Epoch 1457/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0151\n",
      "Epoch 1458/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0150\n",
      "Epoch 1459/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0050 - val_loss: 0.0149\n",
      "Epoch 1460/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0149\n",
      "Epoch 1461/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0149\n",
      "Epoch 1462/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0149\n",
      "Epoch 1463/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0149\n",
      "Epoch 1464/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0148\n",
      "Epoch 1465/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0050 - val_loss: 0.0148\n",
      "Epoch 1466/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0147\n",
      "Epoch 1467/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0147\n",
      "Epoch 1468/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0147\n",
      "Epoch 1469/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0050 - val_loss: 0.0147\n",
      "Epoch 1470/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0050 - val_loss: 0.0147\n",
      "Epoch 1471/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0146\n",
      "Epoch 1472/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0146\n",
      "Epoch 1473/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0049 - val_loss: 0.0145\n",
      "Epoch 1474/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0146\n",
      "Epoch 1475/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0049 - val_loss: 0.0146\n",
      "Epoch 1476/1500\n",
      "28/28 [==============================] - 0s 161us/step - loss: 0.0049 - val_loss: 0.0145\n",
      "Epoch 1477/1500\n",
      "28/28 [==============================] - 0s 161us/step - loss: 0.0049 - val_loss: 0.0145\n",
      "Epoch 1478/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0049 - val_loss: 0.0145\n",
      "Epoch 1479/1500\n",
      "28/28 [==============================] - 0s 89us/step - loss: 0.0049 - val_loss: 0.0144\n",
      "Epoch 1480/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0144\n",
      "Epoch 1481/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0144\n",
      "Epoch 1482/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0144\n",
      "Epoch 1483/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0049 - val_loss: 0.0144\n",
      "Epoch 1484/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0049 - val_loss: 0.0143\n",
      "Epoch 1485/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0049 - val_loss: 0.0143\n",
      "Epoch 1486/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0143\n",
      "Epoch 1487/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0049 - val_loss: 0.0143\n",
      "Epoch 1488/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0143\n",
      "Epoch 1489/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0143\n",
      "Epoch 1490/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0049 - val_loss: 0.0143\n",
      "Epoch 1491/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0142\n",
      "Epoch 1492/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0049 - val_loss: 0.0142\n",
      "Epoch 1493/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0142\n",
      "Epoch 1494/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0049 - val_loss: 0.0142\n",
      "Epoch 1495/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0142\n",
      "Epoch 1496/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0049 - val_loss: 0.0142\n",
      "Epoch 1497/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0142\n",
      "Epoch 1498/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0142\n",
      "Epoch 1499/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0049 - val_loss: 0.0142\n",
      "Epoch 1500/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0049 - val_loss: 0.0141\n"
     ]
    }
   ],
   "source": [
    "# fit the model - INTENSIVE\n",
    "model4_history = model4.fit(X_train, Y_train, batch_size=256, epochs=1500, verbose=1, \\\n",
    "                            shuffle = True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use our model to predict in the range we want\n",
    "num_epochs = f'{len(model4_history.epoch)}'\n",
    "\n",
    "X_range = np.linspace(-10, 10, 500)\n",
    "y_pred = model4.predict(X_range)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(X_train, Y_train, label='Training data')\n",
    "ax.plot(X_range, y_pred, lw=4, color='r', label=f'NN ({num_epochs} epochs)')\n",
    "\n",
    "ax.set_xlabel(r'$X$', fontsize=20)\n",
    "ax.set_ylabel(r'$Y$', fontsize=20)\n",
    "ax.set_title(f'NN with {len(model4_history.model.layers)} layers, {H} nodes in each layer', fontsize=LABEL_SIZE)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(model4_history.history['loss']), 'r')\n",
    "ax.plot(np.sqrt(model4_history.history['val_loss']), 'b' ,label='Val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "Let's try adding a regularizer in our model: `kernel_regularizer=regularizers.l2(l2)`. Also let's create a function that takes the number of layers and the l2 value as the input and creates the model.\n",
    "\n",
    "Usage: `def create_dense([10, 20], l2=0.01)` will create a model with two hidden layers of 10 and 20 nodes each, l2=0.01 regularization and num_classes output nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "H =  100  # number of hidden nodes\n",
    "input_dim = 1\n",
    "\n",
    "model5 = models.Sequential()\n",
    "\n",
    "# Input layer of the neural network with ReLU activation function and L2 regularization\n",
    "model5.add(layers.Dense(H, input_dim=input_dim,  \n",
    "                activation='tanh', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "           \n",
    "# hidden layers\n",
    "model5.add(layers.Dense(H,   \n",
    "                activation='tanh', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "model5.add(layers.Dense(H,   \n",
    "                activation='tanh', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "model5.add(layers.Dense(H,   \n",
    "                activation='tanh', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "model5.add(layers.Dense(H,   \n",
    "                activation='tanh', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "model5.add(layers.Dense(H,   \n",
    "                activation='tanh', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "model5.add(layers.Dense(H,   \n",
    "                activation='tanh', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "# output layer\n",
    "model5.add(layers.Dense(1, \n",
    "                activation='linear')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the model\n",
    "model5.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28 samples, validate on 7 samples\n",
      "Epoch 1/1500\n",
      "28/28 [==============================] - 1s 41ms/step - loss: 6.2273 - val_loss: 6.6694\n",
      "Epoch 2/1500\n",
      "28/28 [==============================] - 0s 558us/step - loss: 6.5881 - val_loss: 6.0715\n",
      "Epoch 3/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 6.1120 - val_loss: 5.9957\n",
      "Epoch 4/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 6.0308 - val_loss: 6.1957\n",
      "Epoch 5/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 6.1765 - val_loss: 6.0645\n",
      "Epoch 6/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 6.0719 - val_loss: 5.8672\n",
      "Epoch 7/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 5.9174 - val_loss: 5.8389\n",
      "Epoch 8/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.8928 - val_loss: 5.9039\n",
      "Epoch 9/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 5.9376 - val_loss: 5.8825\n",
      "Epoch 10/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 5.9131 - val_loss: 5.7848\n",
      "Epoch 11/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.8298 - val_loss: 5.7036\n",
      "Epoch 12/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.7601 - val_loss: 5.6754\n",
      "Epoch 13/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 5.7318 - val_loss: 5.6738\n",
      "Epoch 14/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 5.7235 - val_loss: 5.6605\n",
      "Epoch 15/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.7052 - val_loss: 5.6210\n",
      "Epoch 16/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.6663 - val_loss: 5.5667\n",
      "Epoch 17/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.6163 - val_loss: 5.5178\n",
      "Epoch 18/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.5714 - val_loss: 5.4848\n",
      "Epoch 19/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.5396 - val_loss: 5.4637\n",
      "Epoch 20/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.5171 - val_loss: 5.4411\n",
      "Epoch 21/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.4929 - val_loss: 5.4081\n",
      "Epoch 22/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.4596 - val_loss: 5.3662\n",
      "Epoch 23/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 5.4188 - val_loss: 5.3240\n",
      "Epoch 24/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 5.3773 - val_loss: 5.2888\n",
      "Epoch 25/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.3415 - val_loss: 5.2598\n",
      "Epoch 26/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 5.3109 - val_loss: 5.2325\n",
      "Epoch 27/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 5.2820 - val_loss: 5.2019\n",
      "Epoch 28/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.2509 - val_loss: 5.1669\n",
      "Epoch 29/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.2164 - val_loss: 5.1284\n",
      "Epoch 30/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.1791 - val_loss: 5.0908\n",
      "Epoch 31/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 5.1421 - val_loss: 5.0564\n",
      "Epoch 32/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.1076 - val_loss: 5.0253\n",
      "Epoch 33/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.0755 - val_loss: 4.9954\n",
      "Epoch 34/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 5.0444 - val_loss: 4.9636\n",
      "Epoch 35/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 5.0119 - val_loss: 4.9294\n",
      "Epoch 36/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.9776 - val_loss: 4.8942\n",
      "Epoch 37/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.9426 - val_loss: 4.8596\n",
      "Epoch 38/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.9082 - val_loss: 4.8264\n",
      "Epoch 39/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.8747 - val_loss: 4.7950\n",
      "Epoch 40/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.8427 - val_loss: 4.7634\n",
      "Epoch 41/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.8107 - val_loss: 4.7309\n",
      "Epoch 42/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.7779 - val_loss: 4.6977\n",
      "Epoch 43/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.7445 - val_loss: 4.6641\n",
      "Epoch 44/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 4.7107 - val_loss: 4.6319\n",
      "Epoch 45/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 4.6778 - val_loss: 4.6008\n",
      "Epoch 46/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 4.6455 - val_loss: 4.5702\n",
      "Epoch 47/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.6137 - val_loss: 4.5394\n",
      "Epoch 48/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.5820 - val_loss: 4.5075\n",
      "Epoch 49/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.5498 - val_loss: 4.4746\n",
      "Epoch 50/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.5171 - val_loss: 4.4421\n",
      "Epoch 51/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.4848 - val_loss: 4.4103\n",
      "Epoch 52/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 4.4532 - val_loss: 4.3792\n",
      "Epoch 53/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 4.4220 - val_loss: 4.3483\n",
      "Epoch 54/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.3907 - val_loss: 4.3174\n",
      "Epoch 55/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.3592 - val_loss: 4.2866\n",
      "Epoch 56/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.3277 - val_loss: 4.2566\n",
      "Epoch 57/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.2965 - val_loss: 4.2272\n",
      "Epoch 58/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.2659 - val_loss: 4.1979\n",
      "Epoch 59/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.2355 - val_loss: 4.1683\n",
      "Epoch 60/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.2053 - val_loss: 4.1380\n",
      "Epoch 61/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 4.1748 - val_loss: 4.1076\n",
      "Epoch 62/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 4.1445 - val_loss: 4.0775\n",
      "Epoch 63/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 4.1145 - val_loss: 4.0479\n",
      "Epoch 64/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 4.0849 - val_loss: 4.0189\n",
      "Epoch 65/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.0556 - val_loss: 3.9900\n",
      "Epoch 66/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 4.0261 - val_loss: 3.9616\n",
      "Epoch 67/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 3.9967 - val_loss: 3.9335\n",
      "Epoch 68/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.9676 - val_loss: 3.9059\n",
      "Epoch 69/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.9391 - val_loss: 3.8778\n",
      "Epoch 70/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.9104 - val_loss: 3.8497\n",
      "Epoch 71/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 3.8820 - val_loss: 3.8215\n",
      "Epoch 72/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 3.8538 - val_loss: 3.7933\n",
      "Epoch 73/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.8257 - val_loss: 3.7656\n",
      "Epoch 74/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.7978 - val_loss: 3.7384\n",
      "Epoch 75/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.7702 - val_loss: 3.7117\n",
      "Epoch 76/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.7427 - val_loss: 3.6851\n",
      "Epoch 77/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 3.7152 - val_loss: 3.6589\n",
      "Epoch 78/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.6882 - val_loss: 3.6324\n",
      "Epoch 79/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.6612 - val_loss: 3.6058\n",
      "Epoch 80/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.6343 - val_loss: 3.5790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.6076 - val_loss: 3.5526\n",
      "Epoch 82/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.5812 - val_loss: 3.5264\n",
      "Epoch 83/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.5549 - val_loss: 3.5006\n",
      "Epoch 84/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.5288 - val_loss: 3.4752\n",
      "Epoch 85/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.5028 - val_loss: 3.4501\n",
      "Epoch 86/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 3.4770 - val_loss: 3.4252\n",
      "Epoch 87/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 3.4515 - val_loss: 3.4003\n",
      "Epoch 88/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.4261 - val_loss: 3.3752\n",
      "Epoch 89/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.4008 - val_loss: 3.3503\n",
      "Epoch 90/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.3759 - val_loss: 3.3255\n",
      "Epoch 91/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 3.3510 - val_loss: 3.3010\n",
      "Epoch 92/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.3263 - val_loss: 3.2768\n",
      "Epoch 93/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.3018 - val_loss: 3.2529\n",
      "Epoch 94/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 3.2775 - val_loss: 3.2292\n",
      "Epoch 95/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.2533 - val_loss: 3.2057\n",
      "Epoch 96/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.2295 - val_loss: 3.1822\n",
      "Epoch 97/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.2058 - val_loss: 3.1588\n",
      "Epoch 98/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 3.1822 - val_loss: 3.1354\n",
      "Epoch 99/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 3.1588 - val_loss: 3.1124\n",
      "Epoch 100/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.1356 - val_loss: 3.0895\n",
      "Epoch 101/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 3.1125 - val_loss: 3.0670\n",
      "Epoch 102/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.0896 - val_loss: 3.0446\n",
      "Epoch 103/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.0668 - val_loss: 3.0224\n",
      "Epoch 104/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 3.0442 - val_loss: 3.0001\n",
      "Epoch 105/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 3.0218 - val_loss: 2.9779\n",
      "Epoch 106/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.9996 - val_loss: 2.9559\n",
      "Epoch 107/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 2.9775 - val_loss: 2.9341\n",
      "Epoch 108/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.9556 - val_loss: 2.9127\n",
      "Epoch 109/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.9339 - val_loss: 2.8914\n",
      "Epoch 110/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 2.9123 - val_loss: 2.8703\n",
      "Epoch 111/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.8909 - val_loss: 2.8492\n",
      "Epoch 112/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.8697 - val_loss: 2.8283\n",
      "Epoch 113/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 2.8486 - val_loss: 2.8076\n",
      "Epoch 114/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 2.8277 - val_loss: 2.7870\n",
      "Epoch 115/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.8071 - val_loss: 2.7665\n",
      "Epoch 116/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.7865 - val_loss: 2.7464\n",
      "Epoch 117/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.7661 - val_loss: 2.7263\n",
      "Epoch 118/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.7458 - val_loss: 2.7064\n",
      "Epoch 119/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.7257 - val_loss: 2.6866\n",
      "Epoch 120/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.7057 - val_loss: 2.6669\n",
      "Epoch 121/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 2.6859 - val_loss: 2.6473\n",
      "Epoch 122/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.6663 - val_loss: 2.6279\n",
      "Epoch 123/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.6468 - val_loss: 2.6088\n",
      "Epoch 124/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.6275 - val_loss: 2.5897\n",
      "Epoch 125/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 2.6083 - val_loss: 2.5709\n",
      "Epoch 126/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 2.5892 - val_loss: 2.5521\n",
      "Epoch 127/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.5703 - val_loss: 2.5336\n",
      "Epoch 128/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 2.5517 - val_loss: 2.5151\n",
      "Epoch 129/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.5331 - val_loss: 2.4967\n",
      "Epoch 130/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 2.5147 - val_loss: 2.4786\n",
      "Epoch 131/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.4964 - val_loss: 2.4605\n",
      "Epoch 132/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 2.4782 - val_loss: 2.4427\n",
      "Epoch 133/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.4602 - val_loss: 2.4250\n",
      "Epoch 134/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 2.4424 - val_loss: 2.4074\n",
      "Epoch 135/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.4247 - val_loss: 2.3899\n",
      "Epoch 136/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 2.4071 - val_loss: 2.3725\n",
      "Epoch 137/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 2.3897 - val_loss: 2.3553\n",
      "Epoch 138/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.3724 - val_loss: 2.3383\n",
      "Epoch 139/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 2.3553 - val_loss: 2.3214\n",
      "Epoch 140/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.3382 - val_loss: 2.3046\n",
      "Epoch 141/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.3213 - val_loss: 2.2879\n",
      "Epoch 142/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.3046 - val_loss: 2.2714\n",
      "Epoch 143/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.2880 - val_loss: 2.2550\n",
      "Epoch 144/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.2716 - val_loss: 2.2387\n",
      "Epoch 145/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.2552 - val_loss: 2.2225\n",
      "Epoch 146/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.2390 - val_loss: 2.2065\n",
      "Epoch 147/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 2.2228 - val_loss: 2.1907\n",
      "Epoch 148/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.2069 - val_loss: 2.1749\n",
      "Epoch 149/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 2.1911 - val_loss: 2.1592\n",
      "Epoch 150/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.1753 - val_loss: 2.1437\n",
      "Epoch 151/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 2.1598 - val_loss: 2.1283\n",
      "Epoch 152/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.1443 - val_loss: 2.1130\n",
      "Epoch 153/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 2.1290 - val_loss: 2.0979\n",
      "Epoch 154/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.1138 - val_loss: 2.0828\n",
      "Epoch 155/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.0987 - val_loss: 2.0679\n",
      "Epoch 156/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.0837 - val_loss: 2.0531\n",
      "Epoch 157/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 2.0689 - val_loss: 2.0385\n",
      "Epoch 158/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 2.0542 - val_loss: 2.0239\n",
      "Epoch 159/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 2.0396 - val_loss: 2.0095\n",
      "Epoch 160/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 143us/step - loss: 2.0251 - val_loss: 1.9952\n",
      "Epoch 161/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 2.0107 - val_loss: 1.9810\n",
      "Epoch 162/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.9965 - val_loss: 1.9669\n",
      "Epoch 163/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.9824 - val_loss: 1.9529\n",
      "Epoch 164/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.9683 - val_loss: 1.9390\n",
      "Epoch 165/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.9544 - val_loss: 1.9252\n",
      "Epoch 166/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.9406 - val_loss: 1.9116\n",
      "Epoch 167/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.9269 - val_loss: 1.8980\n",
      "Epoch 168/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 1.9134 - val_loss: 1.8846\n",
      "Epoch 169/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.8999 - val_loss: 1.8712\n",
      "Epoch 170/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.8865 - val_loss: 1.8580\n",
      "Epoch 171/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.8733 - val_loss: 1.8449\n",
      "Epoch 172/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 1.8601 - val_loss: 1.8319\n",
      "Epoch 173/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.8471 - val_loss: 1.8190\n",
      "Epoch 174/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 1.8341 - val_loss: 1.8062\n",
      "Epoch 175/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.8213 - val_loss: 1.7935\n",
      "Epoch 176/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 1.8086 - val_loss: 1.7809\n",
      "Epoch 177/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.7959 - val_loss: 1.7683\n",
      "Epoch 178/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.7834 - val_loss: 1.7560\n",
      "Epoch 179/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.7710 - val_loss: 1.7436\n",
      "Epoch 180/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.7586 - val_loss: 1.7314\n",
      "Epoch 181/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.7464 - val_loss: 1.7193\n",
      "Epoch 182/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.7343 - val_loss: 1.7073\n",
      "Epoch 183/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.7222 - val_loss: 1.6954\n",
      "Epoch 184/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.7103 - val_loss: 1.6835\n",
      "Epoch 185/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.6984 - val_loss: 1.6718\n",
      "Epoch 186/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.6866 - val_loss: 1.6601\n",
      "Epoch 187/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 1.6750 - val_loss: 1.6486\n",
      "Epoch 188/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.6634 - val_loss: 1.6372\n",
      "Epoch 189/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.6520 - val_loss: 1.6258\n",
      "Epoch 190/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 1.6406 - val_loss: 1.6146\n",
      "Epoch 191/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.6293 - val_loss: 1.6034\n",
      "Epoch 192/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.6181 - val_loss: 1.5923\n",
      "Epoch 193/1500\n",
      "28/28 [==============================] - 0s 429us/step - loss: 1.6070 - val_loss: 1.5813\n",
      "Epoch 194/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.5960 - val_loss: 1.5704\n",
      "Epoch 195/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.5851 - val_loss: 1.5595\n",
      "Epoch 196/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.5742 - val_loss: 1.5488\n",
      "Epoch 197/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.5635 - val_loss: 1.5381\n",
      "Epoch 198/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 1.5528 - val_loss: 1.5276\n",
      "Epoch 199/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.5422 - val_loss: 1.5171\n",
      "Epoch 200/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 1.5317 - val_loss: 1.5067\n",
      "Epoch 201/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.5213 - val_loss: 1.4963\n",
      "Epoch 202/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.5109 - val_loss: 1.4861\n",
      "Epoch 203/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.5007 - val_loss: 1.4760\n",
      "Epoch 204/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.4906 - val_loss: 1.4659\n",
      "Epoch 205/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 1.4805 - val_loss: 1.4559\n",
      "Epoch 206/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.4705 - val_loss: 1.4460\n",
      "Epoch 207/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 1.4605 - val_loss: 1.4362\n",
      "Epoch 208/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.4507 - val_loss: 1.4264\n",
      "Epoch 209/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.4409 - val_loss: 1.4167\n",
      "Epoch 210/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.4312 - val_loss: 1.4071\n",
      "Epoch 211/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 1.4216 - val_loss: 1.3976\n",
      "Epoch 212/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.4121 - val_loss: 1.3881\n",
      "Epoch 213/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.4026 - val_loss: 1.3787\n",
      "Epoch 214/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.3932 - val_loss: 1.3694\n",
      "Epoch 215/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 1.3839 - val_loss: 1.3602\n",
      "Epoch 216/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.3746 - val_loss: 1.3510\n",
      "Epoch 217/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.3655 - val_loss: 1.3420\n",
      "Epoch 218/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 1.3564 - val_loss: 1.3329\n",
      "Epoch 219/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 1.3473 - val_loss: 1.3240\n",
      "Epoch 220/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.3384 - val_loss: 1.3151\n",
      "Epoch 221/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.3295 - val_loss: 1.3063\n",
      "Epoch 222/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.3207 - val_loss: 1.2976\n",
      "Epoch 223/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.3119 - val_loss: 1.2889\n",
      "Epoch 224/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 1.3033 - val_loss: 1.2803\n",
      "Epoch 225/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 1.2947 - val_loss: 1.2718\n",
      "Epoch 226/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.2861 - val_loss: 1.2633\n",
      "Epoch 227/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.2776 - val_loss: 1.2549\n",
      "Epoch 228/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 1.2692 - val_loss: 1.2466\n",
      "Epoch 229/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.2608 - val_loss: 1.2383\n",
      "Epoch 230/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 1.2526 - val_loss: 1.2301\n",
      "Epoch 231/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.2444 - val_loss: 1.2220\n",
      "Epoch 232/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.2362 - val_loss: 1.2139\n",
      "Epoch 233/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.2281 - val_loss: 1.2058\n",
      "Epoch 234/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.2201 - val_loss: 1.1979\n",
      "Epoch 235/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.2121 - val_loss: 1.1900\n",
      "Epoch 236/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 1.2042 - val_loss: 1.1822\n",
      "Epoch 237/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.1964 - val_loss: 1.1744\n",
      "Epoch 238/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.1886 - val_loss: 1.1667\n",
      "Epoch 239/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.1809 - val_loss: 1.1591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.1732 - val_loss: 1.1515\n",
      "Epoch 241/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.1656 - val_loss: 1.1439\n",
      "Epoch 242/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.1581 - val_loss: 1.1365\n",
      "Epoch 243/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.1506 - val_loss: 1.1291\n",
      "Epoch 244/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.1432 - val_loss: 1.1217\n",
      "Epoch 245/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.1358 - val_loss: 1.1144\n",
      "Epoch 246/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.1285 - val_loss: 1.1071\n",
      "Epoch 247/1500\n",
      "28/28 [==============================] - 0s 232us/step - loss: 1.1212 - val_loss: 1.0999\n",
      "Epoch 248/1500\n",
      "28/28 [==============================] - 0s 107us/step - loss: 1.1140 - val_loss: 1.0928\n",
      "Epoch 249/1500\n",
      "28/28 [==============================] - 0s 125us/step - loss: 1.1069 - val_loss: 1.0857\n",
      "Epoch 250/1500\n",
      "28/28 [==============================] - 0s 107us/step - loss: 1.0998 - val_loss: 1.0787\n",
      "Epoch 251/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.0928 - val_loss: 1.0717\n",
      "Epoch 252/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.0858 - val_loss: 1.0648\n",
      "Epoch 253/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 1.0789 - val_loss: 1.0579\n",
      "Epoch 254/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.0720 - val_loss: 1.0511\n",
      "Epoch 255/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.0651 - val_loss: 1.0444\n",
      "Epoch 256/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.0584 - val_loss: 1.0377\n",
      "Epoch 257/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.0516 - val_loss: 1.0310\n",
      "Epoch 258/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.0450 - val_loss: 1.0244\n",
      "Epoch 259/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.0383 - val_loss: 1.0178\n",
      "Epoch 260/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 1.0318 - val_loss: 1.0113\n",
      "Epoch 261/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 1.0253 - val_loss: 1.0049\n",
      "Epoch 262/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.0188 - val_loss: 0.9984\n",
      "Epoch 263/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 1.0124 - val_loss: 0.9921\n",
      "Epoch 264/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 1.0060 - val_loss: 0.9858\n",
      "Epoch 265/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.9997 - val_loss: 0.9795\n",
      "Epoch 266/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.9934 - val_loss: 0.9733\n",
      "Epoch 267/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.9872 - val_loss: 0.9671\n",
      "Epoch 268/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.9810 - val_loss: 0.9610\n",
      "Epoch 269/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.9748 - val_loss: 0.9549\n",
      "Epoch 270/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.9688 - val_loss: 0.9489\n",
      "Epoch 271/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.9627 - val_loss: 0.9429\n",
      "Epoch 272/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.9567 - val_loss: 0.9369\n",
      "Epoch 273/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.9508 - val_loss: 0.9310\n",
      "Epoch 274/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.9448 - val_loss: 0.9252\n",
      "Epoch 275/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.9390 - val_loss: 0.9194\n",
      "Epoch 276/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.9332 - val_loss: 0.9136\n",
      "Epoch 277/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.9274 - val_loss: 0.9079\n",
      "Epoch 278/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.9216 - val_loss: 0.9022\n",
      "Epoch 279/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.9159 - val_loss: 0.8965\n",
      "Epoch 280/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.9103 - val_loss: 0.8910\n",
      "Epoch 281/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.9047 - val_loss: 0.8854\n",
      "Epoch 282/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.8991 - val_loss: 0.8799\n",
      "Epoch 283/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.8936 - val_loss: 0.8744\n",
      "Epoch 284/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8881 - val_loss: 0.8690\n",
      "Epoch 285/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.8827 - val_loss: 0.8636\n",
      "Epoch 286/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.8773 - val_loss: 0.8582\n",
      "Epoch 287/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8719 - val_loss: 0.8529\n",
      "Epoch 288/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8666 - val_loss: 0.8476\n",
      "Epoch 289/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8613 - val_loss: 0.8424\n",
      "Epoch 290/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.8560 - val_loss: 0.8372\n",
      "Epoch 291/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8508 - val_loss: 0.8321\n",
      "Epoch 292/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8457 - val_loss: 0.8269\n",
      "Epoch 293/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8405 - val_loss: 0.8219\n",
      "Epoch 294/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8354 - val_loss: 0.8168\n",
      "Epoch 295/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8304 - val_loss: 0.8118\n",
      "Epoch 296/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8254 - val_loss: 0.8068\n",
      "Epoch 297/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.8204 - val_loss: 0.8019\n",
      "Epoch 298/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8154 - val_loss: 0.7970\n",
      "Epoch 299/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8105 - val_loss: 0.7921\n",
      "Epoch 300/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8056 - val_loss: 0.7873\n",
      "Epoch 301/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.8008 - val_loss: 0.7825\n",
      "Epoch 302/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.7960 - val_loss: 0.7778\n",
      "Epoch 303/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7912 - val_loss: 0.7731\n",
      "Epoch 304/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7865 - val_loss: 0.7684\n",
      "Epoch 305/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7818 - val_loss: 0.7637\n",
      "Epoch 306/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7771 - val_loss: 0.7591\n",
      "Epoch 307/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7725 - val_loss: 0.7545\n",
      "Epoch 308/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7679 - val_loss: 0.7500\n",
      "Epoch 309/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7634 - val_loss: 0.7455\n",
      "Epoch 310/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7588 - val_loss: 0.7410\n",
      "Epoch 311/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7543 - val_loss: 0.7365\n",
      "Epoch 312/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7499 - val_loss: 0.7321\n",
      "Epoch 313/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7454 - val_loss: 0.7277\n",
      "Epoch 314/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7410 - val_loss: 0.7234\n",
      "Epoch 315/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7367 - val_loss: 0.7190\n",
      "Epoch 316/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7323 - val_loss: 0.7147\n",
      "Epoch 317/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7280 - val_loss: 0.7105\n",
      "Epoch 318/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7237 - val_loss: 0.7062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.7195 - val_loss: 0.7020\n",
      "Epoch 320/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.7153 - val_loss: 0.6979\n",
      "Epoch 321/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.7111 - val_loss: 0.6937\n",
      "Epoch 322/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.7069 - val_loss: 0.6896\n",
      "Epoch 323/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.7028 - val_loss: 0.6855\n",
      "Epoch 324/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6987 - val_loss: 0.6815\n",
      "Epoch 325/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.6947 - val_loss: 0.6775\n",
      "Epoch 326/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6906 - val_loss: 0.6735\n",
      "Epoch 327/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6866 - val_loss: 0.6695\n",
      "Epoch 328/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6826 - val_loss: 0.6656\n",
      "Epoch 329/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6787 - val_loss: 0.6617\n",
      "Epoch 330/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6748 - val_loss: 0.6578\n",
      "Epoch 331/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.6709 - val_loss: 0.6539\n",
      "Epoch 332/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6670 - val_loss: 0.6501\n",
      "Epoch 333/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.6632 - val_loss: 0.6463\n",
      "Epoch 334/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.6593 - val_loss: 0.6425\n",
      "Epoch 335/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6556 - val_loss: 0.6388\n",
      "Epoch 336/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.6518 - val_loss: 0.6351\n",
      "Epoch 337/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.6481 - val_loss: 0.6314\n",
      "Epoch 338/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6444 - val_loss: 0.6277\n",
      "Epoch 339/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6407 - val_loss: 0.6241\n",
      "Epoch 340/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6370 - val_loss: 0.6205\n",
      "Epoch 341/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6334 - val_loss: 0.6169\n",
      "Epoch 342/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.6298 - val_loss: 0.6133\n",
      "Epoch 343/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6262 - val_loss: 0.6098\n",
      "Epoch 344/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.6227 - val_loss: 0.6063\n",
      "Epoch 345/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6192 - val_loss: 0.6028\n",
      "Epoch 346/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.6156 - val_loss: 0.5993\n",
      "Epoch 347/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.6122 - val_loss: 0.5959\n",
      "Epoch 348/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6087 - val_loss: 0.5925\n",
      "Epoch 349/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6053 - val_loss: 0.5891\n",
      "Epoch 350/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.6019 - val_loss: 0.5857\n",
      "Epoch 351/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5985 - val_loss: 0.5824\n",
      "Epoch 352/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5951 - val_loss: 0.5791\n",
      "Epoch 353/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.5918 - val_loss: 0.5758\n",
      "Epoch 354/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.5885 - val_loss: 0.5725\n",
      "Epoch 355/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.5852 - val_loss: 0.5693\n",
      "Epoch 356/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.5819 - val_loss: 0.5660\n",
      "Epoch 357/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5787 - val_loss: 0.5628\n",
      "Epoch 358/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.5755 - val_loss: 0.5597\n",
      "Epoch 359/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.5723 - val_loss: 0.5565\n",
      "Epoch 360/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5691 - val_loss: 0.5534\n",
      "Epoch 361/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.5660 - val_loss: 0.5503\n",
      "Epoch 362/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5628 - val_loss: 0.5472\n",
      "Epoch 363/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.5597 - val_loss: 0.5441\n",
      "Epoch 364/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5566 - val_loss: 0.5410\n",
      "Epoch 365/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.5536 - val_loss: 0.5380\n",
      "Epoch 366/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.5505 - val_loss: 0.5350\n",
      "Epoch 367/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5475 - val_loss: 0.5320\n",
      "Epoch 368/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5445 - val_loss: 0.5291\n",
      "Epoch 369/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5415 - val_loss: 0.5261\n",
      "Epoch 370/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5386 - val_loss: 0.5232\n",
      "Epoch 371/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.5356 - val_loss: 0.5203\n",
      "Epoch 372/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.5327 - val_loss: 0.5174\n",
      "Epoch 373/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5298 - val_loss: 0.5145\n",
      "Epoch 374/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5269 - val_loss: 0.5117\n",
      "Epoch 375/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5241 - val_loss: 0.5089\n",
      "Epoch 376/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5212 - val_loss: 0.5061\n",
      "Epoch 377/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5184 - val_loss: 0.5033\n",
      "Epoch 378/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.5156 - val_loss: 0.5005\n",
      "Epoch 379/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.5128 - val_loss: 0.4978\n",
      "Epoch 380/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.5100 - val_loss: 0.4950\n",
      "Epoch 381/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5073 - val_loss: 0.4923\n",
      "Epoch 382/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5046 - val_loss: 0.4896\n",
      "Epoch 383/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.5018 - val_loss: 0.4870\n",
      "Epoch 384/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4992 - val_loss: 0.4843\n",
      "Epoch 385/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.4965 - val_loss: 0.4817\n",
      "Epoch 386/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.4938 - val_loss: 0.4791\n",
      "Epoch 387/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4912 - val_loss: 0.4765\n",
      "Epoch 388/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.4886 - val_loss: 0.4739\n",
      "Epoch 389/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.4860 - val_loss: 0.4713\n",
      "Epoch 390/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4834 - val_loss: 0.4688\n",
      "Epoch 391/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.4808 - val_loss: 0.4662\n",
      "Epoch 392/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4783 - val_loss: 0.4637\n",
      "Epoch 393/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4758 - val_loss: 0.4612\n",
      "Epoch 394/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4732 - val_loss: 0.4588\n",
      "Epoch 395/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.4707 - val_loss: 0.4563\n",
      "Epoch 396/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4683 - val_loss: 0.4539\n",
      "Epoch 397/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4658 - val_loss: 0.4514\n",
      "Epoch 398/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4634 - val_loss: 0.4490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4609 - val_loss: 0.4466\n",
      "Epoch 400/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4585 - val_loss: 0.4442\n",
      "Epoch 401/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4561 - val_loss: 0.4419\n",
      "Epoch 402/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4537 - val_loss: 0.4395\n",
      "Epoch 403/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4514 - val_loss: 0.4372\n",
      "Epoch 404/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4490 - val_loss: 0.4349\n",
      "Epoch 405/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4467 - val_loss: 0.4326\n",
      "Epoch 406/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4444 - val_loss: 0.4303\n",
      "Epoch 407/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.4421 - val_loss: 0.4280\n",
      "Epoch 408/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4398 - val_loss: 0.4258\n",
      "Epoch 409/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4375 - val_loss: 0.4236\n",
      "Epoch 410/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.4353 - val_loss: 0.4213\n",
      "Epoch 411/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.4330 - val_loss: 0.4191\n",
      "Epoch 412/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4308 - val_loss: 0.4169\n",
      "Epoch 413/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4286 - val_loss: 0.4148\n",
      "Epoch 414/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.4264 - val_loss: 0.4126\n",
      "Epoch 415/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.4242 - val_loss: 0.4104\n",
      "Epoch 416/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4220 - val_loss: 0.4083\n",
      "Epoch 417/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4199 - val_loss: 0.4062\n",
      "Epoch 418/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4178 - val_loss: 0.4041\n",
      "Epoch 419/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.4156 - val_loss: 0.4020\n",
      "Epoch 420/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4135 - val_loss: 0.3999\n",
      "Epoch 421/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4114 - val_loss: 0.3979\n",
      "Epoch 422/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4093 - val_loss: 0.3958\n",
      "Epoch 423/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.4073 - val_loss: 0.3938\n",
      "Epoch 424/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4052 - val_loss: 0.3918\n",
      "Epoch 425/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.4032 - val_loss: 0.3898\n",
      "Epoch 426/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.4012 - val_loss: 0.3878\n",
      "Epoch 427/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3991 - val_loss: 0.3858\n",
      "Epoch 428/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3972 - val_loss: 0.3838\n",
      "Epoch 429/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3952 - val_loss: 0.3819\n",
      "Epoch 430/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3932 - val_loss: 0.3799\n",
      "Epoch 431/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.3912 - val_loss: 0.3780\n",
      "Epoch 432/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3893 - val_loss: 0.3761\n",
      "Epoch 433/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3874 - val_loss: 0.3742\n",
      "Epoch 434/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.3854 - val_loss: 0.3723\n",
      "Epoch 435/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.3835 - val_loss: 0.3704\n",
      "Epoch 436/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.3816 - val_loss: 0.3686\n",
      "Epoch 437/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3798 - val_loss: 0.3667\n",
      "Epoch 438/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.3779 - val_loss: 0.3649\n",
      "Epoch 439/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3760 - val_loss: 0.3630\n",
      "Epoch 440/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3742 - val_loss: 0.3612\n",
      "Epoch 441/1500\n",
      "28/28 [==============================] - 0s 269us/step - loss: 0.3723 - val_loss: 0.3594\n",
      "Epoch 442/1500\n",
      "28/28 [==============================] - 0s 178us/step - loss: 0.3705 - val_loss: 0.3576\n",
      "Epoch 443/1500\n",
      "28/28 [==============================] - 0s 125us/step - loss: 0.3687 - val_loss: 0.3559\n",
      "Epoch 444/1500\n",
      "28/28 [==============================] - 0s 147us/step - loss: 0.3669 - val_loss: 0.3541\n",
      "Epoch 445/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3651 - val_loss: 0.3523\n",
      "Epoch 446/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.3634 - val_loss: 0.3506\n",
      "Epoch 447/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.3616 - val_loss: 0.3489\n",
      "Epoch 448/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3599 - val_loss: 0.3471\n",
      "Epoch 449/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3581 - val_loss: 0.3454\n",
      "Epoch 450/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3564 - val_loss: 0.3437\n",
      "Epoch 451/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3547 - val_loss: 0.3420\n",
      "Epoch 452/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.3530 - val_loss: 0.3404\n",
      "Epoch 453/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.3513 - val_loss: 0.3387\n",
      "Epoch 454/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3496 - val_loss: 0.3371\n",
      "Epoch 455/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3479 - val_loss: 0.3354\n",
      "Epoch 456/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.3463 - val_loss: 0.3338\n",
      "Epoch 457/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3446 - val_loss: 0.3322\n",
      "Epoch 458/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3430 - val_loss: 0.3306\n",
      "Epoch 459/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.3414 - val_loss: 0.3290\n",
      "Epoch 460/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.3397 - val_loss: 0.3274\n",
      "Epoch 461/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.3381 - val_loss: 0.3258\n",
      "Epoch 462/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3365 - val_loss: 0.3242\n",
      "Epoch 463/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3350 - val_loss: 0.3227\n",
      "Epoch 464/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.3334 - val_loss: 0.3211\n",
      "Epoch 465/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.3318 - val_loss: 0.3196\n",
      "Epoch 466/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.3303 - val_loss: 0.3181\n",
      "Epoch 467/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.3287 - val_loss: 0.3165\n",
      "Epoch 468/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3272 - val_loss: 0.3150\n",
      "Epoch 469/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3257 - val_loss: 0.3135\n",
      "Epoch 470/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.3242 - val_loss: 0.3121\n",
      "Epoch 471/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3227 - val_loss: 0.3106\n",
      "Epoch 472/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3212 - val_loss: 0.3091\n",
      "Epoch 473/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.3197 - val_loss: 0.3077\n",
      "Epoch 474/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3182 - val_loss: 0.3062\n",
      "Epoch 475/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3167 - val_loss: 0.3048\n",
      "Epoch 476/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.3153 - val_loss: 0.3033\n",
      "Epoch 477/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3138 - val_loss: 0.3019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3124 - val_loss: 0.3005\n",
      "Epoch 479/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3110 - val_loss: 0.2991\n",
      "Epoch 480/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.3096 - val_loss: 0.2977\n",
      "Epoch 481/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3082 - val_loss: 0.2963\n",
      "Epoch 482/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3068 - val_loss: 0.2950\n",
      "Epoch 483/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3054 - val_loss: 0.2936\n",
      "Epoch 484/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.3040 - val_loss: 0.2922\n",
      "Epoch 485/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.3026 - val_loss: 0.2909\n",
      "Epoch 486/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.3013 - val_loss: 0.2896\n",
      "Epoch 487/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2999 - val_loss: 0.2882\n",
      "Epoch 488/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2986 - val_loss: 0.2869\n",
      "Epoch 489/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.2972 - val_loss: 0.2856\n",
      "Epoch 490/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2959 - val_loss: 0.2843\n",
      "Epoch 491/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2946 - val_loss: 0.2830\n",
      "Epoch 492/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2933 - val_loss: 0.2817\n",
      "Epoch 493/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2920 - val_loss: 0.2804\n",
      "Epoch 494/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2907 - val_loss: 0.2792\n",
      "Epoch 495/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2894 - val_loss: 0.2779\n",
      "Epoch 496/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2881 - val_loss: 0.2767\n",
      "Epoch 497/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2869 - val_loss: 0.2754\n",
      "Epoch 498/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2856 - val_loss: 0.2742\n",
      "Epoch 499/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2844 - val_loss: 0.2730\n",
      "Epoch 500/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2831 - val_loss: 0.2717\n",
      "Epoch 501/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2819 - val_loss: 0.2705\n",
      "Epoch 502/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2807 - val_loss: 0.2693\n",
      "Epoch 503/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2795 - val_loss: 0.2681\n",
      "Epoch 504/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.2783 - val_loss: 0.2669\n",
      "Epoch 505/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2771 - val_loss: 0.2658\n",
      "Epoch 506/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2759 - val_loss: 0.2646\n",
      "Epoch 507/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2747 - val_loss: 0.2634\n",
      "Epoch 508/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2735 - val_loss: 0.2623\n",
      "Epoch 509/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2723 - val_loss: 0.2611\n",
      "Epoch 510/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2712 - val_loss: 0.2600\n",
      "Epoch 511/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2700 - val_loss: 0.2588\n",
      "Epoch 512/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2689 - val_loss: 0.2577\n",
      "Epoch 513/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2677 - val_loss: 0.2566\n",
      "Epoch 514/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2666 - val_loss: 0.2555\n",
      "Epoch 515/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2655 - val_loss: 0.2544\n",
      "Epoch 516/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2644 - val_loss: 0.2533\n",
      "Epoch 517/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2633 - val_loss: 0.2522\n",
      "Epoch 518/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2622 - val_loss: 0.2511\n",
      "Epoch 519/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2611 - val_loss: 0.2500\n",
      "Epoch 520/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2600 - val_loss: 0.2489\n",
      "Epoch 521/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2589 - val_loss: 0.2479\n",
      "Epoch 522/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2578 - val_loss: 0.2468\n",
      "Epoch 523/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2568 - val_loss: 0.2458\n",
      "Epoch 524/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2557 - val_loss: 0.2447\n",
      "Epoch 525/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2546 - val_loss: 0.2437\n",
      "Epoch 526/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2536 - val_loss: 0.2427\n",
      "Epoch 527/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2526 - val_loss: 0.2416\n",
      "Epoch 528/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2515 - val_loss: 0.2406\n",
      "Epoch 529/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2505 - val_loss: 0.2396\n",
      "Epoch 530/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2495 - val_loss: 0.2386\n",
      "Epoch 531/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.2485 - val_loss: 0.2376\n",
      "Epoch 532/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2475 - val_loss: 0.2366\n",
      "Epoch 533/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2465 - val_loss: 0.2356\n",
      "Epoch 534/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2455 - val_loss: 0.2347\n",
      "Epoch 535/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2445 - val_loss: 0.2337\n",
      "Epoch 536/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2435 - val_loss: 0.2327\n",
      "Epoch 537/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2425 - val_loss: 0.2318\n",
      "Epoch 538/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2416 - val_loss: 0.2308\n",
      "Epoch 539/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2406 - val_loss: 0.2299\n",
      "Epoch 540/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.2397 - val_loss: 0.2289\n",
      "Epoch 541/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2387 - val_loss: 0.2280\n",
      "Epoch 542/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2378 - val_loss: 0.2271\n",
      "Epoch 543/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2368 - val_loss: 0.2262\n",
      "Epoch 544/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2359 - val_loss: 0.2252\n",
      "Epoch 545/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2350 - val_loss: 0.2243\n",
      "Epoch 546/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2341 - val_loss: 0.2234\n",
      "Epoch 547/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2331 - val_loss: 0.2225\n",
      "Epoch 548/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2322 - val_loss: 0.2216\n",
      "Epoch 549/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2313 - val_loss: 0.2207\n",
      "Epoch 550/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2304 - val_loss: 0.2199\n",
      "Epoch 551/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.2296 - val_loss: 0.2190\n",
      "Epoch 552/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.2287 - val_loss: 0.2181\n",
      "Epoch 553/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2278 - val_loss: 0.2173\n",
      "Epoch 554/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2269 - val_loss: 0.2164\n",
      "Epoch 555/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2261 - val_loss: 0.2155\n",
      "Epoch 556/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2252 - val_loss: 0.2147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 557/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2244 - val_loss: 0.2139\n",
      "Epoch 558/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2235 - val_loss: 0.2130\n",
      "Epoch 559/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.2227 - val_loss: 0.2122\n",
      "Epoch 560/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2218 - val_loss: 0.2114\n",
      "Epoch 561/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2210 - val_loss: 0.2105\n",
      "Epoch 562/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2202 - val_loss: 0.2097\n",
      "Epoch 563/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.2193 - val_loss: 0.2089\n",
      "Epoch 564/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2185 - val_loss: 0.2081\n",
      "Epoch 565/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2177 - val_loss: 0.2073\n",
      "Epoch 566/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2169 - val_loss: 0.2065\n",
      "Epoch 567/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2161 - val_loss: 0.2057\n",
      "Epoch 568/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2153 - val_loss: 0.2049\n",
      "Epoch 569/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2145 - val_loss: 0.2042\n",
      "Epoch 570/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.2137 - val_loss: 0.2034\n",
      "Epoch 571/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2130 - val_loss: 0.2026\n",
      "Epoch 572/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2122 - val_loss: 0.2019\n",
      "Epoch 573/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2114 - val_loss: 0.2011\n",
      "Epoch 574/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2106 - val_loss: 0.2003\n",
      "Epoch 575/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2099 - val_loss: 0.1996\n",
      "Epoch 576/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2091 - val_loss: 0.1988\n",
      "Epoch 577/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2084 - val_loss: 0.1981\n",
      "Epoch 578/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.2076 - val_loss: 0.1974\n",
      "Epoch 579/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2069 - val_loss: 0.1966\n",
      "Epoch 580/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2062 - val_loss: 0.1959\n",
      "Epoch 581/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2054 - val_loss: 0.1952\n",
      "Epoch 582/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2047 - val_loss: 0.1945\n",
      "Epoch 583/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.2040 - val_loss: 0.1938\n",
      "Epoch 584/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2033 - val_loss: 0.1931\n",
      "Epoch 585/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2026 - val_loss: 0.1924\n",
      "Epoch 586/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.2018 - val_loss: 0.1917\n",
      "Epoch 587/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.2011 - val_loss: 0.1910\n",
      "Epoch 588/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.2004 - val_loss: 0.1903\n",
      "Epoch 589/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1997 - val_loss: 0.1896\n",
      "Epoch 590/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1991 - val_loss: 0.1889\n",
      "Epoch 591/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1984 - val_loss: 0.1882\n",
      "Epoch 592/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1977 - val_loss: 0.1876\n",
      "Epoch 593/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1970 - val_loss: 0.1869\n",
      "Epoch 594/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1963 - val_loss: 0.1862\n",
      "Epoch 595/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1957 - val_loss: 0.1856\n",
      "Epoch 596/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1950 - val_loss: 0.1849\n",
      "Epoch 597/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1943 - val_loss: 0.1843\n",
      "Epoch 598/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1937 - val_loss: 0.1836\n",
      "Epoch 599/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1930 - val_loss: 0.1830\n",
      "Epoch 600/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1924 - val_loss: 0.1823\n",
      "Epoch 601/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1917 - val_loss: 0.1817\n",
      "Epoch 602/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1911 - val_loss: 0.1811\n",
      "Epoch 603/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1905 - val_loss: 0.1804\n",
      "Epoch 604/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.1898 - val_loss: 0.1798\n",
      "Epoch 605/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1892 - val_loss: 0.1792\n",
      "Epoch 606/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1886 - val_loss: 0.1786\n",
      "Epoch 607/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1880 - val_loss: 0.1780\n",
      "Epoch 608/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1874 - val_loss: 0.1774\n",
      "Epoch 609/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1867 - val_loss: 0.1768\n",
      "Epoch 610/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1861 - val_loss: 0.1762\n",
      "Epoch 611/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1855 - val_loss: 0.1756\n",
      "Epoch 612/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1849 - val_loss: 0.1750\n",
      "Epoch 613/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1843 - val_loss: 0.1744\n",
      "Epoch 614/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.1838 - val_loss: 0.1738\n",
      "Epoch 615/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1832 - val_loss: 0.1732\n",
      "Epoch 616/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1826 - val_loss: 0.1726\n",
      "Epoch 617/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1820 - val_loss: 0.1721\n",
      "Epoch 618/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1814 - val_loss: 0.1715\n",
      "Epoch 619/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1808 - val_loss: 0.1709\n",
      "Epoch 620/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1803 - val_loss: 0.1704\n",
      "Epoch 621/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1797 - val_loss: 0.1698\n",
      "Epoch 622/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1791 - val_loss: 0.1693\n",
      "Epoch 623/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1786 - val_loss: 0.1687\n",
      "Epoch 624/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1780 - val_loss: 0.1682\n",
      "Epoch 625/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1775 - val_loss: 0.1676\n",
      "Epoch 626/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1769 - val_loss: 0.1671\n",
      "Epoch 627/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1764 - val_loss: 0.1665\n",
      "Epoch 628/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1758 - val_loss: 0.1660\n",
      "Epoch 629/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1753 - val_loss: 0.1655\n",
      "Epoch 630/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1748 - val_loss: 0.1649\n",
      "Epoch 631/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1742 - val_loss: 0.1644\n",
      "Epoch 632/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1737 - val_loss: 0.1639\n",
      "Epoch 633/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1732 - val_loss: 0.1634\n",
      "Epoch 634/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1727 - val_loss: 0.1629\n",
      "Epoch 635/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1721 - val_loss: 0.1623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 636/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1716 - val_loss: 0.1618\n",
      "Epoch 637/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1711 - val_loss: 0.1613\n",
      "Epoch 638/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1706 - val_loss: 0.1608\n",
      "Epoch 639/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.1701 - val_loss: 0.1603\n",
      "Epoch 640/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1696 - val_loss: 0.1598\n",
      "Epoch 641/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1691 - val_loss: 0.1593\n",
      "Epoch 642/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1686 - val_loss: 0.1589\n",
      "Epoch 643/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1681 - val_loss: 0.1584\n",
      "Epoch 644/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1676 - val_loss: 0.1579\n",
      "Epoch 645/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1671 - val_loss: 0.1574\n",
      "Epoch 646/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1667 - val_loss: 0.1569\n",
      "Epoch 647/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1662 - val_loss: 0.1565\n",
      "Epoch 648/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1657 - val_loss: 0.1560\n",
      "Epoch 649/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.1652 - val_loss: 0.1555\n",
      "Epoch 650/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1648 - val_loss: 0.1551\n",
      "Epoch 651/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1643 - val_loss: 0.1546\n",
      "Epoch 652/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1638 - val_loss: 0.1541\n",
      "Epoch 653/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1634 - val_loss: 0.1537\n",
      "Epoch 654/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1629 - val_loss: 0.1532\n",
      "Epoch 655/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1624 - val_loss: 0.1528\n",
      "Epoch 656/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1620 - val_loss: 0.1523\n",
      "Epoch 657/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1615 - val_loss: 0.1519\n",
      "Epoch 658/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1611 - val_loss: 0.1514\n",
      "Epoch 659/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1606 - val_loss: 0.1510\n",
      "Epoch 660/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1602 - val_loss: 0.1506\n",
      "Epoch 661/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1598 - val_loss: 0.1501\n",
      "Epoch 662/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1593 - val_loss: 0.1497\n",
      "Epoch 663/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1589 - val_loss: 0.1493\n",
      "Epoch 664/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.1584 - val_loss: 0.1488\n",
      "Epoch 665/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.1580 - val_loss: 0.1484\n",
      "Epoch 666/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1576 - val_loss: 0.1480\n",
      "Epoch 667/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1572 - val_loss: 0.1476\n",
      "Epoch 668/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1567 - val_loss: 0.1472\n",
      "Epoch 669/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1563 - val_loss: 0.1468\n",
      "Epoch 670/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1559 - val_loss: 0.1463\n",
      "Epoch 671/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1555 - val_loss: 0.1459\n",
      "Epoch 672/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1551 - val_loss: 0.1455\n",
      "Epoch 673/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1547 - val_loss: 0.1451\n",
      "Epoch 674/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1543 - val_loss: 0.1447\n",
      "Epoch 675/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1539 - val_loss: 0.1443\n",
      "Epoch 676/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1535 - val_loss: 0.1439\n",
      "Epoch 677/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1531 - val_loss: 0.1435\n",
      "Epoch 678/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1527 - val_loss: 0.1432\n",
      "Epoch 679/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1523 - val_loss: 0.1428\n",
      "Epoch 680/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1519 - val_loss: 0.1424\n",
      "Epoch 681/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1515 - val_loss: 0.1420\n",
      "Epoch 682/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1511 - val_loss: 0.1416\n",
      "Epoch 683/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1507 - val_loss: 0.1412\n",
      "Epoch 684/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1503 - val_loss: 0.1409\n",
      "Epoch 685/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.1500 - val_loss: 0.1405\n",
      "Epoch 686/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1496 - val_loss: 0.1401\n",
      "Epoch 687/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1492 - val_loss: 0.1398\n",
      "Epoch 688/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1488 - val_loss: 0.1394\n",
      "Epoch 689/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1485 - val_loss: 0.1390\n",
      "Epoch 690/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1481 - val_loss: 0.1387\n",
      "Epoch 691/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1477 - val_loss: 0.1383\n",
      "Epoch 692/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1474 - val_loss: 0.1379\n",
      "Epoch 693/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1470 - val_loss: 0.1376\n",
      "Epoch 694/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1467 - val_loss: 0.1372\n",
      "Epoch 695/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1463 - val_loss: 0.1369\n",
      "Epoch 696/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1459 - val_loss: 0.1365\n",
      "Epoch 697/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1456 - val_loss: 0.1362\n",
      "Epoch 698/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1452 - val_loss: 0.1358\n",
      "Epoch 699/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1449 - val_loss: 0.1355\n",
      "Epoch 700/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1445 - val_loss: 0.1352\n",
      "Epoch 701/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1442 - val_loss: 0.1348\n",
      "Epoch 702/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1439 - val_loss: 0.1345\n",
      "Epoch 703/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1435 - val_loss: 0.1342\n",
      "Epoch 704/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1432 - val_loss: 0.1338\n",
      "Epoch 705/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1428 - val_loss: 0.1335\n",
      "Epoch 706/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1425 - val_loss: 0.1332\n",
      "Epoch 707/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1422 - val_loss: 0.1328\n",
      "Epoch 708/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.1419 - val_loss: 0.1325\n",
      "Epoch 709/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1415 - val_loss: 0.1322\n",
      "Epoch 710/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.1412 - val_loss: 0.1319\n",
      "Epoch 711/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1409 - val_loss: 0.1316\n",
      "Epoch 712/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1406 - val_loss: 0.1312\n",
      "Epoch 713/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1402 - val_loss: 0.1309\n",
      "Epoch 714/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1399 - val_loss: 0.1306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 715/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1396 - val_loss: 0.1303\n",
      "Epoch 716/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1393 - val_loss: 0.1300\n",
      "Epoch 717/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1390 - val_loss: 0.1297\n",
      "Epoch 718/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1387 - val_loss: 0.1294\n",
      "Epoch 719/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1384 - val_loss: 0.1291\n",
      "Epoch 720/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1381 - val_loss: 0.1288\n",
      "Epoch 721/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1378 - val_loss: 0.1285\n",
      "Epoch 722/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1374 - val_loss: 0.1282\n",
      "Epoch 723/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1371 - val_loss: 0.1279\n",
      "Epoch 724/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1369 - val_loss: 0.1276\n",
      "Epoch 725/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1366 - val_loss: 0.1273\n",
      "Epoch 726/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1363 - val_loss: 0.1270\n",
      "Epoch 727/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1360 - val_loss: 0.1267\n",
      "Epoch 728/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1357 - val_loss: 0.1265\n",
      "Epoch 729/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1354 - val_loss: 0.1262\n",
      "Epoch 730/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1351 - val_loss: 0.1259\n",
      "Epoch 731/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1348 - val_loss: 0.1256\n",
      "Epoch 732/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1345 - val_loss: 0.1253\n",
      "Epoch 733/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1342 - val_loss: 0.1251\n",
      "Epoch 734/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1340 - val_loss: 0.1248\n",
      "Epoch 735/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1337 - val_loss: 0.1245\n",
      "Epoch 736/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1334 - val_loss: 0.1242\n",
      "Epoch 737/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1331 - val_loss: 0.1240\n",
      "Epoch 738/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1329 - val_loss: 0.1237\n",
      "Epoch 739/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1326 - val_loss: 0.1234\n",
      "Epoch 740/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1323 - val_loss: 0.1232\n",
      "Epoch 741/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1320 - val_loss: 0.1229\n",
      "Epoch 742/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1318 - val_loss: 0.1226\n",
      "Epoch 743/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1315 - val_loss: 0.1224\n",
      "Epoch 744/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1312 - val_loss: 0.1221\n",
      "Epoch 745/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1310 - val_loss: 0.1219\n",
      "Epoch 746/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1307 - val_loss: 0.1216\n",
      "Epoch 747/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1305 - val_loss: 0.1213\n",
      "Epoch 748/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1302 - val_loss: 0.1211\n",
      "Epoch 749/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1299 - val_loss: 0.1208\n",
      "Epoch 750/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1297 - val_loss: 0.1206\n",
      "Epoch 751/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1294 - val_loss: 0.1203\n",
      "Epoch 752/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1292 - val_loss: 0.1201\n",
      "Epoch 753/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1289 - val_loss: 0.1199\n",
      "Epoch 754/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1287 - val_loss: 0.1196\n",
      "Epoch 755/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1284 - val_loss: 0.1194\n",
      "Epoch 756/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1282 - val_loss: 0.1191\n",
      "Epoch 757/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.1279 - val_loss: 0.1189\n",
      "Epoch 758/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1277 - val_loss: 0.1187\n",
      "Epoch 759/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1275 - val_loss: 0.1184\n",
      "Epoch 760/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1272 - val_loss: 0.1182\n",
      "Epoch 761/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1270 - val_loss: 0.1179\n",
      "Epoch 762/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1267 - val_loss: 0.1177\n",
      "Epoch 763/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1265 - val_loss: 0.1175\n",
      "Epoch 764/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1263 - val_loss: 0.1173\n",
      "Epoch 765/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1260 - val_loss: 0.1170\n",
      "Epoch 766/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1258 - val_loss: 0.1168\n",
      "Epoch 767/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1256 - val_loss: 0.1166\n",
      "Epoch 768/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1253 - val_loss: 0.1164\n",
      "Epoch 769/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1251 - val_loss: 0.1161\n",
      "Epoch 770/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1249 - val_loss: 0.1159\n",
      "Epoch 771/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1247 - val_loss: 0.1157\n",
      "Epoch 772/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1244 - val_loss: 0.1155\n",
      "Epoch 773/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1242 - val_loss: 0.1153\n",
      "Epoch 774/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1240 - val_loss: 0.1150\n",
      "Epoch 775/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1238 - val_loss: 0.1148\n",
      "Epoch 776/1500\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.1236 - val_loss: 0.1146\n",
      "Epoch 777/1500\n",
      "28/28 [==============================] - 0s 125us/step - loss: 0.1233 - val_loss: 0.1144\n",
      "Epoch 778/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1231 - val_loss: 0.1142\n",
      "Epoch 779/1500\n",
      "28/28 [==============================] - 0s 71us/step - loss: 0.1229 - val_loss: 0.1140\n",
      "Epoch 780/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1227 - val_loss: 0.1138\n",
      "Epoch 781/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1225 - val_loss: 0.1136\n",
      "Epoch 782/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1223 - val_loss: 0.1134\n",
      "Epoch 783/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1221 - val_loss: 0.1132\n",
      "Epoch 784/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1219 - val_loss: 0.1130\n",
      "Epoch 785/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.1216 - val_loss: 0.1128\n",
      "Epoch 786/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1214 - val_loss: 0.1126\n",
      "Epoch 787/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1212 - val_loss: 0.1124\n",
      "Epoch 788/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1210 - val_loss: 0.1122\n",
      "Epoch 789/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1208 - val_loss: 0.1120\n",
      "Epoch 790/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1206 - val_loss: 0.1118\n",
      "Epoch 791/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1204 - val_loss: 0.1116\n",
      "Epoch 792/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1202 - val_loss: 0.1114\n",
      "Epoch 793/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1200 - val_loss: 0.1112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 794/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1198 - val_loss: 0.1110\n",
      "Epoch 795/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1196 - val_loss: 0.1108\n",
      "Epoch 796/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1194 - val_loss: 0.1106\n",
      "Epoch 797/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1192 - val_loss: 0.1104\n",
      "Epoch 798/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1191 - val_loss: 0.1102\n",
      "Epoch 799/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1189 - val_loss: 0.1101\n",
      "Epoch 800/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1187 - val_loss: 0.1099\n",
      "Epoch 801/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1185 - val_loss: 0.1097\n",
      "Epoch 802/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1183 - val_loss: 0.1095\n",
      "Epoch 803/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1181 - val_loss: 0.1093\n",
      "Epoch 804/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1179 - val_loss: 0.1092\n",
      "Epoch 805/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1177 - val_loss: 0.1090\n",
      "Epoch 806/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1176 - val_loss: 0.1088\n",
      "Epoch 807/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1174 - val_loss: 0.1086\n",
      "Epoch 808/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1172 - val_loss: 0.1084\n",
      "Epoch 809/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1170 - val_loss: 0.1083\n",
      "Epoch 810/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1168 - val_loss: 0.1081\n",
      "Epoch 811/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1167 - val_loss: 0.1079\n",
      "Epoch 812/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1165 - val_loss: 0.1078\n",
      "Epoch 813/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1163 - val_loss: 0.1076\n",
      "Epoch 814/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1161 - val_loss: 0.1074\n",
      "Epoch 815/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1160 - val_loss: 0.1072\n",
      "Epoch 816/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1158 - val_loss: 0.1071\n",
      "Epoch 817/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.1156 - val_loss: 0.1069\n",
      "Epoch 818/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1154 - val_loss: 0.1067\n",
      "Epoch 819/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1153 - val_loss: 0.1066\n",
      "Epoch 820/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1151 - val_loss: 0.1064\n",
      "Epoch 821/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.1149 - val_loss: 0.1063\n",
      "Epoch 822/1500\n",
      "28/28 [==============================] - 0s 141us/step - loss: 0.1148 - val_loss: 0.1061\n",
      "Epoch 823/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1146 - val_loss: 0.1059\n",
      "Epoch 824/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1144 - val_loss: 0.1058\n",
      "Epoch 825/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1143 - val_loss: 0.1056\n",
      "Epoch 826/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1141 - val_loss: 0.1055\n",
      "Epoch 827/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1139 - val_loss: 0.1053\n",
      "Epoch 828/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1138 - val_loss: 0.1052\n",
      "Epoch 829/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1136 - val_loss: 0.1050\n",
      "Epoch 830/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1135 - val_loss: 0.1048\n",
      "Epoch 831/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1133 - val_loss: 0.1047\n",
      "Epoch 832/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1131 - val_loss: 0.1045\n",
      "Epoch 833/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1130 - val_loss: 0.1044\n",
      "Epoch 834/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1128 - val_loss: 0.1042\n",
      "Epoch 835/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1127 - val_loss: 0.1041\n",
      "Epoch 836/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1125 - val_loss: 0.1039\n",
      "Epoch 837/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1124 - val_loss: 0.1038\n",
      "Epoch 838/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1122 - val_loss: 0.1036\n",
      "Epoch 839/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1121 - val_loss: 0.1035\n",
      "Epoch 840/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1119 - val_loss: 0.1034\n",
      "Epoch 841/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1118 - val_loss: 0.1032\n",
      "Epoch 842/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1116 - val_loss: 0.1031\n",
      "Epoch 843/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1115 - val_loss: 0.1029\n",
      "Epoch 844/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.1113 - val_loss: 0.1028\n",
      "Epoch 845/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1112 - val_loss: 0.1026\n",
      "Epoch 846/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1110 - val_loss: 0.1025\n",
      "Epoch 847/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1109 - val_loss: 0.1024\n",
      "Epoch 848/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1107 - val_loss: 0.1022\n",
      "Epoch 849/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1106 - val_loss: 0.1021\n",
      "Epoch 850/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1104 - val_loss: 0.1020\n",
      "Epoch 851/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.1103 - val_loss: 0.1018\n",
      "Epoch 852/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.1102 - val_loss: 0.1017\n",
      "Epoch 853/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1100 - val_loss: 0.1016\n",
      "Epoch 854/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1099 - val_loss: 0.1014\n",
      "Epoch 855/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1097 - val_loss: 0.1013\n",
      "Epoch 856/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1096 - val_loss: 0.1012\n",
      "Epoch 857/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1095 - val_loss: 0.1010\n",
      "Epoch 858/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1093 - val_loss: 0.1009\n",
      "Epoch 859/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1092 - val_loss: 0.1008\n",
      "Epoch 860/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1091 - val_loss: 0.1006\n",
      "Epoch 861/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1089 - val_loss: 0.1005\n",
      "Epoch 862/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1088 - val_loss: 0.1004\n",
      "Epoch 863/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1086 - val_loss: 0.1003\n",
      "Epoch 864/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1085 - val_loss: 0.1001\n",
      "Epoch 865/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1084 - val_loss: 0.1000\n",
      "Epoch 866/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1083 - val_loss: 0.0999\n",
      "Epoch 867/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1081 - val_loss: 0.0998\n",
      "Epoch 868/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1080 - val_loss: 0.0996\n",
      "Epoch 869/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1079 - val_loss: 0.0995\n",
      "Epoch 870/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1077 - val_loss: 0.0994\n",
      "Epoch 871/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1076 - val_loss: 0.0993\n",
      "Epoch 872/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1075 - val_loss: 0.0992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 873/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1074 - val_loss: 0.0990\n",
      "Epoch 874/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1072 - val_loss: 0.0989\n",
      "Epoch 875/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1071 - val_loss: 0.0988\n",
      "Epoch 876/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1070 - val_loss: 0.0987\n",
      "Epoch 877/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1069 - val_loss: 0.0986\n",
      "Epoch 878/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1067 - val_loss: 0.0984\n",
      "Epoch 879/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1066 - val_loss: 0.0983\n",
      "Epoch 880/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.1065 - val_loss: 0.0982\n",
      "Epoch 881/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1064 - val_loss: 0.0981\n",
      "Epoch 882/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1063 - val_loss: 0.0980\n",
      "Epoch 883/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.1061 - val_loss: 0.0979\n",
      "Epoch 884/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1060 - val_loss: 0.0978\n",
      "Epoch 885/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1059 - val_loss: 0.0977\n",
      "Epoch 886/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1058 - val_loss: 0.0975\n",
      "Epoch 887/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1057 - val_loss: 0.0974\n",
      "Epoch 888/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1055 - val_loss: 0.0973\n",
      "Epoch 889/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1054 - val_loss: 0.0972\n",
      "Epoch 890/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1053 - val_loss: 0.0971\n",
      "Epoch 891/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1052 - val_loss: 0.0970\n",
      "Epoch 892/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1051 - val_loss: 0.0969\n",
      "Epoch 893/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1050 - val_loss: 0.0968\n",
      "Epoch 894/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1049 - val_loss: 0.0967\n",
      "Epoch 895/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1047 - val_loss: 0.0966\n",
      "Epoch 896/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1046 - val_loss: 0.0965\n",
      "Epoch 897/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1045 - val_loss: 0.0964\n",
      "Epoch 898/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1044 - val_loss: 0.0963\n",
      "Epoch 899/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1043 - val_loss: 0.0962\n",
      "Epoch 900/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1042 - val_loss: 0.0961\n",
      "Epoch 901/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1041 - val_loss: 0.0960\n",
      "Epoch 902/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1040 - val_loss: 0.0959\n",
      "Epoch 903/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1039 - val_loss: 0.0958\n",
      "Epoch 904/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1038 - val_loss: 0.0957\n",
      "Epoch 905/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1037 - val_loss: 0.0956\n",
      "Epoch 906/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1036 - val_loss: 0.0955\n",
      "Epoch 907/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1034 - val_loss: 0.0954\n",
      "Epoch 908/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1033 - val_loss: 0.0953\n",
      "Epoch 909/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1032 - val_loss: 0.0952\n",
      "Epoch 910/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1031 - val_loss: 0.0951\n",
      "Epoch 911/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1030 - val_loss: 0.0950\n",
      "Epoch 912/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1029 - val_loss: 0.0949\n",
      "Epoch 913/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1028 - val_loss: 0.0948\n",
      "Epoch 914/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1027 - val_loss: 0.0947\n",
      "Epoch 915/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1026 - val_loss: 0.0946\n",
      "Epoch 916/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1025 - val_loss: 0.0945\n",
      "Epoch 917/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.1024 - val_loss: 0.0944\n",
      "Epoch 918/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1023 - val_loss: 0.0943\n",
      "Epoch 919/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1022 - val_loss: 0.0942\n",
      "Epoch 920/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1021 - val_loss: 0.0942\n",
      "Epoch 921/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1020 - val_loss: 0.0941\n",
      "Epoch 922/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.1019 - val_loss: 0.0940\n",
      "Epoch 923/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1018 - val_loss: 0.0939\n",
      "Epoch 924/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1017 - val_loss: 0.0938\n",
      "Epoch 925/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1016 - val_loss: 0.0937\n",
      "Epoch 926/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1015 - val_loss: 0.0936\n",
      "Epoch 927/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.1014 - val_loss: 0.0935\n",
      "Epoch 928/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1014 - val_loss: 0.0934\n",
      "Epoch 929/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1013 - val_loss: 0.0934\n",
      "Epoch 930/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1012 - val_loss: 0.0933\n",
      "Epoch 931/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1011 - val_loss: 0.0932\n",
      "Epoch 932/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1010 - val_loss: 0.0931\n",
      "Epoch 933/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1009 - val_loss: 0.0930\n",
      "Epoch 934/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1008 - val_loss: 0.0929\n",
      "Epoch 935/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1007 - val_loss: 0.0929\n",
      "Epoch 936/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1006 - val_loss: 0.0928\n",
      "Epoch 937/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1005 - val_loss: 0.0927\n",
      "Epoch 938/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1004 - val_loss: 0.0926\n",
      "Epoch 939/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.1003 - val_loss: 0.0925\n",
      "Epoch 940/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1003 - val_loss: 0.0924\n",
      "Epoch 941/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.1002 - val_loss: 0.0924\n",
      "Epoch 942/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1001 - val_loss: 0.0923\n",
      "Epoch 943/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.1000 - val_loss: 0.0922\n",
      "Epoch 944/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0999 - val_loss: 0.0921\n",
      "Epoch 945/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0998 - val_loss: 0.0920\n",
      "Epoch 946/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0997 - val_loss: 0.0920\n",
      "Epoch 947/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0996 - val_loss: 0.0919\n",
      "Epoch 948/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0996 - val_loss: 0.0918\n",
      "Epoch 949/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0995 - val_loss: 0.0917\n",
      "Epoch 950/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0994 - val_loss: 0.0917\n",
      "Epoch 951/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0993 - val_loss: 0.0916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0992 - val_loss: 0.0915\n",
      "Epoch 953/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0991 - val_loss: 0.0914\n",
      "Epoch 954/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0990 - val_loss: 0.0914\n",
      "Epoch 955/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0990 - val_loss: 0.0913\n",
      "Epoch 956/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0989 - val_loss: 0.0912\n",
      "Epoch 957/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0988 - val_loss: 0.0911\n",
      "Epoch 958/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0987 - val_loss: 0.0911\n",
      "Epoch 959/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0986 - val_loss: 0.0910\n",
      "Epoch 960/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0986 - val_loss: 0.0909\n",
      "Epoch 961/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0985 - val_loss: 0.0908\n",
      "Epoch 962/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0984 - val_loss: 0.0908\n",
      "Epoch 963/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0983 - val_loss: 0.0907\n",
      "Epoch 964/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0982 - val_loss: 0.0906\n",
      "Epoch 965/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0982 - val_loss: 0.0906\n",
      "Epoch 966/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0981 - val_loss: 0.0905\n",
      "Epoch 967/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0980 - val_loss: 0.0904\n",
      "Epoch 968/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0979 - val_loss: 0.0904\n",
      "Epoch 969/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0978 - val_loss: 0.0903\n",
      "Epoch 970/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0978 - val_loss: 0.0902\n",
      "Epoch 971/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0977 - val_loss: 0.0902\n",
      "Epoch 972/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0976 - val_loss: 0.0901\n",
      "Epoch 973/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0975 - val_loss: 0.0900\n",
      "Epoch 974/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0975 - val_loss: 0.0900\n",
      "Epoch 975/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0974 - val_loss: 0.0899\n",
      "Epoch 976/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0973 - val_loss: 0.0898\n",
      "Epoch 977/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0972 - val_loss: 0.0898\n",
      "Epoch 978/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0971 - val_loss: 0.0897\n",
      "Epoch 979/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0971 - val_loss: 0.0896\n",
      "Epoch 980/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0970 - val_loss: 0.0896\n",
      "Epoch 981/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0969 - val_loss: 0.0895\n",
      "Epoch 982/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0969 - val_loss: 0.0894\n",
      "Epoch 983/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0968 - val_loss: 0.0894\n",
      "Epoch 984/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0967 - val_loss: 0.0893\n",
      "Epoch 985/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0966 - val_loss: 0.0892\n",
      "Epoch 986/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0966 - val_loss: 0.0892\n",
      "Epoch 987/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0965 - val_loss: 0.0891\n",
      "Epoch 988/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0964 - val_loss: 0.0891\n",
      "Epoch 989/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0963 - val_loss: 0.0890\n",
      "Epoch 990/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0963 - val_loss: 0.0889\n",
      "Epoch 991/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0962 - val_loss: 0.0889\n",
      "Epoch 992/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0961 - val_loss: 0.0888\n",
      "Epoch 993/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0961 - val_loss: 0.0888\n",
      "Epoch 994/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0960 - val_loss: 0.0887\n",
      "Epoch 995/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0959 - val_loss: 0.0886\n",
      "Epoch 996/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0959 - val_loss: 0.0886\n",
      "Epoch 997/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0958 - val_loss: 0.0885\n",
      "Epoch 998/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0957 - val_loss: 0.0885\n",
      "Epoch 999/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0957 - val_loss: 0.0884\n",
      "Epoch 1000/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0956 - val_loss: 0.0883\n",
      "Epoch 1001/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0955 - val_loss: 0.0883\n",
      "Epoch 1002/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0954 - val_loss: 0.0882\n",
      "Epoch 1003/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0954 - val_loss: 0.0882\n",
      "Epoch 1004/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0953 - val_loss: 0.0881\n",
      "Epoch 1005/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0952 - val_loss: 0.0881\n",
      "Epoch 1006/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0952 - val_loss: 0.0880\n",
      "Epoch 1007/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0951 - val_loss: 0.0879\n",
      "Epoch 1008/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0951 - val_loss: 0.0879\n",
      "Epoch 1009/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0950 - val_loss: 0.0878\n",
      "Epoch 1010/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0949 - val_loss: 0.0878\n",
      "Epoch 1011/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0949 - val_loss: 0.0877\n",
      "Epoch 1012/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0948 - val_loss: 0.0877\n",
      "Epoch 1013/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0947 - val_loss: 0.0876\n",
      "Epoch 1014/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0947 - val_loss: 0.0876\n",
      "Epoch 1015/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0946 - val_loss: 0.0875\n",
      "Epoch 1016/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0945 - val_loss: 0.0875\n",
      "Epoch 1017/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0945 - val_loss: 0.0874\n",
      "Epoch 1018/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0944 - val_loss: 0.0874\n",
      "Epoch 1019/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0943 - val_loss: 0.0873\n",
      "Epoch 1020/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0943 - val_loss: 0.0873\n",
      "Epoch 1021/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0942 - val_loss: 0.0872\n",
      "Epoch 1022/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0942 - val_loss: 0.0871\n",
      "Epoch 1023/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0941 - val_loss: 0.0871\n",
      "Epoch 1024/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0940 - val_loss: 0.0870\n",
      "Epoch 1025/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0940 - val_loss: 0.0870\n",
      "Epoch 1026/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0939 - val_loss: 0.0869\n",
      "Epoch 1027/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0939 - val_loss: 0.0869\n",
      "Epoch 1028/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0938 - val_loss: 0.0868\n",
      "Epoch 1029/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0937 - val_loss: 0.0868\n",
      "Epoch 1030/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0937 - val_loss: 0.0867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1031/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0936 - val_loss: 0.0867\n",
      "Epoch 1032/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0936 - val_loss: 0.0867\n",
      "Epoch 1033/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0935 - val_loss: 0.0866\n",
      "Epoch 1034/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0934 - val_loss: 0.0866\n",
      "Epoch 1035/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0934 - val_loss: 0.0865\n",
      "Epoch 1036/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0933 - val_loss: 0.0865\n",
      "Epoch 1037/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0933 - val_loss: 0.0864\n",
      "Epoch 1038/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0932 - val_loss: 0.0864\n",
      "Epoch 1039/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0931 - val_loss: 0.0863\n",
      "Epoch 1040/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0931 - val_loss: 0.0863\n",
      "Epoch 1041/1500\n",
      "28/28 [==============================] - 0s 428us/step - loss: 0.0930 - val_loss: 0.0862\n",
      "Epoch 1042/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0930 - val_loss: 0.0862\n",
      "Epoch 1043/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0929 - val_loss: 0.0861\n",
      "Epoch 1044/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0929 - val_loss: 0.0861\n",
      "Epoch 1045/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0928 - val_loss: 0.0860\n",
      "Epoch 1046/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0928 - val_loss: 0.0860\n",
      "Epoch 1047/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0927 - val_loss: 0.0860\n",
      "Epoch 1048/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0926 - val_loss: 0.0859\n",
      "Epoch 1049/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0926 - val_loss: 0.0859\n",
      "Epoch 1050/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0925 - val_loss: 0.0858\n",
      "Epoch 1051/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0925 - val_loss: 0.0858\n",
      "Epoch 1052/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0924 - val_loss: 0.0857\n",
      "Epoch 1053/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0924 - val_loss: 0.0857\n",
      "Epoch 1054/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0923 - val_loss: 0.0857\n",
      "Epoch 1055/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0923 - val_loss: 0.0856\n",
      "Epoch 1056/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0922 - val_loss: 0.0856\n",
      "Epoch 1057/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0922 - val_loss: 0.0855\n",
      "Epoch 1058/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0921 - val_loss: 0.0855\n",
      "Epoch 1059/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0920 - val_loss: 0.0854\n",
      "Epoch 1060/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0920 - val_loss: 0.0854\n",
      "Epoch 1061/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0919 - val_loss: 0.0854\n",
      "Epoch 1062/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0919 - val_loss: 0.0853\n",
      "Epoch 1063/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0918 - val_loss: 0.0853\n",
      "Epoch 1064/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0918 - val_loss: 0.0852\n",
      "Epoch 1065/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0917 - val_loss: 0.0852\n",
      "Epoch 1066/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0917 - val_loss: 0.0852\n",
      "Epoch 1067/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0916 - val_loss: 0.0851\n",
      "Epoch 1068/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0916 - val_loss: 0.0851\n",
      "Epoch 1069/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0915 - val_loss: 0.0850\n",
      "Epoch 1070/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0915 - val_loss: 0.0850\n",
      "Epoch 1071/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0914 - val_loss: 0.0850\n",
      "Epoch 1072/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0914 - val_loss: 0.0849\n",
      "Epoch 1073/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0913 - val_loss: 0.0849\n",
      "Epoch 1074/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0913 - val_loss: 0.0848\n",
      "Epoch 1075/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0912 - val_loss: 0.0848\n",
      "Epoch 1076/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0912 - val_loss: 0.0848\n",
      "Epoch 1077/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0911 - val_loss: 0.0847\n",
      "Epoch 1078/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0911 - val_loss: 0.0847\n",
      "Epoch 1079/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0910 - val_loss: 0.0847\n",
      "Epoch 1080/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0910 - val_loss: 0.0846\n",
      "Epoch 1081/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0909 - val_loss: 0.0846\n",
      "Epoch 1082/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0909 - val_loss: 0.0845\n",
      "Epoch 1083/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0908 - val_loss: 0.0845\n",
      "Epoch 1084/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0908 - val_loss: 0.0845\n",
      "Epoch 1085/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0908 - val_loss: 0.0844\n",
      "Epoch 1086/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0907 - val_loss: 0.0844\n",
      "Epoch 1087/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0907 - val_loss: 0.0844\n",
      "Epoch 1088/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0906 - val_loss: 0.0843\n",
      "Epoch 1089/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0906 - val_loss: 0.0843\n",
      "Epoch 1090/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0905 - val_loss: 0.0843\n",
      "Epoch 1091/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0905 - val_loss: 0.0842\n",
      "Epoch 1092/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0904 - val_loss: 0.0842\n",
      "Epoch 1093/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0904 - val_loss: 0.0842\n",
      "Epoch 1094/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0903 - val_loss: 0.0841\n",
      "Epoch 1095/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0903 - val_loss: 0.0841\n",
      "Epoch 1096/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0903 - val_loss: 0.0841\n",
      "Epoch 1097/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0902 - val_loss: 0.0840\n",
      "Epoch 1098/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0902 - val_loss: 0.0840\n",
      "Epoch 1099/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0901 - val_loss: 0.0840\n",
      "Epoch 1100/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0901 - val_loss: 0.0839\n",
      "Epoch 1101/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0900 - val_loss: 0.0839\n",
      "Epoch 1102/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0900 - val_loss: 0.0839\n",
      "Epoch 1103/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0899 - val_loss: 0.0838\n",
      "Epoch 1104/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0899 - val_loss: 0.0838\n",
      "Epoch 1105/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0899 - val_loss: 0.0838\n",
      "Epoch 1106/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0898 - val_loss: 0.0837\n",
      "Epoch 1107/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0898 - val_loss: 0.0837\n",
      "Epoch 1108/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0897 - val_loss: 0.0837\n",
      "Epoch 1109/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0897 - val_loss: 0.0836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1110/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0896 - val_loss: 0.0836\n",
      "Epoch 1111/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0896 - val_loss: 0.0836\n",
      "Epoch 1112/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0896 - val_loss: 0.0835\n",
      "Epoch 1113/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0895 - val_loss: 0.0835\n",
      "Epoch 1114/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0895 - val_loss: 0.0835\n",
      "Epoch 1115/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0894 - val_loss: 0.0835\n",
      "Epoch 1116/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0894 - val_loss: 0.0834\n",
      "Epoch 1117/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0894 - val_loss: 0.0834\n",
      "Epoch 1118/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0893 - val_loss: 0.0834\n",
      "Epoch 1119/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0893 - val_loss: 0.0833\n",
      "Epoch 1120/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0892 - val_loss: 0.0833\n",
      "Epoch 1121/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0892 - val_loss: 0.0833\n",
      "Epoch 1122/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0892 - val_loss: 0.0832\n",
      "Epoch 1123/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.0891 - val_loss: 0.0832\n",
      "Epoch 1124/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0891 - val_loss: 0.0832\n",
      "Epoch 1125/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0890 - val_loss: 0.0832\n",
      "Epoch 1126/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0890 - val_loss: 0.0831\n",
      "Epoch 1127/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0890 - val_loss: 0.0831\n",
      "Epoch 1128/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0889 - val_loss: 0.0831\n",
      "Epoch 1129/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0889 - val_loss: 0.0830\n",
      "Epoch 1130/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0889 - val_loss: 0.0830\n",
      "Epoch 1131/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0888 - val_loss: 0.0830\n",
      "Epoch 1132/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0888 - val_loss: 0.0830\n",
      "Epoch 1133/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0887 - val_loss: 0.0829\n",
      "Epoch 1134/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0887 - val_loss: 0.0829\n",
      "Epoch 1135/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0887 - val_loss: 0.0829\n",
      "Epoch 1136/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0886 - val_loss: 0.0829\n",
      "Epoch 1137/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0886 - val_loss: 0.0828\n",
      "Epoch 1138/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0886 - val_loss: 0.0828\n",
      "Epoch 1139/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0885 - val_loss: 0.0828\n",
      "Epoch 1140/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0885 - val_loss: 0.0828\n",
      "Epoch 1141/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0885 - val_loss: 0.0827\n",
      "Epoch 1142/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0884 - val_loss: 0.0827\n",
      "Epoch 1143/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0884 - val_loss: 0.0827\n",
      "Epoch 1144/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0883 - val_loss: 0.0826\n",
      "Epoch 1145/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0883 - val_loss: 0.0826\n",
      "Epoch 1146/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0883 - val_loss: 0.0826\n",
      "Epoch 1147/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0882 - val_loss: 0.0826\n",
      "Epoch 1148/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0882 - val_loss: 0.0825\n",
      "Epoch 1149/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0882 - val_loss: 0.0825\n",
      "Epoch 1150/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0881 - val_loss: 0.0825\n",
      "Epoch 1151/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0881 - val_loss: 0.0825\n",
      "Epoch 1152/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0881 - val_loss: 0.0824\n",
      "Epoch 1153/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0880 - val_loss: 0.0824\n",
      "Epoch 1154/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0880 - val_loss: 0.0824\n",
      "Epoch 1155/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0880 - val_loss: 0.0824\n",
      "Epoch 1156/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0879 - val_loss: 0.0823\n",
      "Epoch 1157/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0879 - val_loss: 0.0823\n",
      "Epoch 1158/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0879 - val_loss: 0.0823\n",
      "Epoch 1159/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0878 - val_loss: 0.0823\n",
      "Epoch 1160/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0878 - val_loss: 0.0823\n",
      "Epoch 1161/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0878 - val_loss: 0.0822\n",
      "Epoch 1162/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0877 - val_loss: 0.0822\n",
      "Epoch 1163/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0877 - val_loss: 0.0822\n",
      "Epoch 1164/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0877 - val_loss: 0.0822\n",
      "Epoch 1165/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0876 - val_loss: 0.0821\n",
      "Epoch 1166/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0876 - val_loss: 0.0821\n",
      "Epoch 1167/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0876 - val_loss: 0.0821\n",
      "Epoch 1168/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0876 - val_loss: 0.0821\n",
      "Epoch 1169/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0875 - val_loss: 0.0820\n",
      "Epoch 1170/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0875 - val_loss: 0.0820\n",
      "Epoch 1171/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0875 - val_loss: 0.0820\n",
      "Epoch 1172/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0874 - val_loss: 0.0820\n",
      "Epoch 1173/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0874 - val_loss: 0.0820\n",
      "Epoch 1174/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0874 - val_loss: 0.0819\n",
      "Epoch 1175/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0873 - val_loss: 0.0819\n",
      "Epoch 1176/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0873 - val_loss: 0.0819\n",
      "Epoch 1177/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0873 - val_loss: 0.0819\n",
      "Epoch 1178/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0873 - val_loss: 0.0819\n",
      "Epoch 1179/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0872 - val_loss: 0.0818\n",
      "Epoch 1180/1500\n",
      "28/28 [==============================] - 0s 429us/step - loss: 0.0872 - val_loss: 0.0818\n",
      "Epoch 1181/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0872 - val_loss: 0.0818\n",
      "Epoch 1182/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.0871 - val_loss: 0.0818\n",
      "Epoch 1183/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0871 - val_loss: 0.0817\n",
      "Epoch 1184/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0871 - val_loss: 0.0817\n",
      "Epoch 1185/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0871 - val_loss: 0.0817\n",
      "Epoch 1186/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0870 - val_loss: 0.0817\n",
      "Epoch 1187/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0870 - val_loss: 0.0817\n",
      "Epoch 1188/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0870 - val_loss: 0.0816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1189/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0869 - val_loss: 0.0816\n",
      "Epoch 1190/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0869 - val_loss: 0.0816\n",
      "Epoch 1191/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0869 - val_loss: 0.0816\n",
      "Epoch 1192/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0869 - val_loss: 0.0816\n",
      "Epoch 1193/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0868 - val_loss: 0.0815\n",
      "Epoch 1194/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0868 - val_loss: 0.0815\n",
      "Epoch 1195/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0868 - val_loss: 0.0815\n",
      "Epoch 1196/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0868 - val_loss: 0.0815\n",
      "Epoch 1197/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0867 - val_loss: 0.0815\n",
      "Epoch 1198/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0867 - val_loss: 0.0814\n",
      "Epoch 1199/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0867 - val_loss: 0.0814\n",
      "Epoch 1200/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0866 - val_loss: 0.0814\n",
      "Epoch 1201/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0866 - val_loss: 0.0814\n",
      "Epoch 1202/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0866 - val_loss: 0.0814\n",
      "Epoch 1203/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0866 - val_loss: 0.0814\n",
      "Epoch 1204/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0865 - val_loss: 0.0813\n",
      "Epoch 1205/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0865 - val_loss: 0.0813\n",
      "Epoch 1206/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0865 - val_loss: 0.0813\n",
      "Epoch 1207/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0865 - val_loss: 0.0813\n",
      "Epoch 1208/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0864 - val_loss: 0.0813\n",
      "Epoch 1209/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0864 - val_loss: 0.0812\n",
      "Epoch 1210/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0864 - val_loss: 0.0812\n",
      "Epoch 1211/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0864 - val_loss: 0.0812\n",
      "Epoch 1212/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.0863 - val_loss: 0.0812\n",
      "Epoch 1213/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0863 - val_loss: 0.0812\n",
      "Epoch 1214/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0863 - val_loss: 0.0812\n",
      "Epoch 1215/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0863 - val_loss: 0.0811\n",
      "Epoch 1216/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0863 - val_loss: 0.0811\n",
      "Epoch 1217/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0862 - val_loss: 0.0811\n",
      "Epoch 1218/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0862 - val_loss: 0.0811\n",
      "Epoch 1219/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0862 - val_loss: 0.0811\n",
      "Epoch 1220/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0862 - val_loss: 0.0811\n",
      "Epoch 1221/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0861 - val_loss: 0.0810\n",
      "Epoch 1222/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0861 - val_loss: 0.0810\n",
      "Epoch 1223/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0861 - val_loss: 0.0810\n",
      "Epoch 1224/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0861 - val_loss: 0.0810\n",
      "Epoch 1225/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0860 - val_loss: 0.0810\n",
      "Epoch 1226/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0860 - val_loss: 0.0810\n",
      "Epoch 1227/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0860 - val_loss: 0.0809\n",
      "Epoch 1228/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0860 - val_loss: 0.0809\n",
      "Epoch 1229/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0860 - val_loss: 0.0809\n",
      "Epoch 1230/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0859 - val_loss: 0.0809\n",
      "Epoch 1231/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0859 - val_loss: 0.0809\n",
      "Epoch 1232/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0859 - val_loss: 0.0809\n",
      "Epoch 1233/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0859 - val_loss: 0.0808\n",
      "Epoch 1234/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0858 - val_loss: 0.0808\n",
      "Epoch 1235/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0858 - val_loss: 0.0808\n",
      "Epoch 1236/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0858 - val_loss: 0.0808\n",
      "Epoch 1237/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0858 - val_loss: 0.0808\n",
      "Epoch 1238/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0858 - val_loss: 0.0808\n",
      "Epoch 1239/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0857 - val_loss: 0.0807\n",
      "Epoch 1240/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0857 - val_loss: 0.0807\n",
      "Epoch 1241/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0857 - val_loss: 0.0807\n",
      "Epoch 1242/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0857 - val_loss: 0.0807\n",
      "Epoch 1243/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0857 - val_loss: 0.0807\n",
      "Epoch 1244/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0856 - val_loss: 0.0807\n",
      "Epoch 1245/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0856 - val_loss: 0.0807\n",
      "Epoch 1246/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0856 - val_loss: 0.0806\n",
      "Epoch 1247/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0856 - val_loss: 0.0806\n",
      "Epoch 1248/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0856 - val_loss: 0.0806\n",
      "Epoch 1249/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0855 - val_loss: 0.0806\n",
      "Epoch 1250/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0855 - val_loss: 0.0806\n",
      "Epoch 1251/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0855 - val_loss: 0.0806\n",
      "Epoch 1252/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0855 - val_loss: 0.0805\n",
      "Epoch 1253/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0855 - val_loss: 0.0805\n",
      "Epoch 1254/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0854 - val_loss: 0.0805\n",
      "Epoch 1255/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0854 - val_loss: 0.0805\n",
      "Epoch 1256/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0854 - val_loss: 0.0805\n",
      "Epoch 1257/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0854 - val_loss: 0.0805\n",
      "Epoch 1258/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0854 - val_loss: 0.0805\n",
      "Epoch 1259/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0853 - val_loss: 0.0804\n",
      "Epoch 1260/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0853 - val_loss: 0.0804\n",
      "Epoch 1261/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0853 - val_loss: 0.0804\n",
      "Epoch 1262/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0853 - val_loss: 0.0804\n",
      "Epoch 1263/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0853 - val_loss: 0.0804\n",
      "Epoch 1264/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0853 - val_loss: 0.0804\n",
      "Epoch 1265/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0852 - val_loss: 0.0804\n",
      "Epoch 1266/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0852 - val_loss: 0.0803\n",
      "Epoch 1267/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0852 - val_loss: 0.0803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1268/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0852 - val_loss: 0.0803\n",
      "Epoch 1269/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0852 - val_loss: 0.0803\n",
      "Epoch 1270/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0851 - val_loss: 0.0803\n",
      "Epoch 1271/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0851 - val_loss: 0.0803\n",
      "Epoch 1272/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0851 - val_loss: 0.0803\n",
      "Epoch 1273/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0851 - val_loss: 0.0803\n",
      "Epoch 1274/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0851 - val_loss: 0.0802\n",
      "Epoch 1275/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0851 - val_loss: 0.0802\n",
      "Epoch 1276/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0850 - val_loss: 0.0802\n",
      "Epoch 1277/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0850 - val_loss: 0.0802\n",
      "Epoch 1278/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0850 - val_loss: 0.0802\n",
      "Epoch 1279/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0850 - val_loss: 0.0802\n",
      "Epoch 1280/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0850 - val_loss: 0.0802\n",
      "Epoch 1281/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0850 - val_loss: 0.0802\n",
      "Epoch 1282/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0849 - val_loss: 0.0801\n",
      "Epoch 1283/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0849 - val_loss: 0.0801\n",
      "Epoch 1284/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0849 - val_loss: 0.0801\n",
      "Epoch 1285/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0849 - val_loss: 0.0801\n",
      "Epoch 1286/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0849 - val_loss: 0.0801\n",
      "Epoch 1287/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0849 - val_loss: 0.0801\n",
      "Epoch 1288/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0848 - val_loss: 0.0801\n",
      "Epoch 1289/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0848 - val_loss: 0.0801\n",
      "Epoch 1290/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0848 - val_loss: 0.0800\n",
      "Epoch 1291/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0848 - val_loss: 0.0800\n",
      "Epoch 1292/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0848 - val_loss: 0.0800\n",
      "Epoch 1293/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0848 - val_loss: 0.0800\n",
      "Epoch 1294/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0848 - val_loss: 0.0800\n",
      "Epoch 1295/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0847 - val_loss: 0.0800\n",
      "Epoch 1296/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0847 - val_loss: 0.0800\n",
      "Epoch 1297/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0847 - val_loss: 0.0800\n",
      "Epoch 1298/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0847 - val_loss: 0.0799\n",
      "Epoch 1299/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0847 - val_loss: 0.0799\n",
      "Epoch 1300/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0847 - val_loss: 0.0799\n",
      "Epoch 1301/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0846 - val_loss: 0.0799\n",
      "Epoch 1302/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0846 - val_loss: 0.0799\n",
      "Epoch 1303/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0846 - val_loss: 0.0799\n",
      "Epoch 1304/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0846 - val_loss: 0.0799\n",
      "Epoch 1305/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0846 - val_loss: 0.0799\n",
      "Epoch 1306/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0846 - val_loss: 0.0799\n",
      "Epoch 1307/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0846 - val_loss: 0.0798\n",
      "Epoch 1308/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0845 - val_loss: 0.0798\n",
      "Epoch 1309/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0845 - val_loss: 0.0798\n",
      "Epoch 1310/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0845 - val_loss: 0.0798\n",
      "Epoch 1311/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0845 - val_loss: 0.0798\n",
      "Epoch 1312/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0845 - val_loss: 0.0798\n",
      "Epoch 1313/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0845 - val_loss: 0.0798\n",
      "Epoch 1314/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0845 - val_loss: 0.0798\n",
      "Epoch 1315/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0844 - val_loss: 0.0798\n",
      "Epoch 1316/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0844 - val_loss: 0.0797\n",
      "Epoch 1317/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0844 - val_loss: 0.0797\n",
      "Epoch 1318/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0844 - val_loss: 0.0797\n",
      "Epoch 1319/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0844 - val_loss: 0.0797\n",
      "Epoch 1320/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0844 - val_loss: 0.0797\n",
      "Epoch 1321/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0844 - val_loss: 0.0797\n",
      "Epoch 1322/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0843 - val_loss: 0.0797\n",
      "Epoch 1323/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0843 - val_loss: 0.0797\n",
      "Epoch 1324/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0843 - val_loss: 0.0797\n",
      "Epoch 1325/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0843 - val_loss: 0.0796\n",
      "Epoch 1326/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0843 - val_loss: 0.0796\n",
      "Epoch 1327/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0843 - val_loss: 0.0796\n",
      "Epoch 1328/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0843 - val_loss: 0.0796\n",
      "Epoch 1329/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0842 - val_loss: 0.0796\n",
      "Epoch 1330/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0842 - val_loss: 0.0796\n",
      "Epoch 1331/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0842 - val_loss: 0.0796\n",
      "Epoch 1332/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0842 - val_loss: 0.0796\n",
      "Epoch 1333/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0842 - val_loss: 0.0796\n",
      "Epoch 1334/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0842 - val_loss: 0.0796\n",
      "Epoch 1335/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0842 - val_loss: 0.0795\n",
      "Epoch 1336/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0842 - val_loss: 0.0795\n",
      "Epoch 1337/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0841 - val_loss: 0.0795\n",
      "Epoch 1338/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0841 - val_loss: 0.0795\n",
      "Epoch 1339/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0841 - val_loss: 0.0795\n",
      "Epoch 1340/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0841 - val_loss: 0.0795\n",
      "Epoch 1341/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.0841 - val_loss: 0.0795\n",
      "Epoch 1342/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0841 - val_loss: 0.0795\n",
      "Epoch 1343/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0841 - val_loss: 0.0795\n",
      "Epoch 1344/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0841 - val_loss: 0.0795\n",
      "Epoch 1345/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0840 - val_loss: 0.0795\n",
      "Epoch 1346/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0840 - val_loss: 0.0794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1347/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0840 - val_loss: 0.0794\n",
      "Epoch 1348/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0840 - val_loss: 0.0794\n",
      "Epoch 1349/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0840 - val_loss: 0.0794\n",
      "Epoch 1350/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0840 - val_loss: 0.0794\n",
      "Epoch 1351/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0840 - val_loss: 0.0794\n",
      "Epoch 1352/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0840 - val_loss: 0.0794\n",
      "Epoch 1353/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0839 - val_loss: 0.0794\n",
      "Epoch 1354/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0839 - val_loss: 0.0794\n",
      "Epoch 1355/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0839 - val_loss: 0.0794\n",
      "Epoch 1356/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0839 - val_loss: 0.0794\n",
      "Epoch 1357/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0839 - val_loss: 0.0793\n",
      "Epoch 1358/1500\n",
      "28/28 [==============================] - 0s 287us/step - loss: 0.0839 - val_loss: 0.0793\n",
      "Epoch 1359/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0839 - val_loss: 0.0793\n",
      "Epoch 1360/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0839 - val_loss: 0.0793\n",
      "Epoch 1361/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0839 - val_loss: 0.0793\n",
      "Epoch 1362/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0838 - val_loss: 0.0793\n",
      "Epoch 1363/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0838 - val_loss: 0.0793\n",
      "Epoch 1364/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0838 - val_loss: 0.0793\n",
      "Epoch 1365/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0838 - val_loss: 0.0793\n",
      "Epoch 1366/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0838 - val_loss: 0.0793\n",
      "Epoch 1367/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0838 - val_loss: 0.0793\n",
      "Epoch 1368/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0838 - val_loss: 0.0792\n",
      "Epoch 1369/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0838 - val_loss: 0.0792\n",
      "Epoch 1370/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0838 - val_loss: 0.0792\n",
      "Epoch 1371/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0837 - val_loss: 0.0792\n",
      "Epoch 1372/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0837 - val_loss: 0.0792\n",
      "Epoch 1373/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0837 - val_loss: 0.0792\n",
      "Epoch 1374/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0837 - val_loss: 0.0792\n",
      "Epoch 1375/1500\n",
      "28/28 [==============================] - 0s 144us/step - loss: 0.0837 - val_loss: 0.0792\n",
      "Epoch 1376/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0837 - val_loss: 0.0792\n",
      "Epoch 1377/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0837 - val_loss: 0.0792\n",
      "Epoch 1378/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0837 - val_loss: 0.0792\n",
      "Epoch 1379/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0837 - val_loss: 0.0792\n",
      "Epoch 1380/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0836 - val_loss: 0.0791\n",
      "Epoch 1381/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0836 - val_loss: 0.0791\n",
      "Epoch 1382/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0836 - val_loss: 0.0791\n",
      "Epoch 1383/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0836 - val_loss: 0.0791\n",
      "Epoch 1384/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0836 - val_loss: 0.0791\n",
      "Epoch 1385/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0836 - val_loss: 0.0791\n",
      "Epoch 1386/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0836 - val_loss: 0.0791\n",
      "Epoch 1387/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0836 - val_loss: 0.0791\n",
      "Epoch 1388/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0836 - val_loss: 0.0791\n",
      "Epoch 1389/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0836 - val_loss: 0.0791\n",
      "Epoch 1390/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0835 - val_loss: 0.0791\n",
      "Epoch 1391/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0835 - val_loss: 0.0791\n",
      "Epoch 1392/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0835 - val_loss: 0.0791\n",
      "Epoch 1393/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0835 - val_loss: 0.0790\n",
      "Epoch 1394/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0835 - val_loss: 0.0790\n",
      "Epoch 1395/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0835 - val_loss: 0.0790\n",
      "Epoch 1396/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0835 - val_loss: 0.0790\n",
      "Epoch 1397/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0835 - val_loss: 0.0790\n",
      "Epoch 1398/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0835 - val_loss: 0.0790\n",
      "Epoch 1399/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0835 - val_loss: 0.0790\n",
      "Epoch 1400/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0834 - val_loss: 0.0790\n",
      "Epoch 1401/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0834 - val_loss: 0.0790\n",
      "Epoch 1402/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0834 - val_loss: 0.0790\n",
      "Epoch 1403/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0834 - val_loss: 0.0790\n",
      "Epoch 1404/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0834 - val_loss: 0.0790\n",
      "Epoch 1405/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0834 - val_loss: 0.0790\n",
      "Epoch 1406/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0834 - val_loss: 0.0789\n",
      "Epoch 1407/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0834 - val_loss: 0.0789\n",
      "Epoch 1408/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0834 - val_loss: 0.0789\n",
      "Epoch 1409/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0834 - val_loss: 0.0789\n",
      "Epoch 1410/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0834 - val_loss: 0.0789\n",
      "Epoch 1411/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0833 - val_loss: 0.0789\n",
      "Epoch 1412/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0833 - val_loss: 0.0789\n",
      "Epoch 1413/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0833 - val_loss: 0.0789\n",
      "Epoch 1414/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0833 - val_loss: 0.0789\n",
      "Epoch 1415/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0833 - val_loss: 0.0789\n",
      "Epoch 1416/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0833 - val_loss: 0.0789\n",
      "Epoch 1417/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0833 - val_loss: 0.0789\n",
      "Epoch 1418/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0833 - val_loss: 0.0789\n",
      "Epoch 1419/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0833 - val_loss: 0.0789\n",
      "Epoch 1420/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0833 - val_loss: 0.0788\n",
      "Epoch 1421/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0833 - val_loss: 0.0788\n",
      "Epoch 1422/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0832 - val_loss: 0.0788\n",
      "Epoch 1423/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0832 - val_loss: 0.0788\n",
      "Epoch 1424/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0832 - val_loss: 0.0788\n",
      "Epoch 1425/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0832 - val_loss: 0.0788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1426/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0832 - val_loss: 0.0788\n",
      "Epoch 1427/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0832 - val_loss: 0.0788\n",
      "Epoch 1428/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0832 - val_loss: 0.0788\n",
      "Epoch 1429/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0832 - val_loss: 0.0788\n",
      "Epoch 1430/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0832 - val_loss: 0.0788\n",
      "Epoch 1431/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0832 - val_loss: 0.0788\n",
      "Epoch 1432/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0832 - val_loss: 0.0788\n",
      "Epoch 1433/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0831 - val_loss: 0.0788\n",
      "Epoch 1434/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0831 - val_loss: 0.0788\n",
      "Epoch 1435/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0831 - val_loss: 0.0787\n",
      "Epoch 1436/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0831 - val_loss: 0.0787\n",
      "Epoch 1437/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0831 - val_loss: 0.0787\n",
      "Epoch 1438/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0831 - val_loss: 0.0787\n",
      "Epoch 1439/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0831 - val_loss: 0.0787\n",
      "Epoch 1440/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0831 - val_loss: 0.0787\n",
      "Epoch 1441/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0831 - val_loss: 0.0787\n",
      "Epoch 1442/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0831 - val_loss: 0.0787\n",
      "Epoch 1443/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0831 - val_loss: 0.0787\n",
      "Epoch 1444/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0831 - val_loss: 0.0787\n",
      "Epoch 1445/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0830 - val_loss: 0.0787\n",
      "Epoch 1446/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0830 - val_loss: 0.0787\n",
      "Epoch 1447/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0830 - val_loss: 0.0787\n",
      "Epoch 1448/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0830 - val_loss: 0.0787\n",
      "Epoch 1449/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0830 - val_loss: 0.0787\n",
      "Epoch 1450/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0830 - val_loss: 0.0787\n",
      "Epoch 1451/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0830 - val_loss: 0.0786\n",
      "Epoch 1452/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0830 - val_loss: 0.0786\n",
      "Epoch 1453/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0830 - val_loss: 0.0786\n",
      "Epoch 1454/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0830 - val_loss: 0.0786\n",
      "Epoch 1455/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0830 - val_loss: 0.0786\n",
      "Epoch 1456/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0830 - val_loss: 0.0786\n",
      "Epoch 1457/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0830 - val_loss: 0.0786\n",
      "Epoch 1458/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0829 - val_loss: 0.0786\n",
      "Epoch 1459/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0829 - val_loss: 0.0786\n",
      "Epoch 1460/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0829 - val_loss: 0.0786\n",
      "Epoch 1461/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0829 - val_loss: 0.0786\n",
      "Epoch 1462/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0829 - val_loss: 0.0786\n",
      "Epoch 1463/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0829 - val_loss: 0.0786\n",
      "Epoch 1464/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0829 - val_loss: 0.0786\n",
      "Epoch 1465/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0829 - val_loss: 0.0786\n",
      "Epoch 1466/1500\n",
      "28/28 [==============================] - 0s 0us/step - loss: 0.0829 - val_loss: 0.0786\n",
      "Epoch 1467/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0829 - val_loss: 0.0786\n",
      "Epoch 1468/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0829 - val_loss: 0.0785\n",
      "Epoch 1469/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0829 - val_loss: 0.0785\n",
      "Epoch 1470/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0829 - val_loss: 0.0785\n",
      "Epoch 1471/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0828 - val_loss: 0.0785\n",
      "Epoch 1472/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0828 - val_loss: 0.0785\n",
      "Epoch 1473/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0828 - val_loss: 0.0785\n",
      "Epoch 1474/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0828 - val_loss: 0.0785\n",
      "Epoch 1475/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0828 - val_loss: 0.0785\n",
      "Epoch 1476/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0828 - val_loss: 0.0785\n",
      "Epoch 1477/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0828 - val_loss: 0.0785\n",
      "Epoch 1478/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0828 - val_loss: 0.0785\n",
      "Epoch 1479/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0828 - val_loss: 0.0785\n",
      "Epoch 1480/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0828 - val_loss: 0.0785\n",
      "Epoch 1481/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0828 - val_loss: 0.0785\n",
      "Epoch 1482/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0828 - val_loss: 0.0785\n",
      "Epoch 1483/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0828 - val_loss: 0.0785\n",
      "Epoch 1484/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0828 - val_loss: 0.0785\n",
      "Epoch 1485/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0827 - val_loss: 0.0785\n",
      "Epoch 1486/1500\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.0827 - val_loss: 0.0785\n",
      "Epoch 1487/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0827 - val_loss: 0.0784\n",
      "Epoch 1488/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0827 - val_loss: 0.0784\n",
      "Epoch 1489/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0827 - val_loss: 0.0784\n",
      "Epoch 1490/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0827 - val_loss: 0.0784\n",
      "Epoch 1491/1500\n",
      "28/28 [==============================] - 0s 286us/step - loss: 0.0827 - val_loss: 0.0784\n",
      "Epoch 1492/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0827 - val_loss: 0.0784\n",
      "Epoch 1493/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0827 - val_loss: 0.0784\n",
      "Epoch 1494/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0827 - val_loss: 0.0784\n",
      "Epoch 1495/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0827 - val_loss: 0.0784\n",
      "Epoch 1496/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0827 - val_loss: 0.0784\n",
      "Epoch 1497/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0827 - val_loss: 0.0784\n",
      "Epoch 1498/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0827 - val_loss: 0.0784\n",
      "Epoch 1499/1500\n",
      "28/28 [==============================] - 0s 143us/step - loss: 0.0827 - val_loss: 0.0784\n",
      "Epoch 1500/1500\n",
      "28/28 [==============================] - 0s 142us/step - loss: 0.0826 - val_loss: 0.0784\n"
     ]
    }
   ],
   "source": [
    "# fit the model - INTENSIVE\n",
    "model5_history = model5.fit(X_train, Y_train, batch_size=256, epochs=1500, verbose=1, \\\n",
    "                            shuffle = True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use our model to predict in the range we want\n",
    "num_epochs = f'{len(model5_history.epoch)}'\n",
    "\n",
    "X_range = np.linspace(-10, 10, 500)\n",
    "y_pred = model5.predict(X_range)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "ax.scatter(X_train, Y_train, label='Training data')\n",
    "ax.plot(X_range, y_pred, lw=4, color='r', label=f'NN ({num_epochs} epochs)')\n",
    "\n",
    "ax.set_xlabel(r'$X$', fontsize=20)\n",
    "ax.set_ylabel(r'$Y$', fontsize=20)\n",
    "ax.set_title(f'NN with {len(model5_history.model.layers)} layers, {H} nodes in each layer', fontsize=LABEL_SIZE)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems very good. Let's see the $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score as r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 0us/step\n",
      "Test loss: 0.08376505225896835\n",
      "Test R2: 0.8739446439144187\n"
     ]
    }
   ],
   "source": [
    "score = model5.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', score)\n",
    "print('Test R2:', r2(Y_test, model5.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "ax.plot(np.sqrt(model5_history.history['loss']), 'r')\n",
    "ax.plot(np.sqrt(model5_history.history['val_loss']), 'b' ,label='Val')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
